{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coordinated-bhutan",
   "metadata": {},
   "source": [
    "主要包含：\n",
    "* lightning中的数据容器\n",
    "* 迭代多个数据集\n",
    "* 处理顺序数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-least",
   "metadata": {},
   "source": [
    "# Lightning 中的数据容器\n",
    "\n",
    "Lightning 中使用了几种不同的数据容器："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-payday",
   "metadata": {},
   "source": [
    "|  对象   | 定义  |\n",
    "|  ----  | ----  |\n",
    "| Dataset  | PyTorchDataset表示从键到数据样本的映射。 |\n",
    "| IterableDataset  | PyTorch IterableDataset 表示数据流。 |\n",
    "|DataLoader|PyTorch DataLoader 表示可在 DataSet 上迭代的 Python。|\n",
    "|LightningDataModule|LightningDataModule 只是一个集合：训练 DataLoader、验证 DataLoader、测试 DataLoader 和预测 DataLoader，以及匹配的转换和所需的数据处理/下载步骤。|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-miami",
   "metadata": {},
   "source": [
    "# 为什么选择 LightningDataModules？\n",
    "\n",
    "LightningDataModule 被设计为一种将数据相关挂钩与 LightningModule 分离的方式，以便您可以开发数据集不可知模型。 LightningDataModule 可以轻松地将不同的数据集与您的模型进行热交换，因此您可以对其进行测试并跨域对其进行基准测试。 它还使跨项目共享和重用确切的数据拆分和转换成为可能。\n",
    "\n",
    "阅读本文以了解有关 LightningDataModules 的更多详细信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-holder",
   "metadata": {},
   "source": [
    "# 多个数据集\n",
    "\n",
    "有几种方法可以将多个数据集传递给 Lightning：\n",
    "* 创建一个 DataLoader，它在后台迭代多个数据集。\n",
    "* 在训练循环中，您可以将多个 DataLoader 作为字典或列表/元组传递，Lightning 将自动组合来自不同 DataLoader 的批次。\n",
    "* 在验证和测试循环中，您可以选择返回多个 DataLoader，Lightning 将依次调用它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-payday",
   "metadata": {},
   "source": [
    "# 使用 LightningDataModule\n",
    "\n",
    "你可以使用它的数据加载器钩子在你的 LightningDataModule 中设置多个 DataLoader，Lightning 将在后台使用正确的一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "\n",
    "    ...\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return [torch.utils.data.DataLoader(self.val_dataset_1), torch.utils.data.DataLoader(self.val_dataset_2)]\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_dataset)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-cinema",
   "metadata": {},
   "source": [
    "# 使用 LightningModule 钩子\n",
    "\n",
    "## 连接数据集\n",
    "\n",
    "对于多个数据集的训练，您可以创建一个 dataloader 类来包装您的多个数据集（这当然也适用于测试和验证数据集）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return tuple(d[i] for d in self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(d) for d in self.datasets)\n",
    "\n",
    "\n",
    "class LitModel(LightningModule):\n",
    "    def train_dataloader(self):\n",
    "        concat_dataset = ConcatDataset(datasets.ImageFolder(traindir_A), datasets.ImageFolder(traindir_B))\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            concat_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # SAME\n",
    "        ...\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # SAME\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-adjustment",
   "metadata": {},
   "source": [
    "## 返回多个 DataLoader\n",
    "\n",
    "您可以在 LightningModule 中设置多个 DataLoader，Lightning 会负责批量组合。\n",
    "\n",
    "有关更多详细信息，请查看 multiple_trainloader_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        loader_a = torch.utils.data.DataLoader(range(6), batch_size=4)\n",
    "        loader_b = torch.utils.data.DataLoader(range(15), batch_size=5)\n",
    "\n",
    "        # 将加载器作为字典传递。 这将创建这样的批次：\n",
    "        # {'a': batch from loader_a, 'b': batch from loader_b}\n",
    "        loaders = {\"a\": loader_a, \"b\": loader_b}\n",
    "\n",
    "        # 或者：\n",
    "        # 将加载器作为序列传递。 这将创建这样的批次：\n",
    "        # [batch from loader_a, batch from loader_b]\n",
    "        loaders = [loader_a, loader_b]\n",
    "\n",
    "        return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-suite",
   "metadata": {},
   "source": [
    "此外，Lightning 还支持嵌套列表和字典（或组合）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        loader_a = torch.utils.data.DataLoader(range(8), batch_size=4)\n",
    "        loader_b = torch.utils.data.DataLoader(range(16), batch_size=2)\n",
    "\n",
    "        return {\"a\": loader_a, \"b\": loader_b}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 从每个 DataLoader 访问一个带有批处理的字典\n",
    "        batch_a = batch[\"a\"]\n",
    "        batch_b = batch[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        loader_a = torch.utils.data.DataLoader(range(8), batch_size=4)\n",
    "        loader_b = torch.utils.data.DataLoader(range(16), batch_size=4)\n",
    "        loader_c = torch.utils.data.DataLoader(range(32), batch_size=4)\n",
    "        loader_c = torch.utils.data.DataLoader(range(64), batch_size=4)\n",
    "\n",
    "        # 将加载器作为嵌套字典传递。 这将创建这样的批次：\n",
    "        loaders = {\"loaders_a_b\": [loader_a, loader_b], \"loaders_c_d\": {\"c\": loader_c, \"d\": loader_d}}\n",
    "        return loaders\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # access the data\n",
    "        batch_a_b = batch[\"loaders_a_b\"]\n",
    "        batch_c_d = batch[\"loaders_c_d\"]\n",
    "\n",
    "        batch_a = batch_a_b[0]\n",
    "        batch_b = batch_a_b[1]\n",
    "\n",
    "        batch_c = batch_c_d[\"c\"]\n",
    "        batch_d = batch_c_d[\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-camel",
   "metadata": {},
   "source": [
    "# 多个验证/测试数据集\n",
    "\n",
    "对于验证和测试 DataLoader，您可以传递单个 DataLoader 或它们的列表。 此可选命名参数可与上述任何用例结合使用。 您可以选择按顺序或同时传递批次，就像训练步骤一样。 验证和测试 DataLoaders 的默认模式是顺序的。\n",
    "\n",
    "有关默认顺序选项的更多详细信息，请参阅以下内容：\n",
    "* `val_dataloader()`\n",
    "* `test_dataloader()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_dataloader(self):\n",
    "    loader_1 = DataLoader()\n",
    "    loader_2 = DataLoader()\n",
    "    return [loader_1, loader_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-thought",
   "metadata": {},
   "source": [
    "要同时组合多个测试和验证 DataLoader 的批次，需要使用 CombinedLoader 包装 DataLoader。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "\n",
    "\n",
    "def val_dataloader(self):\n",
    "    loader_1 = DataLoader()\n",
    "    loader_2 = DataLoader()\n",
    "    loaders = {\"a\": loader_a, \"b\": loader_b}\n",
    "    combined_loaders = CombinedLoader(loaders, \"max_size_cycle\")\n",
    "    return combined_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-intersection",
   "metadata": {},
   "source": [
    "# 使用额外的数据加载器进行测试\n",
    "\n",
    "即使尚未在 LightningModule 实例中定义 test_dataloader() 方法，您也可以在测试集上运行推理。 例如，如果您的测试数据集在您的模型声明时不可用，就会出现这种情况。 只需将测试集传递给 test() 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup your data loader\n",
    "test = DataLoader(...)\n",
    "\n",
    "# test (pass in the loader)\n",
    "trainer.test(test_dataloaders=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-chest",
   "metadata": {},
   "source": [
    "# 顺序数据\n",
    "\n",
    "Lightning 内置了对处理顺序数据的支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-freedom",
   "metadata": {},
   "source": [
    "## 打包序列作为输入\n",
    "\n",
    "使用 PackedSequence 时，做两件事：\n",
    "* 返回数据集中的填充张量或 DataLoader collate_fn 中的可变长度张量列表（示例显示列表实现）。\n",
    "* 根据用例将序列打包到前向或训练和验证步骤中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For use in DataLoader\n",
    "def collate_fn(batch):\n",
    "    x = [item[0] for item in batch]\n",
    "    y = [item[1] for item in batch]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# In module\n",
    "def training_step(self, batch, batch_nb):\n",
    "    x = rnn.pack_sequence(batch[0], enforce_sorted=False)\n",
    "    y = rnn.pack_sequence(batch[1], enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-degree",
   "metadata": {},
   "source": [
    "# 时间截断断续传播 (TBPTT)\n",
    "\n",
    "例如，在训练 RNN 时使用 Truncated Backpropagation Through Time 可以节省内存。\n",
    "\n",
    "闪电可以通过这个标志自动处理TBPTT。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "class MyModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 重要：这个属性激活了时间截断的反向传播\n",
    "        # 将此值设置为 2 会将批次拆分为大小为 2 的序列\n",
    "        self.truncated_bptt_steps = 2\n",
    "\n",
    "    # 截断时间反向传播\n",
    "    def training_step(self, batch, batch_idx, hiddens):\n",
    "        # 必须更新训练步骤以接受 ``hiddens`` 参数\n",
    "        # hiddens 是前一个被截断的反向传播步骤的隐藏\n",
    "        out, hiddens = self.lstm(data, hiddens)\n",
    "        return {\"loss\": ..., \"hiddens\": hiddens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-emerald",
   "metadata": {},
   "source": [
    "> 如果您需要修改批处理的拆分方式，请覆盖 tbptt_split_batch()。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-surgeon",
   "metadata": {},
   "source": [
    "# 可迭代数据集\n",
    "\n",
    "Lightning 支持使用 IterableDatasets 以及地图样式的数据集。 IterableDatasets 在使用顺序数据时提供了一个更自然的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-mills",
   "metadata": {},
   "source": [
    "> 使用 IterableDataset 时，您必须在初始化 Trainer 时将 val_check_interval 设置为 1.0（默认值）或 int（指定验证前要运行的训练批次数）。 这是因为 IterableDataset 没有 __len__ 并且当 val_check_interval 小于 1 时，Lightning 需要它来计算验证间隔。 同样，您可以将 limit_{mode}_batches 设置为浮点数或整数。 如果它设置为 0.0 或 0 它将设置 num_{mode}_batches 为 0，如果它是一个 int 它会将 num_{mode}_batches 设置为 limit_{mode}_batches，如果它设置为 1.0 它将运行 整个数据集，否则会抛出异常。 这里的模式可以是训练/验证/测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IterableDataset\n",
    "class CustomDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_source)\n",
    "\n",
    "\n",
    "# Setup DataLoader\n",
    "def train_dataloader(self):\n",
    "    seq_data = [\"A\", \"long\", \"time\", \"ago\", \"in\", \"a\", \"galaxy\", \"far\", \"far\", \"away\"]\n",
    "    iterable_dataset = CustomDataset(seq_data)\n",
    "\n",
    "    dataloader = DataLoader(dataset=iterable_dataset, batch_size=5)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set val_check_interval\n",
    "trainer = Trainer(val_check_interval=100)\n",
    "\n",
    "# Set limit_val_batches to 0.0 or 0\n",
    "trainer = Trainer(limit_val_batches=0.0)\n",
    "\n",
    "# Set limit_val_batches as an int\n",
    "trainer = Trainer(limit_val_batches=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
