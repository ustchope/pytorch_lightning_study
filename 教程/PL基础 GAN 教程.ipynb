{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f5df6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 394 ms (started: 2021-09-01 18:52:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34904288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #2 Sept 01, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dfeca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.55 ms (started: 2021-09-01 19:10:05 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "from pytorch_lightning import LightningModule, seed_everything, Trainer, LightningDataModule\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from torchmetrics.functional import accuracy\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed_everything(7)\n",
    "\n",
    "PATH_DATASETS = os.environ.get('PATH_DATASETS', '.')\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e67e0",
   "metadata": {},
   "source": [
    "# MNIST 数据模块\n",
    "\n",
    "下面，我们为 MNIST 数据集定义一个 DataModule。 要了解有关 DataModules 的更多信息，请查看我们关于它们的教程或查看最新文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7eac832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.58 ms (started: 2021-09-01 18:55:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = PATH_DATASETS,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, )),\n",
    "        ])\n",
    "\n",
    "        # self.dims is returned when you call dm.size()\n",
    "        # Setting default dims here because we know them.\n",
    "        # Could optionally be assigned dynamically in dm.setup()\n",
    "        self.dims = (1, 28, 28)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.mnist_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b93af5",
   "metadata": {},
   "source": [
    "# A. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b0fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.84 ms (started: 2021-09-01 19:09:21 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96eb225",
   "metadata": {},
   "source": [
    "# B. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc853bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.41 ms (started: 2021-09-01 19:09:22 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6e0de",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6f8ef",
   "metadata": {},
   "source": [
    "在这个例子中需要检查的几个很酷的功能......\n",
    "\n",
    "* 我们使用 `some_tensor.type_as(another_tensor)` 来确保我们在正确的设备（即 GPU、CPU）上初始化新的张量。\n",
    "* Lightning 会自动将您的数据加载器数据放在正确的设备上\n",
    "* 在这个例子中，我们动态地从潜在的暗淡中提取，所以我们需要动态地将张量添加到正确的设备。\n",
    "* `type_as` 是我们推荐的方法。\n",
    "* 此示例展示了如何在 LightningModule 中使用多个数据加载器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c752ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.35 ms (started: 2021-09-01 19:11:44 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class GAN(LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        width,\n",
    "        height,\n",
    "        latent_dim: int = 100,\n",
    "        lr: float = 0.0002,\n",
    "        b1: float = 0.5,\n",
    "        b2: float = 0.999,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 网络\n",
    "        data_shape = (channels, width, height)\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n",
    "        self.discriminator = Discriminator(img_shape=data_shape)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # 训练生成器\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            self.logger.experiment.add_image('generated_images', grid, 0)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({'loss': g_loss, 'progress_bar': tqdm_dict, 'log': tqdm_dict})\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "            fake = fake.type_as(imgs)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({'loss': d_loss, 'progress_bar': tqdm_dict, \n",
    "                                  'log': tqdm_dict})\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        z = self.validation_z.type_as(self.generator.model[0].weight)\n",
    "\n",
    "        # log sampled images\n",
    "        sample_imgs = self(z)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image('generated_images', grid, self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a30d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name          | Type          | Params | In sizes | Out sizes     \n",
      "----------------------------------------------------------------------------\n",
      "0 | generator     | Generator     | 1.5 M  | [2, 100] | [2, 1, 28, 28]\n",
      "1 | discriminator | Discriminator | 533 K  | ?        | ?             \n",
      "----------------------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.174     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0b0a0450db4f49abba86b8fde847c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.6 s (started: 2021-09-01 19:11:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "dm = MNISTDataModule()\n",
    "model = GAN(*dm.size())\n",
    "trainer = Trainer(gpus=AVAIL_GPUS, max_epochs=5, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4a0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
