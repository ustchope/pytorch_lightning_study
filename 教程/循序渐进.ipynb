{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "local-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 930 ms (started: 2021-08-31 22:51:10 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main ea72b2d] 更新 #3 Aug 31, 2021\n",
      " 2 files changed, 2138 insertions(+)\n",
      " create mode 100644 \"\\346\\225\\231\\347\\250\\213/.ipynb_checkpoints/\\345\\276\\252\\345\\272\\217\\346\\270\\220\\350\\277\\233-checkpoint.ipynb\"\n",
      " create mode 100644 \"\\346\\225\\231\\347\\250\\213/\\345\\276\\252\\345\\272\\217\\346\\270\\220\\350\\277\\233.ipynb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/pytorch_lightning_study.git\n",
      "   02483ee..ea72b2d  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.6 s (started: 2021-08-31 22:51:29 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #3 Aug 31, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intense-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.96 s (started: 2021-08-31 22:51:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-analyst",
   "metadata": {},
   "source": [
    "本指南将带您了解 PyTorch Lightning 的核心部分。\n",
    "\n",
    "我们将完成以下工作：\n",
    "* 实现一个 MNIST 分类器。\n",
    "* 使用继承实现 AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-operations",
   "metadata": {},
   "source": [
    "> 任何 DL/ML PyTorch 项目都适合 Lightning 结构。 在这里，我们只专注于 3 种类型的研究来说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-thursday",
   "metadata": {},
   "source": [
    "# 从 MNIST 到自动编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-recovery",
   "metadata": {},
   "source": [
    "## 研究代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-madness",
   "metadata": {},
   "source": [
    "### 模型\n",
    "\n",
    "闪电模块包含所有核心研究成分：\n",
    "* 该模型\n",
    "* 优化器\n",
    "* 训练/验证/测试步骤\n",
    "\n",
    "让我们首先从模型开始。 在这种情况下，我们将设计一个 3 层神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.9 ms (started: 2021-08-31 21:54:07 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "\n",
    "\n",
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, height, width)\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 256)\n",
    "        self.layer_3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-container",
   "metadata": {},
   "source": [
    "请注意，这是一个闪电模块，而不是 torch.nn.Module。 LightningModule 等效于纯 PyTorch 模块，只是它增加了功能。 但是，您可以像使用 PyTorch 模块一样使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "individual-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.6 ms (started: 2021-08-31 21:54:52 +08:00)\n"
     ]
    }
   ],
   "source": [
    "net = LitMNIST()\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mechanical-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3127, -2.2126, -2.3196, -2.2438, -2.2116, -2.2051, -2.3613, -2.3832,\n",
       "         -2.3733, -2.4333]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.66 ms (started: 2021-08-31 21:55:31 +08:00)\n"
     ]
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-superintendent",
   "metadata": {},
   "source": [
    "现在我们添加了包含所有训练循环逻辑的 training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-offer",
   "metadata": {},
   "source": [
    "### 数据\n",
    "\n",
    "闪电在纯数据加载器上运行。 这是用于加载 MNIST 的 PyTorch 代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "computational-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.2 ms (started: 2021-08-31 22:22:22 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# transforms\n",
    "# prepare transforms standard to MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# data\n",
    "mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "mnist_train = DataLoader(mnist_train, batch_size=64, num_workers = 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-contact",
   "metadata": {},
   "source": [
    "您可以通过 3 种方式使用 DataLoaders：\n",
    "\n",
    "1. 将 DataLoaders 传递给 .fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-highlight",
   "metadata": {},
   "source": [
    "将数据加载器传递给 .fit() 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-submission",
   "metadata": {},
   "source": [
    "2. LightningModule 数据加载器\n",
    "\n",
    "对于快速的研究原型设计，将模型与数据加载器链接可能更容易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    def train_dataloader(self):\n",
    "        # transforms\n",
    "        # prepare transforms standard to MNIST\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        # data\n",
    "        mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "        return DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transforms = ...\n",
    "        mnist_val = ...\n",
    "        return DataLoader(mnist_val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        transforms = ...\n",
    "        mnist_test = ...\n",
    "        return DataLoader(mnist_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-flush",
   "metadata": {},
   "source": [
    "DataLoaders 已经在模型中，不需要在 .fit() 上指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-architect",
   "metadata": {},
   "source": [
    "3. DataModules（推荐）\n",
    "\n",
    "定义自由浮动的数据加载器、拆分、下载指令等可能会变得混乱。 在这种情况下，最好将数据集的完整定义分组到一个 DataModule 中，其中包括：\n",
    "* 下载说明\n",
    "* 加工说明\n",
    "* 拆分说明\n",
    "* 训练数据加载器\n",
    "* Val 数据加载器\n",
    "* 测试数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataModule(LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dims = None\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # 仅在 1 个 GPU 上调用\n",
    "        download_dataset()\n",
    "        tokenize()\n",
    "        build_vocab()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # 在每个 GPU 上调用\n",
    "        vocab = load_vocab()\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "        self.train, self.val, self.test = load_datasets()\n",
    "        self.train_dims = self.train.next_batch.size()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-stylus",
   "metadata": {},
   "source": [
    "使用 DataModules 可以更轻松地共享完整的数据集定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 MNIST 数据集\n",
    "mnist_dm = MNISTDatamodule()\n",
    "model = LitModel(num_classes=mnist_dm.num_classes)\n",
    "trainer.fit(model, mnist_dm)\n",
    "\n",
    "# 或具有相同模型的其他数据集\n",
    "imagenet_dm = ImagenetDatamodule()\n",
    "model = LitModel(num_classes=imagenet_dm.num_classes)\n",
    "trainer.fit(model, imagenet_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-sudan",
   "metadata": {},
   "source": [
    "### 由数据定义的模型\n",
    "\n",
    "当您的模型需要了解数据时，最好在将数据传递给模型之前对其进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dm 并手动调用处理\n",
    "dm = ImagenetDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "model = LitModel(out_features=dm.num_classes, img_width=dm.img_width, img_height=dm.img_height)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-blast",
   "metadata": {},
   "source": [
    "* 使用 prepare_data() 下载和处理数据集。\n",
    "* 使用 setup() 进行拆分，并构建模型内部。\n",
    "\n",
    "使用 DataModule 的替代方法是将模型模块的初始化推迟到 LightningModule 的`setup`方法，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        self.l1 = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        download_data()\n",
    "        tokenize()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # 阶段是“fit”、“验证”、“测试”或“预测”。 90% 的时间不相关\n",
    "        data = load_data()\n",
    "        num_classes = data.classes\n",
    "        self.l1 = nn.Linear(..., num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-satellite",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "接下来我们选择使用什么优化器来训练我们的系统。 在 PyTorch 中，我们这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "inner-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.34 ms (started: 2021-08-31 22:20:44 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(LitMNIST().parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-particular",
   "metadata": {},
   "source": [
    "在 Lightning 中，我们做同样的事情，但在 configure_optimizers() 方法下组织它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-arrangement",
   "metadata": {},
   "source": [
    "> LightningModule 本身有参数，所以传入 self.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-impression",
   "metadata": {},
   "source": [
    "但是，如果您有多个优化器，请使用匹配参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.generator(), lr=1e-3), Adam(self.discriminator(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-persian",
   "metadata": {},
   "source": [
    "### 训练步骤\n",
    "\n",
    "训练步骤是在训练循环中发生的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs:\n",
    "    for batch in data:\n",
    "        # TRAINING STEP\n",
    "        # ....\n",
    "        # TRAINING STEP\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-sponsorship",
   "metadata": {},
   "source": [
    "在 MNIST 的情况下，我们执行以下操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs:\n",
    "    for batch in data:\n",
    "        # ------ TRAINING STEP START ------\n",
    "        x, y = batch\n",
    "        logits = model(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        # ------ TRAINING STEP END ------\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-detroit",
   "metadata": {},
   "source": [
    "在 Lightning 中，训练步骤中的所有内容都在 LightningModule 中的 training_step() 函数下组织。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-humor",
   "metadata": {},
   "source": [
    "同样，这是相同的 PyTorch 代码，只是它是由 LightningModule 组织的。 此代码不受限制，这意味着它可以像完整的 seq-2-seq、RL 循环、GAN 等一样复杂……"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-water",
   "metadata": {},
   "source": [
    "## 工程代码\n",
    "\n",
    "### 训练\n",
    "\n",
    "到目前为止，我们在纯 PyTorch 中定义了 4 个关键成分，但使用 LightningModule 组织代码。\n",
    "* 模型。\n",
    "* 训练数据。\n",
    "* 优化器。\n",
    "* 训练循环中会发生什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-password",
   "metadata": {},
   "source": [
    "为清楚起见，我们会记得完整的 LightningModule 现在看起来像这样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immune-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.6 ms (started: 2021-08-31 22:20:08 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 256)\n",
    "        self.layer_3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-freight",
   "metadata": {},
   "source": [
    "同样，这是相同的 PyTorch 代码，只是它由 LightningModule 组织。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-statistics",
   "metadata": {},
   "source": [
    "### 日志记录\n",
    "\n",
    "要登录 Tensorboard、您最喜欢的记录器和/或进度条，请使用 log() 方法，该方法可以从 LightningModule 中的任何方法调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_metric\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-event",
   "metadata": {},
   "source": [
    "log() 方法有几个选项：\n",
    "* on_step（记录训练中该步骤的指标）\n",
    "* on_epoch（在epoch结束时自动累积和记录）\n",
    "* prog_bar（记录到进度条）\n",
    "* logger（像 Tensorboard 一样记录到记录器）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-intervention",
   "metadata": {},
   "source": [
    "根据调用日志的位置，Lightning 会自动为您确定正确的模式。 但是当然您可以通过手动设置标志来覆盖默认行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-theater",
   "metadata": {},
   "source": [
    "> 设置 on_epoch=True 将在整个训练时期累积您的记录值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-rendering",
   "metadata": {},
   "source": [
    "您还可以直接使用记录器的任何方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    tensorboard = self.logger.experiment\n",
    "    tensorboard.any_summary_writer_method_you_want()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-distinction",
   "metadata": {},
   "source": [
    "训练开始后，您可以使用自己喜欢的记录器或启动 Tensorboard 日志来查看日志："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-consent",
   "metadata": {},
   "source": [
    "这将生成自动tensorboard日志（或使用您选择的记录器）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-afghanistan",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gu0bxe6t3vj612e0nktaw02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-advice",
   "metadata": {},
   "source": [
    "但是您也可以使用我们支持的任何数量的其他记录器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-census",
   "metadata": {},
   "source": [
    "### 在 CPU 上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "planned-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  9.98it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:00,  9.85it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:00<00:00,  9.78it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:00<00:00,  9.72it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00,  9.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 518 ms (started: 2021-08-31 22:48:01 +08:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "example_iter = [1,2,3,4,5]\n",
    "for rec in tqdm(example_iter):\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cosmetic-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | layer_1 | Linear | 100 K \n",
      "1 | layer_2 | Linear | 33.0 K\n",
      "2 | layer_3 | Linear | 2.6 K \n",
      "-----------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1dbb69317e436294a0a0c56a99d215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 44s (started: 2021-08-31 22:42:47 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = LitMNIST()\n",
    "trainer = Trainer(progress_bar_refresh_rate = 1)\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-lotus",
   "metadata": {},
   "source": [
    "### 在 GPU 上训练\n",
    "\n",
    "但最好的地方是你可以用trainer flag做的所有魔法。 例如，要在 GPU 上运行此模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer(gpus=1)\n",
    "trainer.fit(model, mnist_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
