{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cfd388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 300 ms (started: 2021-09-01 17:45:43 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #1 Sept 01, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3700359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.22 ms (started: 2021-09-01 18:05:38 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "import torchmetrics\n",
    "\n",
    "PATH_DATASETS = os.environ.get('PATH_DATASETS', '.')\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "num_workers = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127abf07",
   "metadata": {},
   "source": [
    "# 定义 LitMNISTModel\n",
    "\n",
    "下面，我们重用了 hello world 教程中的 LightningModule，它对 MNIST 手写数字进行分类。\n",
    "\n",
    "不幸的是，我们在模型中硬编码了特定于数据集的项目，永远限制它使用 MNIST 数据。 😢\n",
    "\n",
    "如果您不打算在不同的数据集上训练/评估您的模型，这很好。 但是，在许多情况下，当您想使用不同的数据集尝试您的架构时，这会变得很麻烦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e6cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms (started: 2021-09-01 17:50:14 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.data_dir = data_dir\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, )),\n",
    "        ])\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Build model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torchmetrics.functional.accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=128, num_workers=num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=128, num_workers=num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=128, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a3fe0",
   "metadata": {},
   "source": [
    "# 训练 ListMNIST 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c1443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55.1 K\n",
      "-------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac8fd23eb7c4f3ab2e720cdfe6f8f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d2da7c82af421680da874bbdcdbbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.7 s (started: 2021-09-01 17:50:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    gpus=AVAIL_GPUS,\n",
    "    progress_bar_refresh_rate=20,\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ad1ec",
   "metadata": {},
   "source": [
    "# 使用数据模块\n",
    "\n",
    "DataModules 是一种将数据相关挂钩与 LightningModule 分离的方法，因此您可以开发与数据集无关的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003cec6",
   "metadata": {},
   "source": [
    "# 定义 MNISTDataModule\n",
    "\n",
    "让我们回顾一下下面课程中的每个函数，并讨论它们在做什么：\n",
    "\n",
    "1. `__init__`\n",
    "    * 接收一个 `data_dir` 参数，该参数指向您已下载/希望下载 MNIST 数据集的位置。\n",
    "    * 定义将应用于训练、验证和测试数据集拆分的转换。\n",
    "    * 定义默认的 `self.dims`，它是一个从 `datamodule.size()` 返回的元组，可以帮助您初始化模型。\n",
    "2. `prepare_data` \n",
    "    * 这是我们可以下载数据集的地方。 我们指向我们想要的数据集，如果在那里找不到数据集，就要求 torchvision 的 MNIST 数据集类下载。 \n",
    "    * 请注意，我们没有在此函数中进行任何状态分配（即 `self.something = ...`）\n",
    "3. `setup`  \n",
    "    * 从文件加载数据并为每个分割（训练、验证、测试）准备 PyTorch 张量数据集。\n",
    "    * 设置需要一个“`stage`”参数，用于分离“`fit`”和“`test`”的逻辑。\n",
    "    * 如果您不介意一次加载所有数据集，您可以设置一个条件，以允许在 None 传递到 stage 时运行“fit”相关设置和“test”相关设置。\n",
    "    * 请注意，这会在所有 GPU 上运行，并且在此处进行状态分配*是*安全的\n",
    "4. `x_dataloader`  \n",
    "    * train_dataloader()、val_dataloader() 和 test_dataloader() 都返回 PyTorch DataLoader 实例，这些实例是通过包装我们在 setup() 中准备的各自数据集创建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0fca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.59 ms (started: 2021-09-01 17:58:48 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir: str = PATH_DATASETS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, )),\n",
    "        ])\n",
    "\n",
    "        # 调用 dm.size() 时返回 self.dims\n",
    "        # 在这里设置默认暗度，因为我们知道它们。\n",
    "        # 可以选择在 dm.setup() 中动态分配\n",
    "        self.dims = (1, 28, 28)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # 分配 train/val 数据集以用于数据加载器\n",
    "        if stage in ('fit', None):\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # 分配测试数据集以在数据加载器中使用\n",
    "        if stage in ('test', None):\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefa9df",
   "metadata": {},
   "source": [
    "# 定义与数据集无关的 LitModel\n",
    "\n",
    "下面，我们定义与我们之前制作的 LitMNIST 模型相同的模型。\n",
    "\n",
    "但是，这次我们的模型可以自由使用我们想要的任何输入数据🔥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0035683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.39 ms (started: 2021-09-01 17:58:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitModel(LightningModule):\n",
    "\n",
    "    def __init__(self, channels, width, height, num_classes, hidden_size=64, learning_rate=2e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # 我们将输入维度作为参数并使用它们来动态构建模型。\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torchmetrics.functional.accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a46cb",
   "metadata": {},
   "source": [
    "# 使用 MNISTDataModule 训练 LitModel\n",
    "\n",
    "现在，我们使用 MNISTDataModule 的配置设置和数据加载器初始化和训练 LitModel。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fd978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55.1 K\n",
      "-------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4327ea63a10496faa48b9c0ae30d1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3178838cb01248c588e7fe0d1b818268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.5 s (started: 2021-09-01 18:02:26 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 初始化数据模块\n",
    "dm = MNISTDataModule()\n",
    "# 从数据模块的属性初始化模型\n",
    "model = LitModel(*dm.size(), dm.num_classes)\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=AVAIL_GPUS,\n",
    ")\n",
    "# 将数据模块作为 arg 传递给 trainer.fit 以覆盖模型挂钩:)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed465e",
   "metadata": {},
   "source": [
    "# 定义 CIFAR10 数据模块\n",
    "\n",
    "让我们通过为 CIFAR10 数据集定义一个新的数据模块来证明我们之前制作的 LitModel 与数据集无关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c6d59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.39 ms (started: 2021-09-01 18:05:08 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10DataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=BATCH_SIZE, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302c731",
   "metadata": {},
   "source": [
    "# 使用 CIFAR10DataModule 训练 LitModel\n",
    "\n",
    "我们的模型不是很好，所以它在 CIFAR10 数据集上的表现会很糟糕。\n",
    "\n",
    "这里的重点是我们可以看到我们的 LitModel 使用不同的数据模块作为其输入数据没有问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03a41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./cifar-10-python.tar.gz\n",
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 855 K \n",
      "-------------------------------------\n",
      "855 K     Trainable params\n",
      "0         Non-trainable params\n",
      "855 K     Total params\n",
      "3.420     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42e9b58af274a92a0cb3d0ac2de7233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af089aa433e4f6daa3a546a40313139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.4 s (started: 2021-09-01 18:14:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "dm = CIFAR10DataModule()\n",
    "model = LitModel(*dm.size(), dm.num_classes, hidden_size=256)\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=AVAIL_GPUS,\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909a0e1",
   "metadata": {},
   "source": [
    "# 恭喜 - 是时候加入社区了！\n",
    "\n",
    "恭喜您完成本笔记本教程！ 如果你喜欢这个并想加入闪电运动，你可以通过以下方式来做到！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01850f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
