{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7c8fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 424 ms (started: 2021-09-01 13:27:09 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff93789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n",
      "time: 2.35 ms (started: 2021-09-01 00:17:12 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf178f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook.start(\"--logdir ./lightning_logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13eeb38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main 1a4dd6f] 更新 #4 Aug 31, 2021\n",
      " 1 file changed, 97 insertions(+), 74 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:ustchope/pytorch_lightning_study.git\n",
      "   cf31512..1a4dd6f  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.81 s (started: 2021-08-31 23:42:49 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #4 Aug 31, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a000a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.64 ms (started: 2021-09-01 13:28:27 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e467618",
   "metadata": {},
   "source": [
    "本指南将带您了解 PyTorch Lightning 的核心部分。\n",
    "\n",
    "我们将完成以下工作：\n",
    "* 实现一个 MNIST 分类器。\n",
    "* 使用继承实现 AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea030123",
   "metadata": {},
   "source": [
    "> 任何 DL/ML PyTorch 项目都适合 Lightning 结构。 在这里，我们只专注于 3 种类型的研究来说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ae7c7",
   "metadata": {},
   "source": [
    "# 从 MNIST 到自动编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40104b0",
   "metadata": {},
   "source": [
    "## 研究代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f6cb2",
   "metadata": {},
   "source": [
    "### 模型\n",
    "\n",
    "闪电模块包含所有核心研究成分：\n",
    "* 该模型\n",
    "* 优化器\n",
    "* 训练/验证/测试步骤\n",
    "\n",
    "让我们首先从模型开始。 在这种情况下，我们将设计一个 3 层神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7ba2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.21 ms (started: 2021-09-01 13:27:22 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "\n",
    "\n",
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, height, width)\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 256)\n",
    "        self.layer_3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01ac2f",
   "metadata": {},
   "source": [
    "请注意，这是一个闪电模块，而不是 torch.nn.Module。 LightningModule 等效于纯 PyTorch 模块，只是它增加了功能。 但是，您可以像使用 PyTorch 模块一样使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71612b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.6 ms (started: 2021-08-31 21:54:52 +08:00)\n"
     ]
    }
   ],
   "source": [
    "net = LitMNIST()\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d91629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3127, -2.2126, -2.3196, -2.2438, -2.2116, -2.2051, -2.3613, -2.3832,\n",
       "         -2.3733, -2.4333]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.66 ms (started: 2021-08-31 21:55:31 +08:00)\n"
     ]
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea5b15",
   "metadata": {},
   "source": [
    "现在我们添加了包含所有训练循环逻辑的 training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e85d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb17e8",
   "metadata": {},
   "source": [
    "### 数据\n",
    "\n",
    "闪电在纯数据加载器上运行。 这是用于加载 MNIST 的 PyTorch 代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c159da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.8 ms (started: 2021-09-01 13:27:29 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# transforms\n",
    "# prepare transforms standard to MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# data\n",
    "mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "mnist_train = DataLoader(mnist_train, batch_size=64, num_workers = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49319b06",
   "metadata": {},
   "source": [
    "您可以通过 3 种方式使用 DataLoaders：\n",
    "\n",
    "1. 将 DataLoaders 传递给 .fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a4861",
   "metadata": {},
   "source": [
    "将数据加载器传递给 .fit() 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872af726",
   "metadata": {},
   "source": [
    "2. LightningModule 数据加载器\n",
    "\n",
    "对于快速的研究原型设计，将模型与数据加载器链接可能更容易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0021c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 767 µs (started: 2021-08-31 23:59:54 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    def train_dataloader(self):\n",
    "        # transforms\n",
    "        # prepare transforms standard to MNIST\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        # data\n",
    "        mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "        return DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transforms = ...\n",
    "        mnist_val = ...\n",
    "        return DataLoader(mnist_val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        transforms = ...\n",
    "        mnist_test = ...\n",
    "        return DataLoader(mnist_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930b662",
   "metadata": {},
   "source": [
    "DataLoaders 已经在模型中，不需要在 .fit() 上指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f03bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728ce80",
   "metadata": {},
   "source": [
    "3. DataModules（推荐）\n",
    "\n",
    "定义自由浮动的数据加载器、拆分、下载指令等可能会变得混乱。 在这种情况下，最好将数据集的完整定义分组到一个 DataModule 中，其中包括：\n",
    "* 下载说明\n",
    "* 加工说明\n",
    "* 拆分说明\n",
    "* 训练数据加载器\n",
    "* Val 数据加载器\n",
    "* 测试数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78054195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataModule(LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dims = None\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # 仅在 1 个 GPU 上调用\n",
    "        download_dataset()\n",
    "        tokenize()\n",
    "        build_vocab()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # 在每个 GPU 上调用\n",
    "        vocab = load_vocab()\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "        self.train, self.val, self.test = load_datasets()\n",
    "        self.train_dims = self.train.next_batch.size()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        transforms = ...\n",
    "        return DataLoader(self.test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124b051",
   "metadata": {},
   "source": [
    "使用 DataModules 可以更轻松地共享完整的数据集定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 MNIST 数据集\n",
    "mnist_dm = MNISTDatamodule()\n",
    "model = LitModel(num_classes=mnist_dm.num_classes)\n",
    "trainer.fit(model, mnist_dm)\n",
    "\n",
    "# 或具有相同模型的其他数据集\n",
    "imagenet_dm = ImagenetDatamodule()\n",
    "model = LitModel(num_classes=imagenet_dm.num_classes)\n",
    "trainer.fit(model, imagenet_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab805730",
   "metadata": {},
   "source": [
    "### 由数据定义的模型\n",
    "\n",
    "当您的模型需要了解数据时，最好在将数据传递给模型之前对其进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dm 并手动调用处理\n",
    "dm = ImagenetDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "model = LitModel(out_features=dm.num_classes, img_width=dm.img_width, img_height=dm.img_height)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aea0b8",
   "metadata": {},
   "source": [
    "* 使用 prepare_data() 下载和处理数据集。\n",
    "* 使用 setup() 进行拆分，并构建模型内部。\n",
    "\n",
    "使用 DataModule 的替代方法是将模型模块的初始化推迟到 LightningModule 的`setup`方法，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82209aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        self.l1 = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        download_data()\n",
    "        tokenize()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # 阶段是“fit”、“验证”、“测试”或“预测”。 90% 的时间不相关\n",
    "        data = load_data()\n",
    "        num_classes = data.classes\n",
    "        self.l1 = nn.Linear(..., num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d287422",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "接下来我们选择使用什么优化器来训练我们的系统。 在 PyTorch 中，我们这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60dc08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.12 ms (started: 2021-09-01 00:18:45 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(LitMNIST().parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4af9c7",
   "metadata": {},
   "source": [
    "在 Lightning 中，我们做同样的事情，但在 configure_optimizers() 方法下组织它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939f0c4",
   "metadata": {},
   "source": [
    "> LightningModule 本身有参数，所以传入 self.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb9d10",
   "metadata": {},
   "source": [
    "但是，如果您有多个优化器，请使用匹配参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b67cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.generator(), lr=1e-3), Adam(self.discriminator(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97ae5b",
   "metadata": {},
   "source": [
    "### 训练步骤\n",
    "\n",
    "训练步骤是在训练循环中发生的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs:\n",
    "    for batch in data:\n",
    "        # TRAINING STEP\n",
    "        # ....\n",
    "        # TRAINING STEP\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b55aed",
   "metadata": {},
   "source": [
    "在 MNIST 的情况下，我们执行以下操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs:\n",
    "    for batch in data:\n",
    "        # ------ TRAINING STEP START ------\n",
    "        x, y = batch\n",
    "        logits = model(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        # ------ TRAINING STEP END ------\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6123f83",
   "metadata": {},
   "source": [
    "在 Lightning 中，训练步骤中的所有内容都在 LightningModule 中的 training_step() 函数下组织。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d4675b",
   "metadata": {},
   "source": [
    "同样，这是相同的 PyTorch 代码，只是它是由 LightningModule 组织的。 此代码不受限制，这意味着它可以像完整的 seq-2-seq、RL 循环、GAN 等一样复杂……"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcda1d9",
   "metadata": {},
   "source": [
    "## 工程代码\n",
    "\n",
    "### 训练\n",
    "\n",
    "到目前为止，我们在纯 PyTorch 中定义了 4 个关键成分，但使用 LightningModule 组织代码。\n",
    "* 模型。\n",
    "* 训练数据。\n",
    "* 优化器。\n",
    "* 训练循环中会发生什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0297cf0",
   "metadata": {},
   "source": [
    "为清楚起见，我们会记得完整的 LightningModule 现在看起来像这样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3511dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 ms (started: 2021-09-01 00:18:42 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer_2 = nn.Linear(128, 256)\n",
    "        self.layer_3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389054a6",
   "metadata": {},
   "source": [
    "同样，这是相同的 PyTorch 代码，只是它由 LightningModule 组织。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83716574",
   "metadata": {},
   "source": [
    "### 日志记录\n",
    "\n",
    "要登录 Tensorboard、您最喜欢的记录器和/或进度条，请使用 log() 方法，该方法可以从 LightningModule 中的任何方法调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_metric\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8c135",
   "metadata": {},
   "source": [
    "log() 方法有几个选项：\n",
    "* on_step（记录训练中该步骤的指标）\n",
    "* on_epoch（在epoch结束时自动累积和记录）\n",
    "* prog_bar（记录到进度条）\n",
    "* logger（像 Tensorboard 一样记录到记录器）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea69eafe",
   "metadata": {},
   "source": [
    "根据调用日志的位置，Lightning 会自动为您确定正确的模式。 但是当然您可以通过手动设置标志来覆盖默认行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864b271",
   "metadata": {},
   "source": [
    "> 设置 on_epoch=True 将在整个训练时期累积您的记录值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489af9f2",
   "metadata": {},
   "source": [
    "您还可以直接使用记录器的任何方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c226226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    tensorboard = self.logger.experiment\n",
    "    tensorboard.any_summary_writer_method_you_want()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92508f",
   "metadata": {},
   "source": [
    "训练开始后，您可以使用自己喜欢的记录器或启动 Tensorboard 日志来查看日志："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a726595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343befc",
   "metadata": {},
   "source": [
    "这将生成自动tensorboard日志（或使用您选择的记录器）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd900f",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gu0bxe6t3vj612e0nktaw02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d81d1",
   "metadata": {},
   "source": [
    "但是您也可以使用我们支持的任何数量的其他记录器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcd008",
   "metadata": {},
   "source": [
    "### 在 CPU 上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "090838b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1292: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | layer_1 | Linear | 100 K \n",
      "1 | layer_2 | Linear | 33.0 K\n",
      "2 | layer_3 | Linear | 2.6 K \n",
      "-----------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d970840bdf4eec91842ababef90153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 48 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.1 s (started: 2021-09-01 00:18:57 +08:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = LitMNIST()\n",
    "trainer = Trainer(progress_bar_refresh_rate = 1)\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143e13b",
   "metadata": {},
   "source": [
    "### 在 GPU 上训练\n",
    "\n",
    "但最好的地方是你可以用trainer flag做的所有魔法。 例如，要在 GPU 上运行此模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a738b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | layer_1 | Linear | 100 K \n",
      "1 | layer_2 | Linear | 33.0 K\n",
      "2 | layer_3 | Linear | 2.6 K \n",
      "-----------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6db6f937c724b03bb90a998a29e8ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160><function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160><function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    \n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "          File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "      File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    \n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "AssertionError      File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'    can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160><function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()Exception ignored in:     \n",
      "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "        if w.is_alive():if w.is_alive():  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "            self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>    AssertionErrorAssertionError\n",
      "if w.is_alive():: : Traceback (most recent call last):\n",
      "\n",
      "can only test a child processcan only test a child process  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "Exception ignored in: \n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>self._shutdown_workers()    \n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>AssertionError\n",
      "        : Traceback (most recent call last):\n",
      "self._shutdown_workers()if w.is_alive():can only test a child process  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "\n",
      "\n",
      "      File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers()    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'      File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():AssertionError\n",
      "    :   File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():can only test a child process\n",
      "      File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160><function _MultiProcessingDataLoaderIter.__del__ at 0x7f522f7b1160>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Exception ignored in: <function _releaseLock at 0x7f52627bee50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/torch19/lib/python3.9/logging/__init__.py\", line 223, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2312129, 2312169, 2312209, 2312249, 2312289, 2312329, 2312369, 2312409, 2312449, 2312489, 2312529, 2312569, 2312609, 2312649, 2312689, 2312729, 2312769, 2312809, 2312849, 2312889, 2312929, 2312969) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3f3722a584f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLitMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# reset trainer on this loop and all child loops in case user connected a custom loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detected KeyboardInterrupt, attempting graceful shutdown...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mepoch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, dataloader_iter, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcanceled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m \u001b[0mreturning\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/profiler/base.py\u001b[0m in \u001b[0;36mprofile_iterable\u001b[0;34m(self, iterable, action_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mprefetch_iterator\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# the iterator may be empty from the beginning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \"\"\"\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mnext_fn\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mnext_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_fault_tolerant_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/torch19/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2312129, 2312169, 2312209, 2312249, 2312289, 2312329, 2312369, 2312409, 2312449, 2312489, 2312529, 2312569, 2312609, 2312649, 2312689, 2312729, 2312769, 2312809, 2312849, 2312889, 2312929, 2312969) exited unexpectedly"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 59min 52s (started: 2021-09-01 00:39:58 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer(gpus=1)\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2456b",
   "metadata": {},
   "source": [
    "### 在多 GPU 上训练\n",
    "\n",
    "或者，您也可以在多个 GPU 上进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45d3de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | layer_1 | Linear | 100 K \n",
      "1 | layer_2 | Linear | 33.0 K\n",
      "2 | layer_3 | Linear | 2.6 K \n",
      "-----------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e6620c505e44fa99d8f63422147aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.97 s (started: 2021-09-01 00:39:42 +08:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = Trainer(gpus=8, accelerator='dp')\n",
    "trainer.fit(model, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ee40a",
   "metadata": {},
   "source": [
    "或者多个节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db240d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (32 GPUs)\n",
    "model = LitMNIST()\n",
    "trainer = Trainer(gpus=8, num_nodes=4, accelerator=\"ddp\")\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b905d",
   "metadata": {},
   "source": [
    "## 超参数\n",
    "\n",
    "Lightning 具有与命令行 ArgumentParser 无缝交互的实用程序，并与您选择的超参数优化框架配合得很好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c11a2",
   "metadata": {},
   "source": [
    "### 参数解析器\n",
    "\n",
    "Lightning 旨在增强内置 Python ArgumentParser 的许多功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a89436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--layer_1_dim\", type=int, default=128)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcd06c",
   "metadata": {},
   "source": [
    "这允许您像这样调用您的程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1751d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python trainer.py --layer_1_dim 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130ce38",
   "metadata": {},
   "source": [
    "### Argparser 最佳实践\n",
    "\n",
    "最佳做法是将您的论点分为三个部分。\n",
    "1. 训练器参数（gpus、num_nodes 等...）\n",
    "2. 模型特定参数（layer_dim、num_layers、learning_rate 等...）\n",
    "3. 程序参数（data_path、cluster_email 等...）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2c5d4",
   "metadata": {},
   "source": [
    "我们可以这样做。 首先，在您的 LightningModule 中，定义特定于该模块的参数。 请记住，数据拆分或数据路径也可能特定于某个模块（即：如果您的项目有一个在 Imagenet 上训练的模型和另一个在 CIFAR-10 上训练的模型）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"LitModel\")\n",
    "        parser.add_argument(\"--encoder_layers\", type=int, default=12)\n",
    "        parser.add_argument(\"--data_path\", type=str, default=\"/some/path\")\n",
    "        return parent_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df914c73",
   "metadata": {},
   "source": [
    "现在，在您的主训练文件中，添加 Trainer args、程序 args，并添加模型 args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# trainer_main.py\n",
    "# ----------------\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "\n",
    "# 添加程序级参数\n",
    "parser.add_argument(\"--conda_env\", type=str, default=\"some_name\")\n",
    "parser.add_argument(\"--notification_email\", type=str, default=\"will@email.com\")\n",
    "\n",
    "# 添加特定于模型的参数\n",
    "parser = LitModel.add_model_specific_args(parser)\n",
    "\n",
    "# 将所有可用的训练器选项添加到 argparse\n",
    "# 即：现在 --gpus --num_nodes ... --fast_dev_run 在 cli 中的所有工作\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e73723",
   "metadata": {},
   "source": [
    "现在你可以像这样调用运行你的程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python trainer_main.py --gpus 2 --num_nodes 2 --conda_env 'my_env' --encoder_layers 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5348d",
   "metadata": {},
   "source": [
    "最后，确保像这样开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b94ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 像这样初始化训练器\n",
    "trainer = Trainer.from_argparse_args(args, early_stopping_callback=...)\n",
    "\n",
    "# 不喜欢这个\n",
    "trainer = Trainer(gpus=hparams.gpus, ...)\n",
    "\n",
    "# 直接用 Namespace 初始化模型\n",
    "model = LitModel(args)\n",
    "\n",
    "# 或使用所有键值对初始化模型\n",
    "dict_args = vars(args)\n",
    "model = LitModel(**dict_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9e46a",
   "metadata": {},
   "source": [
    "## LightningModule 超参数\n",
    "\n",
    "很多时候，我们训练一个模型的多个版本。 您可能会分享该模型或在几个月后再次使用该模型，此时了解该模型是如何训练的（即：什么学习率、神经网络等）非常有用。\n",
    "\n",
    "Lightning 有几种方法可以将这些信息保存在检查点和 yaml 文件中。 这里的目标是提高可读性和再现性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f381b4",
   "metadata": {},
   "source": [
    "1. 在 LightningModule `__init__` 函数中使用 `save_hyperparameters()` 将使 Lightning 能够将所有提供的参数存储在 `self.hparams` 属性中。 这些超参数也将存储在模型检查点中，这简化了生产设置中的模型重新实例化。 这也使这些值可以通过 `self.hparams`获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80106263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self, layer_1_dim=128, learning_rate=1e-2, **kwargs):\n",
    "        super().__init__()\n",
    "        # 调用它以将 (layer_1_dim=128, learning_rate=1e-4) 保存到检查点\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 相等的\n",
    "        self.save_hyperparameters(\"layer_1_dim\", \"learning_rate\")\n",
    "\n",
    "        # 现在可以从 hparams 访问 layer_1_dim\n",
    "        self.hparams.layer_1_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742c679",
   "metadata": {},
   "source": [
    "2. 有时，您的 init 可能具有您可能不想保存的对象或其他参数。 在这种情况下，只选择几个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99680939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self, loss_fx, generator_network, layer_1_dim=128 ** kwargs):\n",
    "        super().__init__()\n",
    "        self.layer_1_dim = layer_1_dim\n",
    "        self.loss_fx = loss_fx\n",
    "\n",
    "        # 调用它以将 (layer_1_dim=128) 保存到检查点\n",
    "        self.save_hyperparameters(\"layer_1_dim\")\n",
    "\n",
    "\n",
    "#加载指定其他参数\n",
    "model = LitMNIST.load_from_checkpoint(PATH, loss_fx=torch.nn.SomeOtherLoss, generator_network=MyGenerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530ff77",
   "metadata": {},
   "source": [
    "3. 您还可以将 dict 或 Namespace 等完整对象转换为 hparams，以便将它们保存到检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ece84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self, conf: Optional[Union[Dict, Namespace, DictConfig]] = None, **kwargs):\n",
    "        super().__init__()\n",
    "        # save the config and any extra arguments\n",
    "        self.save_hyperparameters(conf)\n",
    "        self.save_hyperparameters(kwargs)\n",
    "\n",
    "        self.layer_1 = nn.Linear(28 * 28, self.hparams.layer_1_dim)\n",
    "        self.layer_2 = nn.Linear(self.hparams.layer_1_dim, self.hparams.layer_2_dim)\n",
    "        self.layer_3 = nn.Linear(self.hparams.layer_2_dim, 10)\n",
    "\n",
    "\n",
    "conf = {...}\n",
    "# OR\n",
    "# conf = parser.parse_args()\n",
    "# OR\n",
    "# conf = OmegaConf.create(...)\n",
    "model = LitMNIST(conf=conf, anything=10)\n",
    "\n",
    "# 现在可以从 hparams 访问任何存储的变量\n",
    "model.hparams.anything\n",
    "\n",
    "# 为此，您需要使用 `self.hparams.layer_1_dim` 访问，而不是 `conf.layer_1_dim`\n",
    "model = LitMNIST.load_from_checkpoint(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d1b0c",
   "metadata": {},
   "source": [
    "### 训练器参数\n",
    "\n",
    "回顾一下，将所有可能的训练器标志添加到 argparser 并以这种方式初始化训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9353ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "hparams = parser.parse_args()\n",
    "\n",
    "trainer = Trainer.from_argparse_args(hparams)\n",
    "\n",
    "#或者如果您需要传入回调\n",
    "trainer = Trainer.from_argparse_args(hparams, checkpoint_callback=..., callbacks=[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7d839",
   "metadata": {},
   "source": [
    "### 多个闪电模块\n",
    "\n",
    "我们经常有多个闪电模块，每个模块都有不同的参数。 LightningModule 允许您为每个文件定义参数，而不是污染 main.py 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def __init__(self, layer_1_dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(28 * 28, layer_1_dim)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"LitMNIST\")\n",
    "        parser.add_argument(\"--layer_1_dim\", type=int, default=128)\n",
    "        return parent_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf010006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodGAN(LightningModule):\n",
    "    def __init__(self, encoder_layers, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(layers=encoder_layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"GoodGAN\")\n",
    "        parser.add_argument(\"--encoder_layers\", type=int, default=12)\n",
    "        return parent_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb15f9",
   "metadata": {},
   "source": [
    "现在我们可以允许每个模型在 main.py 中注入它需要的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    dict_args = vars(args)\n",
    "\n",
    "    # pick model\n",
    "    if args.model_name == \"gan\":\n",
    "        model = GoodGAN(**dict_args)\n",
    "    elif args.model_name == \"mnist\":\n",
    "        model = LitMNIST(**dict_args)\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(args)\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser = Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # figure out which model to use\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"gan\", help=\"gan or mnist\")\n",
    "\n",
    "    # THIS LINE IS KEY TO PULL THE MODEL NAME\n",
    "    temp_args, _ = parser.parse_known_args()\n",
    "\n",
    "    # let the model add what it wants\n",
    "    if temp_args.model_name == \"gan\":\n",
    "        parser = GoodGAN.add_model_specific_args(parser)\n",
    "    elif temp_args.model_name == \"mnist\":\n",
    "        parser = LitMNIST.add_model_specific_args(parser)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # train\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70873b9d",
   "metadata": {},
   "source": [
    "现在我们可以使用命令行界面训练 MNIST 或 GAN！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python main.py --model_name gan --encoder_layers 24\n",
    "$ python main.py --model_name mnist --layer_1_dim 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20b6ee",
   "metadata": {},
   "source": [
    "## Validating\n",
    "\n",
    "在大多数情况下，当数据验证拆分的性能达到最小值时，我们会停止训练模型。\n",
    "\n",
    "就像 training_step 一样，我们可以定义一个 validation_step 来检查我们关心的任何指标、生成样本或向日志中添加更多指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    loss = MSE_loss(...)\n",
    "    self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025ff3a",
   "metadata": {},
   "source": [
    "现在我们也可以使用验证循环进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf563de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = LitMNIST()\n",
    "trainer = Trainer(tpu_cores=8)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209b3fe",
   "metadata": {},
   "source": [
    "您可能已经注意到记录的“验证健全性检查”字样。 这是因为 Lightning 在开始训练之前运行了 2 批验证。 这是一种单元测试，以确保如果您在验证循环中有错误，您无需等待一个完整的 epoch 才能找出答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90572755",
   "metadata": {},
   "source": [
    "> Lightning 禁用梯度，将模型置于评估模式，并执行验证所需的一切。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46610c",
   "metadata": {},
   "source": [
    "### 引擎盖下的 Val 循环\n",
    "\n",
    "在幕后，Lightning 执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "for epoch in epochs:\n",
    "    for batch in data:\n",
    "        # train\n",
    "        ...\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    outputs = []\n",
    "    for batch in val_data:\n",
    "        x, y = batch  # validation_step\n",
    "        y_hat = model(x)  # validation_step\n",
    "        loss = loss(y_hat, x)  # validation_step\n",
    "        outputs.append({\"val_loss\": loss})  # validation_step\n",
    "\n",
    "    total_loss = outputs.mean()  # validation_epoch_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e1329",
   "metadata": {},
   "source": [
    "### 可选方法\n",
    "\n",
    "如果您仍然需要更细粒度的控制，请为循环定义其他可选方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    preds = ...\n",
    "    return preds\n",
    "\n",
    "\n",
    "def validation_epoch_end(self, val_step_outputs):\n",
    "    for pred in val_step_outputs:\n",
    "        # do something with all the predictions from each validation_step\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481dbeb1",
   "metadata": {},
   "source": [
    "## 测试\n",
    "\n",
    "一旦我们的研究完成并且我们即将发布或部署一个模型，我们通常想弄清楚它如何在“现实世界”中推广。 为此，我们使用保留的数据拆分进行测试。\n",
    "\n",
    "就像验证循环一样，我们定义了一个测试循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log(\"test_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d6519",
   "metadata": {},
   "source": [
    "但是，为了确保不会无意中使用测试集，Lightning 有一个单独的 API 来运行测试。 训练模型后，只需调用 .test()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d850b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = LitMNIST()\n",
    "trainer = Trainer(tpu_cores=8)\n",
    "trainer.fit(model)\n",
    "\n",
    "# run test set\n",
    "result = trainer.test()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59ec5f",
   "metadata": {},
   "source": [
    "您还可以从保存的闪电模型运行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST.load_from_checkpoint(PATH)\n",
    "trainer = Trainer(tpu_cores=8)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c155dc6",
   "metadata": {},
   "source": [
    "## 预测\n",
    "\n",
    "同样，LightningModule 与 PyTorch 模块完全相同。 这意味着您可以加载它并将其用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43692601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNIST.load_from_checkpoint(PATH)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9b227",
   "metadata": {},
   "source": [
    "从表面上看，forward 和 training_step 是类似的。 通常，我们要确保我们希望模型做的事情是在前进中发生的事情。 而 training_step 可能从它内部调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38aa4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(LightningModule):\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier()\n",
    "x = mnist_image()\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ee209",
   "metadata": {},
   "source": [
    "在这种情况下，我们设置了这个 LightningModel 来预测 logits。 但我们也可以让它预测特征图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTRepresentator(LightningModule):\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.layer_1(x)\n",
    "        x1 = F.relu(x)\n",
    "        x = self.layer_2(x1)\n",
    "        x2 = F.relu(x)\n",
    "        x3 = self.layer_3(x2)\n",
    "        return [x, x1, x2, x3]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out, l1_feats, l2_feats, l3_feats = self(x)\n",
    "        logits = F.log_softmax(out, dim=1)\n",
    "        ce_loss = F.nll_loss(logits, y)\n",
    "        loss = perceptual_loss(l1_feats, l2_feats, l3_feats) + ce_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9360f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTRepresentator.load_from_checkpoint(PATH)\n",
    "x = mnist_image()\n",
    "feature_maps = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0da5d4",
   "metadata": {},
   "source": [
    "或者也许我们有一个用于生成的模型。 LightningModule 也只是一个 torch.nn.Module。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb404499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTDreamer(LightningModule):\n",
    "    def forward(self, z):\n",
    "        imgs = self.decoder(z)\n",
    "        return imgs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        representation = self.encoder(x)\n",
    "        imgs = self(representation)\n",
    "\n",
    "        loss = perceptual_loss(imgs, x)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitMNISTDreamer.load_from_checkpoint(PATH)\n",
    "z = sample_noise()\n",
    "generated_imgs = model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c54146",
   "metadata": {},
   "source": [
    "要大规模执行推理，可以使用 predict() 和 predict_step() 默认情况下，predict_step() 调用 forward()，但可以覆盖它以添加任何处理逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTDreamer(LightningModule):\n",
    "    def forward(self, z):\n",
    "        imgs = self.decoder(z)\n",
    "        return imgs\n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = None):\n",
    "        return self(batch)\n",
    "\n",
    "\n",
    "model = LitMNISTDreamer()\n",
    "trainer.predict(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c548",
   "metadata": {},
   "source": [
    "您如何拆分 forward() 与 training_step() 与 predict_step() 中的内容取决于您希望如何使用此模型进行预测。 但是，我们建议 forward() 仅包含您的模型的张量操作。 training_step() 用日志记录、指标和损失计算封装 forward() 逻辑。 predict_step() 用任何必要的预处理或后处理函数封装 forward()。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc88bff",
   "metadata": {},
   "source": [
    "## 非关键环节"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c77f9",
   "metadata": {},
   "source": [
    "### 可扩展性\n",
    "\n",
    "尽管闪电让一切变得超级简单，但它并没有牺牲任何灵活性或控制力。 Lightning 提供了多种管理训练状态的方法。\n",
    "\n",
    "### 训练覆盖\n",
    "\n",
    "训练、验证和测试循环的任何部分都可以修改。 例如，如果您想进行自己的向后传递，则可以覆盖默认实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87949d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, use_amp, loss, optimizer):\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3d6fd",
   "metadata": {},
   "source": [
    "用你自己的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def backward(self, use_amp, loss, optimizer, optimizer_idx):\n",
    "        # do a custom way of backward\n",
    "        loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43ffeb",
   "metadata": {},
   "source": [
    "训练的每个部分都可以通过这种方式进行配置。 有关完整列表，请查看 LightningModule。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3ba8c",
   "metadata": {},
   "source": [
    "### 回调\n",
    "\n",
    "添加任意功能的另一种方法是为您可能关心的钩子添加自定义回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class MyPrintingCallback(Callback):\n",
    "    def on_init_start(self, trainer):\n",
    "        print(\"Starting to init trainer!\")\n",
    "\n",
    "    def on_init_end(self, trainer):\n",
    "        print(\"Trainer is init now\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"do something when training ends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dff28d",
   "metadata": {},
   "source": [
    "并将回调传递给训练器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a3cb6",
   "metadata": {},
   "source": [
    "### 子模块\n",
    "\n",
    "研究项目倾向于测试针对同一数据集的不同方法。 这在带有继承的 Lightning 中很容易做到。\n",
    "\n",
    "例如，假设我们现在想要训练一个自动编码器用作 MNIST 图像的特征提取器。 我们正在从 LitMNIST 模块扩展我们的自动编码器，该模块已经定义了所有数据加载。 Autoencoder 模型中唯一改变的是初始化、转发、训练、验证和测试步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74cddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.7 ms (started: 2021-09-01 13:27:38 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AutoEncoder(LitMNIST):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.metric = MSE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        representation = self.encoder(x)\n",
    "        x_hat = self.decoder(representation)\n",
    "\n",
    "        loss = self.metric(x, x_hat)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, prefix):\n",
    "        x, _ = batch\n",
    "        representation = self.encoder(x)\n",
    "        x_hat = self.decoder(representation)\n",
    "\n",
    "        loss = self.metric(x, x_hat)\n",
    "        self.log(f\"{prefix}_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5535d6b",
   "metadata": {},
   "source": [
    "我们可以使用同一个训练器来训练它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "trainer = Trainer(gpus=1, max_epochs=10)\n",
    "trainer.fit(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5025d8",
   "metadata": {},
   "source": [
    "请记住，forward 方法应该定义 LightningModule 的实际用途。 在这种情况下，我们想使用 AutoEncoder 来提取图像表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images = torch.Tensor(32, 1, 28, 28)\n",
    "representations = autoencoder(some_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d440dae",
   "metadata": {},
   "source": [
    "## 迁移学习\n",
    "\n",
    "### 使用预训练模型\n",
    "\n",
    "有时我们想使用 LightningModule 作为预训练模型。 这很好，因为 LightningModule 只是一个 torch.nn.Module！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fe554",
   "metadata": {},
   "source": [
    "让我们在单独的模型中使用 AutoEncoder 作为特征提取器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c6c91",
   "metadata": {},
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    ...\n",
    "\n",
    "\n",
    "class AutoEncoder(LightningModule):\n",
    "    def __init__(self):\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "\n",
    "class CIFAR10Classifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        # init the pretrained LightningModule\n",
    "        self.feature_extractor = AutoEncoder.load_from_checkpoint(PATH)\n",
    "        self.feature_extractor.freeze()\n",
    "\n",
    "        # the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes\n",
    "        self.classifier = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        representations = self.feature_extractor(x)\n",
    "        x = self.classifier(representations)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75093a8d",
   "metadata": {},
   "source": [
    "我们使用预训练的自动编码器（LightningModule）进行迁移学习！\n",
    "\n",
    "示例：Imagenet（计算机视觉）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class ImagenetTransferLearning(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # init a pretrained resnet\n",
    "        backbone = models.resnet50(pretrained=True)\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "\n",
    "        # use the pretrained model to classify cifar-10 (10 image classes)\n",
    "        num_target_classes = 10\n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        x = self.classifier(representations)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcef8c",
   "metadata": {},
   "source": [
    "微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bce63",
   "metadata": {},
   "source": [
    "并用它来预测您感兴趣的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621190c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImagenetTransferLearning.load_from_checkpoint(PATH)\n",
    "model.freeze()\n",
    "\n",
    "x = some_images_from_cifar10()\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ed7ed",
   "metadata": {},
   "source": [
    "我们在 imagenet 上使用了预训练模型，在 CIFAR-10 上进行了微调，以在 CIFAR-10 上进行预测。 在非学术界，我们会在你拥有的一个小数据集上进行微调，并在你的数据集上进行预测。\n",
    "\n",
    "示例：BERT (NLP)\n",
    "\n",
    "只要它是 torch.nn.Module 子类，Lightning 与用于迁移学习的内容完全无关。\n",
    "\n",
    "这是一个使用 Huggingface Transformer 的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMNLIFinetuner(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-cased\", output_attentions=True)\n",
    "        self.W = nn.Linear(bert.config.hidden_size, 3)\n",
    "        self.num_classes = 3\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "\n",
    "        h, _, attn = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        h_cls = h[:, 0]\n",
    "        logits = self.W(h_cls)\n",
    "        return logits, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331dcbd",
   "metadata": {},
   "source": [
    "## 为什么使用 PyTorch 闪电\n",
    "\n",
    "1. 更少的样板\n",
    "\n",
    "研究和生产代码从简单的代码开始，但一旦添加 GPU 训练、16 位、检查点、日志记录等，复杂性就会迅速增加……\n",
    "\n",
    "PyTorch Lightning 为您实现了这些功能，并对其进行了严格的测试，以确保您可以专注于研究想法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf2b9b7",
   "metadata": {},
   "source": [
    "编写更少的工程/样板代码意味着：\n",
    "* 更少的错误\n",
    "* 更快的迭代\n",
    "* 更快的原型设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe531c",
   "metadata": {},
   "source": [
    "2. 更多功能\n",
    "\n",
    "在 PyTorch Lightning 中，您可以利用来自世界顶级 AI 实验室的数百名 AI 研究人员、研究工程师和博士编写的代码，实现所有最新的最佳实践和 SOTA 功能，例如\n",
    "* GPU、多 GPU、TPU 训练\n",
    "* 多节点训练\n",
    "* 自动记录\n",
    "* …\n",
    "* 梯度积累"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d6a10",
   "metadata": {},
   "source": [
    "3. 不易出错\n",
    "\n",
    "为什么要重新发明轮子？\n",
    "\n",
    "使用 PyTorch Lightning 享受深度学习结构，该结构在每次拉取请求时都经过 CPU/多 GPU/多 TPU 的严格测试（500 多次测试）。\n",
    "\n",
    "我们承诺，我们来自顶级实验室的 20 多名集体团队比您更考虑培训:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae294753",
   "metadata": {},
   "source": [
    "4. 不是新库\n",
    "\n",
    "PyTorch Lightning 是有组织的 PyTorch - 无需学习新框架。\n",
    "\n",
    "在此处了解如何从 PyTorch 转换为 Lightning。\n",
    "\n",
    "您的项目将变得越来越复杂，最终您将更多地进行工程而不是尝试新想法……将最困难的部分推迟到 Lightning！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ef629",
   "metadata": {},
   "source": [
    "## Lightning哲学\n",
    "\n",
    "Lightning 将您的深度学习代码分为 4 部分：\n",
    "* 研究代码\n",
    "* 工程代码\n",
    "* 非关键代码\n",
    "* 数据代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9db344",
   "metadata": {},
   "source": [
    "### 研究代码\n",
    "\n",
    "在 MNIST 生成示例中，研究代码将是特定系统及其训练方式（即：GAN 或 VAE 或 GPT）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d351daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Linear(...)\n",
    "l2 = nn.Linear(...)\n",
    "decoder = Decoder()\n",
    "\n",
    "x1 = l1(x)\n",
    "x2 = l2(x2)\n",
    "out = decoder(features, x)\n",
    "\n",
    "loss = perceptual_loss(x1, x2, x) + CE(out, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5e405",
   "metadata": {},
   "source": [
    "在 Lightning 中，此代码被组织成一个 Lightning 模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9391a",
   "metadata": {},
   "source": [
    "### 工程代码\n",
    "\n",
    "工程代码是与训练该系统相关的所有代码。 诸如提前停止、GPU 分布、16 位精度等。这通常是大多数项目中相同的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deef9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda(0)\n",
    "x = x.cuda(0)\n",
    "\n",
    "distributed = DistributedParallel(model)\n",
    "\n",
    "with gpu_zero:\n",
    "    download_data()\n",
    "\n",
    "dist.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d840e",
   "metadata": {},
   "source": [
    "在 Lightning 中，这段代码是由训练器抽象出来的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba6890",
   "metadata": {},
   "source": [
    "### 非关键代码\n",
    "\n",
    "这是有助于研究但与研究代码无关的代码。 一些例子可能是：\n",
    "* 检查梯度\n",
    "* 登录到tensorboard。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log samples\n",
    "z = Q.rsample()\n",
    "generated = decoder(z)\n",
    "self.experiment.log(\"images\", generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bfdd9",
   "metadata": {},
   "source": [
    "### 数据代码\n",
    "\n",
    "Lightning 使用标准的 PyTorch DataLoaders 或任何提供一批数据的东西。 这段代码最终会因转换、规范化常量和分布在整个文件中的数据拆分而变得混乱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb189a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train = MNIST(...)\n",
    "train, val = split(train, val)\n",
    "test = MNIST(...)\n",
    "\n",
    "# transforms\n",
    "train_transforms = ...\n",
    "val_transforms = ...\n",
    "test_transforms = ...\n",
    "\n",
    "# dataloader ...\n",
    "# download with dist.barrier() for multi-gpu, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd855fdf",
   "metadata": {},
   "source": [
    "一旦您开始进行多 GPU 训练或需要有关数据的信息来构建模型，此代码就会变得特别复杂。\n",
    "\n",
    "在 Lightning 中，此代码组织在数据模块内。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
