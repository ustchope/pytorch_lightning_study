{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d7ff35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.1 ms (started: 2021-09-02 13:29:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083b6a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main e4b8052] 更新 #3 Sept 02, 2021\n",
      " 2 files changed, 12 insertions(+)\n",
      " create mode 100644 \"Lightning-Bolts/.ipynb_checkpoints/\\346\\234\\252\\345\\221\\275\\345\\220\\215-checkpoint.ipynb\"\n",
      " create mode 100644 \"Lightning-Bolts/\\346\\234\\252\\345\\221\\275\\345\\220\\215.ipynb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:ustchope/pytorch_lightning_study.git\n",
      "   5e5af48..e4b8052  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.84 s (started: 2021-09-02 09:24:18 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #3 Sept 02, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694b308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.7 ms (started: 2021-09-02 13:29:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "from pytorch_lightning import LightningModule, seed_everything, Trainer, LightningDataModule\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from torchmetrics.functional import accuracy\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed_everything(7)\n",
    "\n",
    "PATH_DATASETS = os.environ.get('PATH_DATASETS', '.')\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb669c7",
   "metadata": {},
   "source": [
    "**介绍指南**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399d032",
   "metadata": {},
   "source": [
    "欢迎使用 PyTorch Lightning Bolts！\n",
    "\n",
    "Bolts 是一个深度学习研究和生产工具箱：\n",
    "* SOTA 预训练模型。\n",
    "* 模型组件。\n",
    "* 回调。\n",
    "* 损失。\n",
    "* 数据集。\n",
    "\n",
    "**Bolts 的主要目标是尽可能快地尝试新想法！**\n",
    "\n",
    "所有模型都经过（每天）测试、基准测试、记录并在 CPU、TPU、GPU 和 16 位精度上工作。\n",
    "\n",
    "一些例子！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edbb1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.6 ms (started: 2021-09-02 09:26:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.models import VAE\n",
    "from pl_bolts.models.vision import GPT2, ImageGPT, PixelCNN\n",
    "from pl_bolts.models.self_supervised import AMDIM, CPC_v2, SimCLR, Moco_v2\n",
    "from pl_bolts.models import LinearRegression, LogisticRegression\n",
    "from pl_bolts.models.gans import GAN\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "from pl_bolts.datamodules import FashionMNISTDataModule, CIFAR10DataModule, ImagenetDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb4fc8",
   "metadata": {},
   "source": [
    "**Bolts 是为快速的想法迭代而构建的 - 子类化、覆盖和训练！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.vision import ImageGPT\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "class VideoGPT(ImageGPT):\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = _shape_input(x)\n",
    "\n",
    "        logits = self.gpt(x)\n",
    "        simclr_features = self.simclr(x)\n",
    "\n",
    "        # -----------------\n",
    "        # do something new with GPT logits + simclr_features\n",
    "        # -----------------\n",
    "\n",
    "        loss = self.criterion(logits.view(-1, logits.size(-1)), x.view(-1).long())\n",
    "\n",
    "        logs = {\"loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": logs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58252cc1",
   "metadata": {},
   "source": [
    "随意混合和匹配数据、模块和组件！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(datamodule=ImagenetDataModule(PATH))\n",
    "model = GAN(datamodule=FashionMNISTDataModule(PATH))\n",
    "model = ImageGPT(datamodule=FashionMNISTDataModule(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ab120",
   "metadata": {},
   "source": [
    "并在任何硬件加速器上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "model = ImageGPT(datamodule=FashionMNISTDataModule(PATH))\n",
    "\n",
    "# cpus\n",
    "pl.Trainer.fit(model)\n",
    "\n",
    "# gpus\n",
    "pl.Trainer(gpus=8).fit(model)\n",
    "\n",
    "# tpus\n",
    "pl.Trainer(tpu_cores=8).fit(model)model = ImageGPT()\n",
    "Trainer().fit(\n",
    "    model,\n",
    "    train_dataloader=DataLoader(...),\n",
    "    val_dataloader=DataLoader(...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d1b22",
   "metadata": {},
   "source": [
    "或传入您选择的任何数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fe555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageGPT()\n",
    "\n",
    "Trainer().fit(\n",
    "    model,\n",
    "    train_dataloader=DataLoader(...),\n",
    "    val_dataloader=DataLoader(...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba208f8f",
   "metadata": {},
   "source": [
    "## 社区建设\n",
    "\n",
    "然后闪电社区构建螺栓并将它们贡献给螺栓。 闪电团队保证贡献是：\n",
    "* 经过严格测试（CPU、GPU、TPU）。\n",
    "* 有据可查。\n",
    "* 通过 PyTorch 闪电标准化。\n",
    "* 针对速度进行了优化。\n",
    "* 检查正确性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673222f8",
   "metadata": {},
   "source": [
    "# 何时使用Blots\n",
    "\n",
    "## 对于预训练模型\n",
    "\n",
    "大多数螺栓都有在各种数据集或算法上训练的预训练权重。 当您没有足够的数据、时间或金钱来进行自己的培训时，这很有用。\n",
    "\n",
    "例如，您可以使用预训练的 VAE 为图像数据集生成特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "from pl_bolts.models.self_supervised import CPC_v2\n",
    "\n",
    "model1 = VAE(input_height=32, pretrained='imagenet2012')\n",
    "encoder = model1.encoder\n",
    "encoder.eval()\n",
    "\n",
    "# bolts are pretrained on different datasets\n",
    "model2 = CPC_v2(encoder='resnet18', pretrained='imagenet128').freeze()\n",
    "model3 = CPC_v2(encoder='resnet18', pretrained='stl10').freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac593244",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in own_data:\n",
    "    features = encoder(x)\n",
    "    feat2 = model2(x)\n",
    "    feat3 = model3(x)\n",
    "\n",
    "# which is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60253536",
   "metadata": {},
   "source": [
    "## 微调您的数据\n",
    "\n",
    "如果您有自己的数据，微调通常可以提高性能。 由于这是纯 PyTorch，您可以使用您喜欢的任何微调协议。\n",
    "\n",
    "示例 1：解冻的微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e445ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfrozen finetune\n",
    "model = CPC_v2(encoder='resnet18', pretrained='imagenet128')\n",
    "resnet18 = model.encoder\n",
    "# don't call .freeze()\n",
    "\n",
    "classifier = LogisticRegression(...)\n",
    "\n",
    "for (x, y) in own_data:\n",
    "    feats = resnet18(x)\n",
    "    y_hat = classifier(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add67324",
   "metadata": {},
   "source": [
    "示例 2：先冻结再解冻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREEZE!\n",
    "model = CPC_v2(encoder='resnet18', pretrained='imagenet128')\n",
    "resnet18 = model.encoder\n",
    "resnet18.eval()\n",
    "\n",
    "classifier = LogisticRegression(...)\n",
    "\n",
    "for epoch in epochs:\n",
    "    for (x, y) in own_data:\n",
    "        feats = resnet18(x)\n",
    "        y_hat = classifier(feats)\n",
    "        loss = cross_entropy_with_logits(y_hat, y)\n",
    "\n",
    "    # UNFREEZE after 10 epochs\n",
    "    if epoch == 10:\n",
    "        resnet18.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e61ed0",
   "metadata": {},
   "source": [
    "## 研究用\n",
    "\n",
    "这是 bolts 与其他带有模型的库非常不同的地方。 它不仅是为生产而设计的，而且每个模块都经过编写，可以轻松扩展以进行研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.vision import ImageGPT\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "class VideoGPT(ImageGPT):\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = _shape_input(x)\n",
    "\n",
    "        logits = self.gpt(x)\n",
    "        simclr_features = self.simclr(x)\n",
    "\n",
    "        # -----------------\n",
    "        # do something new with GPT logits + simclr_features\n",
    "        # -----------------\n",
    "\n",
    "        loss = self.criterion(logits.view(-1, logits.size(-1)), x.view(-1).long())\n",
    "\n",
    "        logs = {\"loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": logs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a1988",
   "metadata": {},
   "source": [
    "或者，您的研究是在 self_supervised_learning 中，并且您想要做一个新的 SimCLR。 在这种情况下，您唯一想要改变的就是损失。\n",
    "\n",
    "通过子类化，您可以专注于更改系统的单个部分，而不必担心其他部分会起作用（因为如果它们在 Bolt 中，那么它们会起作用并且我们已经对其进行了测试）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19043b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass SimCLR and change ONLY what you want to try\n",
    "class ComplexCLR(SimCLR):\n",
    "\n",
    "    def init_loss(self):\n",
    "        return self.new_xent_loss\n",
    "\n",
    "    def new_xent_loss(self):\n",
    "        out = torch.cat([out_1, out_2], dim=0) n_samples = len(out)\n",
    "\n",
    "        # Full similarity matrix\n",
    "        cov = torch.mm(out, out.t().contiguous())\n",
    "        sim = torch.exp(cov / temperature)\n",
    "\n",
    "        # Negative similarity\n",
    "        mask = ~torch.eye(n_samples, device=sim.device).bool()\n",
    "        neg = sim.masked_select(mask).view(n_samples, -1).sum(dim=-1)\n",
    "\n",
    "        # ------------------\n",
    "        # some new thing we want to do\n",
    "        # ------------------\n",
    "\n",
    "        # Positive similarity :\n",
    "        pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "        pos = torch.cat([pos, pos], dim=0)\n",
    "        loss = -torch.log(pos / neg).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60391791",
   "metadata": {},
   "source": [
    "# 回调\n",
    "\n",
    "回调是任意程序，可以在 Lightning 的训练循环中的任何时间点运行。\n",
    "\n",
    "Bolts 包含一组社区贡献的回调，可以在任何 Lightning 模块中工作！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[PrintTableMetricsCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa15a6",
   "metadata": {},
   "source": [
    "## 信息回调\n",
    "\n",
    "这些回调在训练期间提供了各种有用的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebe621",
   "metadata": {},
   "source": [
    "### 打印表指标\n",
    "\n",
    "此回调将训练指标打印到表格中。 出于速度目的，它非常简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "\n",
    "callback = PrintTableMetricsCallback()\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[callback])\n",
    "trainer.fit(...)\n",
    "\n",
    "# ------------------------------\n",
    "# at the end of every epoch it will print\n",
    "# ------------------------------\n",
    "\n",
    "# loss│train_loss│val_loss│epoch\n",
    "# ──────────────────────────────\n",
    "# 2.2541470527648926│2.2541470527648926│2.2158432006835938│0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dc59c",
   "metadata": {},
   "source": [
    "### LightningModule 中的数据监控\n",
    "\n",
    "数据监控回调允许您记录和检查通过训练步骤和模型层的数据分布。 当与支持的记录器结合使用时，TrainingDataMonitor 为 training_step() 中的每个批次输入创建直方图并将其发送到记录器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import TrainingDataMonitor\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# 记录发送到 LightningModule.training_step 的输入数据的直方图\n",
    "monitor = TrainingDataMonitor(log_every_n_steps=25)\n",
    "\n",
    "model = YourLightningModule()\n",
    "trainer = Trainer(callbacks=[monitor])\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5072e2",
   "metadata": {},
   "source": [
    "第二个更高级的 ModuleDataMonitor 回调跟踪通过模型本身及其子模块的数据的直方图，即它跟踪所有 .forward() 调用并注册输入和输出。 您可以跟踪所有或仅跟踪一部分子模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import ModuleDataMonitor\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# log the in- and output histograms of LightningModule's `forward`\n",
    "monitor = ModuleDataMonitor()\n",
    "\n",
    "# LightningModule 中的所有子模块\n",
    "monitor = ModuleDataMonitor(submodules=True)\n",
    "\n",
    "# specific submodules\n",
    "monitor = ModuleDataMonitor(submodules=[\"generator\", \"generator.conv1\"])\n",
    "\n",
    "model = YourLightningModule()\n",
    "trainer = Trainer(callbacks=[monitor])\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2847b82",
   "metadata": {},
   "source": [
    "这对于调试复杂模型中的数据流和识别数值不稳定性特别有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c95d6",
   "metadata": {},
   "source": [
    "### 模型验证\n",
    "\n",
    "批量优化的梯度检查\n",
    "\n",
    "一批样本的梯度下降不仅有利于优化，还可以利用数据并行性。 但是，必须注意不要在批次维度上混合数据。 只有在重塑或排列操作中的一个小错误会导致优化卡住，你甚至不会得到运行时错误。 如何判断模型是否在批次中混合了数据？ 一个简单的技巧是执行以下操作：\n",
    "* 在示例批次上运行模型（可以是随机数据）\n",
    "* 获取输出批次并选择第 n 个样本（选择 n）\n",
    "* 仅计算该样本的虚拟损失值并计算整个输入批次的梯度\n",
    "* 观察到只有输入批次中的第 i 个样本具有非零梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5d1c5",
   "metadata": {},
   "source": [
    "如果批次中其他样本的梯度不为零，则意味着模型的前向传递正在混合数据！ BatchGradientVerificationCallback 在训练开始之前为您完成所有这些工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pl_bolts.callbacks import BatchGradientVerificationCallback\n",
    "\n",
    "model = YourLightningModule()\n",
    "verification = BatchGradientVerificationCallback()\n",
    "trainer = Trainer(callbacks=[verification])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f2e42",
   "metadata": {},
   "source": [
    "如果检测到批次内的数据混合，此回调将使用以下消息警告用户："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your model is mixing data across the batch dimension.\n",
    "This can lead to wrong gradient updates in the optimizer.\n",
    "Check the operations that reshape and permute tensor dimensions in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421188df",
   "metadata": {},
   "source": [
    "也可以使用适用于任何 PyTorch 模块的非回调版本 BatchGradientVerification："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ea0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils import BatchGradientVerification\n",
    "\n",
    "model = YourPyTorchModel()\n",
    "verification = BatchGradientVerification(model)\n",
    "valid = verification.check(input_array=torch.rand(2, 3, 4), sample_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f2377",
   "metadata": {},
   "source": [
    "在这个例子中，我们通过检查第二个样本的梯度，在批量大小 2 上运行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc45b80",
   "metadata": {},
   "source": [
    "## 自我监督的回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49497b13",
   "metadata": {},
   "source": [
    "自监督学习模型的有用回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab75b1",
   "metadata": {},
   "source": [
    "### BYOLMA权重更新\n",
    "\n",
    "来自 Bootstrap Your Own Latent (BYOL) 的指数移动平均权重更新规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型必须有 2 个属性\n",
    "model = Model()\n",
    "model.online_network = ...\n",
    "model.target_network = ...\n",
    "\n",
    "trainer = Trainer(callbacks=[BYOLMAWeightUpdate()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c3ef5a",
   "metadata": {},
   "source": [
    "### SSL在线评估器\n",
    "\n",
    "附加 MLP 以对给定模型进行微调。 回调有自己的迷你内部循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a43700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您的模型必须有 2 个属性\n",
    "model = Model()\n",
    "model.z_dim = ... # the representation dim\n",
    "model.num_classes = ... # the num of classes in the model\n",
    "\n",
    "online_eval = SSLOnlineEvaluator(\n",
    "    z_dim=model.z_dim,\n",
    "    num_classes=model.num_classes,\n",
    "    dataset='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba636f4f",
   "metadata": {},
   "source": [
    "## 可变回调\n",
    "\n",
    "对 GAN、可变自动编码器或任何具有潜在空间的东西有用的回调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa037b5f",
   "metadata": {},
   "source": [
    "潜层纬度插值器\n",
    "\n",
    "插值潜层纬度。\n",
    "\n",
    "示例输出："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4b026",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gu27oqrhqvj61600m0gov02.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb941904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import LatentDimInterpolator\n",
    "\n",
    "Trainer(callbacks=[LatentDimInterpolator()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c5fd5",
   "metadata": {},
   "source": [
    "## 视觉回调\n",
    "\n",
    "视觉模型的有用回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850afe7",
   "metadata": {},
   "source": [
    "### 混淆Logit\n",
    "\n",
    "显示输入必须如何更改才能将预测从一个 logit 移动到另一个 logit\n",
    "\n",
    "示例输出："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e90ad9",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gu27qnaqs3j616m0fatat02.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks.vision import ConfusedLogitCallback\n",
    "trainer = Trainer(callbacks=[ConfusedLogitCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5652f",
   "metadata": {},
   "source": [
    "> 每当调用时，此模型将在 LightningModule 中查找 self.last_batch 和 self.last_logits。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378718d6",
   "metadata": {},
   "source": [
    "### Tensorboard 图像生成器\n",
    "\n",
    "从生成模型生成图像并绘制到张量板\n",
    "\n",
    "生成图像和日志到张量板。 您的模型必须实现生成的前向函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model must have img_dim arg\n",
    "model.img_dim = (1, 28, 28)\n",
    "\n",
    "# model forward must work for sampling\n",
    "z = torch.rand(batch_size, latent_dim)\n",
    "img_samples = your_model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f49c1",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import TensorboardGenerativeModelImageSampler\n",
    "\n",
    "trainer = Trainer(callbacks=[TensorboardGenerativeModelImageSampler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b038c5c",
   "metadata": {},
   "source": [
    "# 数据模块\n",
    "\n",
    "在 PyTorch 中，处理数据具有以下主要元素。\n",
    "* 下载、保存和准备数据集。\n",
    "* 拆分为训练、验证和测试。\n",
    "* 对于每个分割，应用不同的变换\n",
    "\n",
    "DataModule 将这些操作组合到一个可重复的 DataModule 中，该 DataModule 可以共享以保证：\n",
    "* 一致的数据预处理（下载、拆分等...）\n",
    "* 完全相同的分裂\n",
    "* 完全相同的变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import ImagenetDataModule\n",
    "\n",
    "dm = ImagenetDataModule(data_dir=PATH)\n",
    "\n",
    "# 标准的 PyTorch！\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "Trainer().fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1fc02",
   "metadata": {},
   "source": [
    "但是当与 PyTorch LightningModules（所有 Bolts 模型）搭配使用时，您可以使用相同的拆分、转换等插入和播放完整的数据集定义……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = ImagenetDataModule(PATH)\n",
    "model = VAE(datamodule=imagenet)\n",
    "model = ImageGPT(datamodule=imagenet)\n",
    "model = GAN(datamodule=imagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2389a4",
   "metadata": {},
   "source": [
    "我们甚至有预先构建的模块来弥合 Numpy、Sklearn 和 PyTorch 之间的差距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "datamodule = SklearnDataModule(X, y)\n",
    "\n",
    "model = LitModel(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cf976",
   "metadata": {},
   "source": [
    "## 回归英雄\n",
    "\n",
    "如果您的工作或研究不需要“锤子”，我们提供经典 ML 模型的实现，这些模型受益于 Lightning 的多 GPU 和 TPU 支持。\n",
    "\n",
    "因此，现在您可以可扩展地运行大量工作负载，而无需进行任何工程设计。 例如，在这里我们可以在 Imagenet 上运行逻辑回归（每个 epoch 大约需要 3 分钟）！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.regression import LogisticRegression\n",
    "\n",
    "imagenet = ImagenetDataModule(PATH)\n",
    "\n",
    "# 224 x 224 x 3\n",
    "pixels_per_image = 150528\n",
    "model = LogisticRegression(input_dim=pixels_per_image, num_classes=1000)\n",
    "model.prepare_data = imagenet.prepare_data\n",
    "\n",
    "trainer = Trainer(gpus=2)\n",
    "trainer.fit(\n",
    "    model,\n",
    "    imagenet.train_dataloader(batch_size=256),\n",
    "    imagenet.val_dataloader(batch_size=256)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8153406",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "\n",
    "这是线性回归的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# link the numpy dataset to PyTorch\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "loaders = SklearnDataModule(X, y)\n",
    "\n",
    "# training runs training batches while validating against a validation set\n",
    "model = LinearRegression()\n",
    "trainer = pl.Trainer(num_gpus=8)\n",
    "trainer.fit(model, train_dataloader=loaders.train_dataloader(), val_dataloaders=loaders.val_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3abd18",
   "metadata": {},
   "source": [
    "完成后，您可以根据需要运行测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bca18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=loaders.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b175610",
   "metadata": {},
   "source": [
    "但更重要的是，您可以扩展到多个 GPU、TPU 甚至 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 GPUs\n",
    "trainer = pl.Trainer(num_gpus=8)\n",
    "\n",
    "# 8 TPU cores\n",
    "trainer = pl.Trainer(tpu_cores=8)\n",
    "\n",
    "# 32 GPUs\n",
    "trainer = pl.Trainer(num_gpus=8, num_nodes=4)\n",
    "\n",
    "# 128 CPUs\n",
    "trainer = pl.Trainer(num_processes=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480d111",
   "metadata": {},
   "source": [
    "## 逻辑回归\n",
    "\n",
    "这是逻辑回归的一个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pl_bolts.models.regression import LogisticRegression\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# use any numpy or sklearn dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "dm = SklearnDataModule(X, y, batch_size=12)\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(input_dim=4, num_classes=3)\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer(tpu_cores=8, precision=16)\n",
    "trainer.fit(model, train_dataloader=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "\n",
    "trainer.test(test_dataloaders=dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f344f8",
   "metadata": {},
   "source": [
    "除了第一个（批次）之外，任何输入都将在所有维度上展平。 这意味着图像、声音等……开箱即用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ca1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dm = MNISTDataModule(num_workers=0, data_dir=tmpdir)\n",
    "\n",
    "model = LogisticRegression(input_dim=28 * 28, num_classes=10, learning_rate=0.001)\n",
    "model.prepare_data = dm.prepare_data\n",
    "model.train_dataloader = dm.train_dataloader\n",
    "model.val_dataloader = dm.val_dataloader\n",
    "model.test_dataloader = dm.test_dataloader\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=2)\n",
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "# {test_acc: 0.92}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3852faf",
   "metadata": {},
   "source": [
    "但更重要的是，您可以扩展到多个 GPU、TPU 甚至 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 GPUs\n",
    "trainer = pl.Trainer(num_gpus=8)\n",
    "\n",
    "# 8 TPUs\n",
    "trainer = pl.Trainer(tpu_cores=8)\n",
    "\n",
    "# 32 GPUs\n",
    "trainer = pl.Trainer(num_gpus=8, num_nodes=4)\n",
    "\n",
    "# 128 CPUs\n",
    "trainer = pl.Trainer(num_processes=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de966c67",
   "metadata": {},
   "source": [
    "# 常规 PyTorch\n",
    "\n",
    "Bolt 中的所有内容也适用于常规 PyTorch，因为它们都只是 nn.Modules！\n",
    "\n",
    "但是，如果您使用 Lightning 进行训练，则无需处理工程代码 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5a38e",
   "metadata": {},
   "source": [
    "# 命令行支持\n",
    "\n",
    "也可以从命令行训练任何 bolt 模块\n",
    "```bash\n",
    "cd pl_bolts/models/autoencoders/basic_vae\n",
    "python basic_vae_pl_module.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79dc26",
   "metadata": {},
   "source": [
    "每个脚本都接受闪电训练器和模型的 Argparse 参数\n",
    "```bash\n",
    "python basic_vae_pl_module.py --latent_dim 32 --batch_size 32 --gpus 4 --max_epochs 12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9cc710",
   "metadata": {},
   "source": [
    "# 数据模块\n",
    "\n",
    "DataModules（在 PyTorch Lightning 0.9.0 中引入）将数据与模型分离。 DataModule 只是训练数据加载器、验证数据加载器和测试数据加载器的集合。 此外，它还指定了如何：\n",
    "* 下载/准备数据。\n",
    "* 训练/验证/测试拆分。\n",
    "* 转变\n",
    "然后你可以像这样使用它：\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b66aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule('path/to/data')\n",
    "model = LitModel()\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe090e",
   "metadata": {},
   "source": [
    "或者通过普通的 PyTorch 手动使用它\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1174eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule('path/to/data')\n",
    "for batch in dm.train_dataloader():\n",
    "    ...\n",
    "for batch in dm.val_dataloader():\n",
    "    ...\n",
    "for batch in dm.test_dataloader():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646b7fa",
   "metadata": {},
   "source": [
    "请访问 PyTorch Lightning 文档以获取有关 DataModules 的更多详细信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561fa5d5",
   "metadata": {},
   "source": [
    "## SklearnDataModule\n",
    "\n",
    "将 sklearn 或 numpy 数据集映射到 PyTorch Dataloaders 的实用程序，具有自动数据拆分和 GPU/TPU 支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6282a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.5 ms (started: 2021-09-02 13:32:12 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "loaders = SklearnDataModule(X, y, batch_size = 32)\n",
    "\n",
    "train_loader = loaders.train_dataloader()\n",
    "val_loader = loaders.val_dataloader()\n",
    "test_loader = loaders.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62770f1f",
   "metadata": {},
   "source": [
    "或构建您自己的火炬数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2fd625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.6 ms (started: 2021-09-02 13:32:57 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from pl_bolts.datamodules import SklearnDataset\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "dataset = SklearnDataset(X, y)\n",
    "loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d603f35",
   "metadata": {},
   "source": [
    "## Sklearn 数据集类\n",
    "\n",
    "将 sklearn 或 numpy 数据集转换为 PyTorch 数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf1c842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.8 ms (started: 2021-09-02 13:35:00 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from pl_bolts.datamodules import SklearnDataset\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "dataset = SklearnDataset(X, y)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef3e6e",
   "metadata": {},
   "source": [
    "## Sklearn DataModule 类\n",
    "\n",
    "为 Numpy 数据集自动生成训练、验证和测试拆分。 为方便起见，它们被设置为数据加载器。 或者，您可以传入自己的验证和测试拆分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67507cd",
   "metadata": {},
   "source": [
    "为 Numpy 数据集自动生成训练、验证和测试拆分。 为方便起见，它们被设置为数据加载器。 或者，您可以传入自己的验证和测试拆分。\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc400c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20 ms (started: 2021-09-02 13:38:21 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "loaders = SklearnDataModule(X, y, batch_size=32)\n",
    "\n",
    "# train set\n",
    "train_loader = loaders.train_dataloader()\n",
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0185f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.47 ms (started: 2021-09-02 13:38:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157b23cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.8 ms (started: 2021-09-02 13:38:36 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "val_loader = loaders.val_dataloader()\n",
    "len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371df985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.25 ms (started: 2021-09-02 13:38:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d09736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.17 ms (started: 2021-09-02 13:38:44 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "test_loader = loaders.test_dataloader()\n",
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fac8430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.41 ms (started: 2021-09-02 13:38:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993d6fa",
   "metadata": {},
   "source": [
    "## 视觉数据模块\n",
    "\n",
    "以下是用于计算机视觉的预构建数据模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e4e9f",
   "metadata": {},
   "source": [
    "**监督学习**\n",
    "\n",
    "这些是标准视觉数据集，其中包含在 DataLoaders 中预先生成的训练、测试、val 分割以及标准变换（和归一化）值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f565299",
   "metadata": {},
   "source": [
    "### BinaryMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70006e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import BinaryMNISTDataModule\n",
    "\n",
    "dm = BinaryMNISTDataModule('.')\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115d57a",
   "metadata": {},
   "source": [
    "### CityScapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe377f",
   "metadata": {},
   "source": [
    "变换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transform_lib.Compose([\n",
    "    transform_lib.ToTensor(),\n",
    "    transform_lib.Normalize(\n",
    "        mean=[0.28689554, 0.32513303, 0.28389177],\n",
    "        std=[0.18696375, 0.19017339, 0.18720214]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc34f1f",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import CityscapesDataModule\n",
    "\n",
    "dm = CityscapesDataModule(PATH)\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08d3f9",
   "metadata": {},
   "source": [
    "或者您可以设置自己的转换\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_transforms = ...\n",
    "dm.test_transforms = ...\n",
    "dm.val_transforms  = ...\n",
    "dm.target_transforms = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628c93d",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba2c3e",
   "metadata": {},
   "source": [
    "标准 CIFAR10、训练、验证、测试拆分和转换\n",
    "\n",
    "变换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb61d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms = transform_lib.Compose([\n",
    "    transform_lib.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "        std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075bdc7c",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import CIFAR10DataModule\n",
    "\n",
    "dm = CIFAR10DataModule(PATH)\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fb737",
   "metadata": {},
   "source": [
    "或者您可以设置自己的转换\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a09ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_transforms = ...\n",
    "dm.test_transforms = ...\n",
    "dm.val_transforms  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438f940",
   "metadata": {},
   "source": [
    "### FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import FashionMNISTDataModule\n",
    "\n",
    "dm = FashionMNISTDataModule('.')\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dd72d",
   "metadata": {},
   "source": [
    "### Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import ImagenetDataModule\n",
    "\n",
    "dm = ImagenetDataModule(IMAGENET_PATH)\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fda1ff",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f08988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import MNISTDataModule\n",
    "\n",
    "dm = MNISTDataModule('.')\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebe891",
   "metadata": {},
   "source": [
    "**半监督学习**\n",
    "\n",
    "以下数据集支持未标记训练和半监督学习，其中仅标记了几个示例。\n",
    "\n",
    "### Imagenet (ssl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810c3a2",
   "metadata": {},
   "source": [
    "### STL-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8166015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import STL10DataModule\n",
    "\n",
    "dm = STL10DataModule(PATH)\n",
    "model = LitModel()\n",
    "\n",
    "Trainer().fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9dabc",
   "metadata": {},
   "source": [
    "# 数据集\n",
    "\n",
    "收集有用的数据集\n",
    "\n",
    "使用这些数据集进行调试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b31ae6",
   "metadata": {},
   "source": [
    "## DummyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4beaf5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.35 ms (started: 2021-09-02 15:07:05 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datasets import DummyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# mnist dims\n",
    "ds = DummyDataset((1, 28, 28), (1, ))\n",
    "dl = DataLoader(ds, batch_size=7)\n",
    "# get first batch\n",
    "batch = next(iter(dl))\n",
    "x, y = batch\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bb6805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.73 ms (started: 2021-09-02 15:07:07 +08:00)\n"
     ]
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19effc32",
   "metadata": {},
   "source": [
    "## DummyDetectionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb57cea",
   "metadata": {},
   "source": [
    "生成用于检测的虚拟数据集\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c92e7db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.53 ms (started: 2021-09-02 15:07:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datasets import DummyDetectionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "ds = DummyDetectionDataset()\n",
    "dl = DataLoader(ds, batch_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd705d",
   "metadata": {},
   "source": [
    "## RandomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cfa76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.06 ms (started: 2021-09-02 15:08:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datasets import RandomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "ds = RandomDataset(10)\n",
    "dl = DataLoader(ds, batch_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d4367",
   "metadata": {},
   "source": [
    "## RandomDictDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafaf2c0",
   "metadata": {},
   "source": [
    "生成具有 dict 结构的虚拟数据集\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa99a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.85 ms (started: 2021-09-02 15:09:19 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datasets import RandomDictDataset\n",
    "from torch.utils.data import DataLoader\n",
    "ds = RandomDictDataset(10)\n",
    "dl = DataLoader(ds, batch_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610502d9",
   "metadata": {},
   "source": [
    "## RandomDictStringDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c942d61",
   "metadata": {},
   "source": [
    "生成带有字符串的虚拟数据集\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1382bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.53 ms (started: 2021-09-02 15:10:05 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pl_bolts.datasets import RandomDictStringDataset\n",
    "from torch.utils.data import DataLoader\n",
    "ds = RandomDictStringDataset(10)\n",
    "dl = DataLoader(ds, batch_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc0cb0",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457aa348",
   "metadata": {},
   "source": [
    "## AsynchronousLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb19546",
   "metadata": {},
   "source": [
    "此数据加载器的行为与标准 pytorch 数据加载器相同，但会通过训练将数据异步传输到 GPU。 您还可以使用它来包装现有的数据加载器。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9764571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = AsynchronousLoader(DataLoader(ds, batch_size=16), device=device)\n",
    "\n",
    "for b in dataloader:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae3559",
   "metadata": {},
   "source": [
    "使用 DataLoader 从 CPU 内存异步加载到设备内存的类。\n",
    "\n",
    "请注意，这仅适用于单 GPU 训练，multiGPU 使用 PyTorch 的 DataParallel 或 DistributedDataParallel，后者使用自己的代码跨 GPU 传输数据。 这可能会破坏 DataParallel 或 DistributedDataParallel 或使事情变慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54422aa",
   "metadata": {},
   "source": [
    "# 损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24414e57",
   "metadata": {},
   "source": [
    "这个包列出了跨研究领域的常见损失（这是一项正在进行的工作。如果你有任何损失想要贡献，请提交 PR！）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c0b1e",
   "metadata": {},
   "source": [
    "## 物体检测\n",
    "\n",
    "这些是对象检测中使用的常见损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0912b",
   "metadata": {},
   "source": [
    "### GIoU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d85d01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0794]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.2 ms (started: 2021-09-02 15:18:43 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pl_bolts.losses.object_detection import giou_loss\n",
    "\n",
    "preds = torch.tensor([[100, 100, 200, 200]])\n",
    "target = torch.tensor([[150, 150, 250, 250]])\n",
    "giou_loss(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92312263",
   "metadata": {},
   "source": [
    "### IoU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a01d9c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8571]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms (started: 2021-09-02 15:19:25 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pl_bolts.losses.object_detection import iou_loss\n",
    "preds = torch.tensor([[100, 100, 200, 200]])\n",
    "target = torch.tensor([[150, 150, 250, 250]])\n",
    "iou_loss(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f6145",
   "metadata": {},
   "source": [
    "## 强化学习\n",
    "\n",
    "这些是 RL 中使用的常见损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62a4fd",
   "metadata": {},
   "source": [
    "### DQN Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10841c76",
   "metadata": {},
   "source": [
    "使用重播缓冲区中的小批量计算 mse 损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38513f",
   "metadata": {},
   "source": [
    "### Double DQN Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24a62a",
   "metadata": {},
   "source": [
    "使用重播缓冲区中的小批量计算 mse 损失。 这通过使用双 dqn 对原始 DQN 损失进行了改进。 这通过使用训练网络的动作从目标网络中选择值来显示。 这段代码被大量注释，以便清楚地解释这个过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b73ea8",
   "metadata": {},
   "source": [
    "### Per DQN Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a4034",
   "metadata": {},
   "source": [
    "使用来自 PER 缓冲区的批次的优先权重计算 mse 损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7e9cc",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605ddf2",
   "metadata": {},
   "source": [
    "## 如何使用模型\n",
    "\n",
    "模型旨在“固定”到您的研究或生产案例上。\n",
    "\n",
    "Bolts旨在以下列方式使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50f746",
   "metadata": {},
   "source": [
    "### 预测您的数据\n",
    "\n",
    "大多数Bolts都有在各种数据集或算法上训练的预训练权重。 当您没有足够的数据、时间或金钱来进行自己的培训时，这很有用。\n",
    "\n",
    "例如，您可以使用预训练的 VAE 为图像数据集生成特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfc731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch19/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:209: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['non_linear_evaluator.block_forward.2.weight', 'non_linear_evaluator.block_forward.2.bias']\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "encoder = simclr.encoder\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in own_data:\n",
    "    features = encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4778f",
   "metadata": {},
   "source": [
    "Bolts的优点是每个系统都可以以有趣的方式分解和使用。 例如，这个 resnet50 在 Imagenet 上使用自监督学习（无标签）进行训练，因此可能比使用标签训练的相同 resnet50 表现更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d4b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无标签训练\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "resnet50_unsupervised = simclr.encoder.eval()\n",
    "\n",
    "# 用标签训练\n",
    "from torchvision.models import resnet50\n",
    "resnet50_supervised = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也许在没有标签的情况下训练的特征对于分类或其他任务要好得多\n",
    "x = image_sample()\n",
    "unsup_feats = resnet50_unsupervised(x)\n",
    "sup_feats = resnet50_supervised(x)\n",
    "\n",
    "# 哪个会更好？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb22dc3",
   "metadata": {},
   "source": [
    "Bolt 通常在多个数据集上进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39e8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "# imagenet weights\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "\n",
    "simclr.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11944fc8",
   "metadata": {},
   "source": [
    "## 对数据进行微调\n",
    "\n",
    "如果您有一点数据并且可以支付一点培训费用，那么对自己的数据进行微调通常会更好。\n",
    "\n",
    "要进行微调，您有两个选项解冻微调或稍后解冻。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f191e8f",
   "metadata": {},
   "source": [
    "### 解冻微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201b3df",
   "metadata": {},
   "source": [
    "在这种方法中，我们加载预训练模型并从头开始解冻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55840434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "resnet50 = simclr.encoder\n",
    "# don't call .freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(...)\n",
    "\n",
    "for (x, y) in own_data:\n",
    "    feats = resnet50(x)\n",
    "    y_hat = classifier(feats)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106552b",
   "metadata": {},
   "source": [
    "或者作为 LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b47268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "        self.classifier = LogisticRegression(...)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x, y) = batch\n",
    "        feats = self.encoder(x)\n",
    "        y_hat = self.classifier(feats)\n",
    "        loss = cross_entropy_with_logits(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "trainer = Trainer(gpus=2)\n",
    "model = FineTuner(resnet50)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e05ed",
   "metadata": {},
   "source": [
    "有时这很有效，但更多时候最好让编码器冻结一段时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d140f",
   "metadata": {},
   "source": [
    "### 冻结然后解冻\n",
    "\n",
    "最常用的方法是先冻结然后解冻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze!\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "resnet50 = simclr.encoder\n",
    "resnet50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(...)\n",
    "\n",
    "for epoch in epochs:\n",
    "    for (x, y) in own_data:\n",
    "        feats = resnet50(x)\n",
    "        y_hat = classifier(feats)\n",
    "        loss = cross_entropy_with_logits(y_hat, y)\n",
    "\n",
    "    # unfreeze after 10 epochs\n",
    "    if epoch == 10:\n",
    "        resnet50.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e092894",
   "metadata": {},
   "source": [
    "或者在 Lightning 中作为回调，这样你就不会污染你的研究代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da519a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFreezeCallback(Callback):\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        if trainer.current_epoch == 10.\n",
    "            encoder.unfreeze()\n",
    "\n",
    "trainer = Trainer(gpus=2, callbacks=[UnFreezeCallback()])\n",
    "model = FineTuner(resnet50)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f7c6c",
   "metadata": {},
   "source": [
    "除非你仍然需要将它混合到你的研究代码中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "        self.classifier = LogisticRegression(...)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # option 1 - (not recommended because it's messy)\n",
    "        if self.trainer.current_epoch == 10:\n",
    "            self.encoder.unfreeze()\n",
    "\n",
    "        (x, y) = batch\n",
    "        feats = self.encoder(x)\n",
    "        y_hat = self.classifier(feats)\n",
    "        loss = cross_entropy_with_logits(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        # a hook is cleaner (but a callback is much better)\n",
    "        if self.trainer.current_epoch == 10:\n",
    "            self.encoder.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77699fbd",
   "metadata": {},
   "source": [
    "### 超参数搜索\n",
    "\n",
    "为了使微调工作良好，您应该尝试模型超参数的许多版本。 否则，您不太可能从数据中获得最大价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7674fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "hidden_dim = [128, 256, 512]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hd in hidden_dim:\n",
    "        vae = VAE(input_height=32, hidden_dim=hd, learning_rate=lr)\n",
    "        trainer = Trainer()\n",
    "        trainer.fit(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d39b74",
   "metadata": {},
   "source": [
    "## 从头开始训练\n",
    "\n",
    "如果您确实有足够的数据和计算资源，那么您可以尝试从头开始训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c67655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = DataLoader(YourDataset)\n",
    "val_data = DataLoader(YourDataset)\n",
    "\n",
    "# use any bolts model without pretraining\n",
    "model = VAE()\n",
    "\n",
    "# fit!\n",
    "trainer = Trainer(gpus=2)\n",
    "trainer.fit(model, train_dataloader=train_data, val_dataloaders=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bc600",
   "metadata": {},
   "source": [
    "## 研究用\n",
    "\n",
    "bolts 与所有其他库的区别在于，bolts 是由 AI 研究人员构建和使用的。 这意味着每个螺栓都是模块化的，因此可以轻松扩展或与代码库其余部分的任意部分混合。\n",
    "\n",
    "### 扩展工作\n",
    "\n",
    "也许一个研究项目需要修改已知方法的一部分。 在这种情况下，您最好只更改已知性能良好的系统部分。 否则，您可能无法正确执行工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d081ec3",
   "metadata": {},
   "source": [
    "示例 1：更改 VAE 的先验或近似后验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976112fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "class MyVAEFlavor(VAE):\n",
    "\n",
    "    def init_prior(self, z_mu, z_std):\n",
    "        P = MyPriorDistribution\n",
    "\n",
    "        # default is standard normal\n",
    "        # P = distributions.normal.Normal(loc=torch.zeros_like(z_mu), scale=torch.ones_like(z_std))\n",
    "        return P\n",
    "\n",
    "    def init_posterior(self, z_mu, z_std):\n",
    "        Q = MyPosteriorDistribution\n",
    "        # default is normal(z_mu, z_sigma)\n",
    "        # Q = distributions.normal.Normal(loc=z_mu, scale=z_std)\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583755f",
   "metadata": {},
   "source": [
    "当然，用闪电训练它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyVAEFlavor()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f40d7",
   "metadata": {},
   "source": [
    "只需几行代码，您就可以更改 VAE 的一些基本内容……这意味着您可以更快地迭代想法，因为知道 bolt 实现和训练循环是正确且经过测试的。\n",
    "\n",
    "如果您的模型不适用于新的 P、Q，那么您可以更快地放弃该研究想法，而不是试图确定您的 VAE 实施是否正确，或者您的训练循环是否正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2019bb",
   "metadata": {},
   "source": [
    "示例 2：更改 GAN 的生成器步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ce3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import GAN\n",
    "\n",
    "class FancyGAN(GAN):\n",
    "\n",
    "    def generator_step(self, x):\n",
    "        # sample noise\n",
    "        z = torch.randn(x.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(x)\n",
    "\n",
    "        # generate images\n",
    "        self.generated_imgs = self(z)\n",
    "\n",
    "        # ground truth result (ie: all real)\n",
    "        real = torch.ones(x.size(0), 1)\n",
    "        real = real.type_as(x)\n",
    "        g_loss = self.generator_loss(real)\n",
    "\n",
    "        tqdm_dict = {'g_loss': g_loss}\n",
    "        output = OrderedDict({\n",
    "            'loss': g_loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        })\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b04d98",
   "metadata": {},
   "source": [
    "示例 3：在对比性自监督学习方法中改变计算损失的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8295a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import AMDIM\n",
    "\n",
    "class MyDIM(AMDIM):\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        [img_1, img_2], labels = batch\n",
    "\n",
    "        # generate features\n",
    "        r1_x1, r5_x1, r7_x1, r1_x2, r5_x2, r7_x2 = self.forward(img_1, img_2)\n",
    "\n",
    "        # Contrastive task\n",
    "        loss, lgt_reg = self.contrastive_task((r1_x1, r5_x1, r7_x1), (r1_x2, r5_x2, r7_x2))\n",
    "        unsupervised_loss = loss.sum() + lgt_reg\n",
    "\n",
    "        result = {\n",
    "            'val_nce': unsupervised_loss\n",
    "        }\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aaddd0",
   "metadata": {},
   "source": [
    "## 导入零件\n",
    "\n",
    "所有螺栓都是模块化的。 这意味着您还可以任意混合和匹配来自不同方法的基本块。\n",
    "\n",
    "示例 1：将 GAN 的 VAE 编码器用作生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import GAN\n",
    "from pl_bolts.models.autoencoders.basic_vae import Encoder\n",
    "\n",
    "class FancyGAN(GAN):\n",
    "\n",
    "    def init_generator(self, img_dim):\n",
    "        generator = Encoder(...)\n",
    "        return generator\n",
    "\n",
    "trainer = Trainer(...)\n",
    "trainer.fit(FancyGAN())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620009b",
   "metadata": {},
   "source": [
    "例2：在CPC中使用AMDIM的对比任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import AMDIM, CPC_v2\n",
    "\n",
    "default_amdim_task = AMDIM().contrastive_task\n",
    "model = CPC_v2(contrastive_task=default_amdim_task, encoder='cpc_default')\n",
    "# you might need to modify the cpc encoder depending on what you use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca198b",
   "metadata": {},
   "source": [
    "## 组成新想法\n",
    "\n",
    "您可能也有兴趣创建全新的方法来混合和匹配各种不同的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此模型仅用于说明目的，没有研究意义，但旨在表明您可以随心所欲地发挥创造力和表现力。\n",
    "class MyNewContrastiveApproach(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        suoer().__init_()\n",
    "\n",
    "        self.gan = GAN()\n",
    "        self.vae = VAE()\n",
    "        self.amdim = AMDIM()\n",
    "        self.cpc = CPC_v2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x, y) = batch\n",
    "\n",
    "        feat_a = self.gan.generator(x)\n",
    "        feat_b = self.vae.encoder(x)\n",
    "\n",
    "        unsup_loss = self.amdim(feat_a) + self.cpc(feat_b)\n",
    "\n",
    "        vae_loss = self.vae._step(batch)\n",
    "        gan_loss = self.gan.generator_loss(x)\n",
    "\n",
    "        return unsup_loss + vae_loss + gan_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98707661",
   "metadata": {},
   "source": [
    "## 经典机器学习模型\n",
    "\n",
    "该模块在 PyTorch Lightning 中实现了经典的机器学习模型，包括线性回归和逻辑回归。 与其他实现这些模型的库不同，这里我们使用 PyTorch 来启用多 GPU、多 TPU 和半精度训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e3fae",
   "metadata": {},
   "source": [
    "### 线性回归\n",
    "\n",
    "线性回归拟合了实值目标变量 y 和一个或多个特征 X 之间的线性模型。我们估计了最小化预测和真实目标值之间的均方误差的回归系数。\n",
    "\n",
    "我们将线性回归模型制定为单层神经网络。 默认情况下，我们在输出层中只包含一个神经元，尽管您可以自己指定 output_dim。\n",
    "\n",
    "通过指定正则化强度（默认为 0）添加 L1 或 L2 正则化，或两者。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08806fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.regression import LinearRegression\n",
    "import pytorch_lightning as pl\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "loaders = SklearnDataModule(X, y)\n",
    "\n",
    "model = LinearRegression(input_dim=13)\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, train_dataloader=loaders.train_dataloader(), val_dataloaders=loaders.val_dataloader())\n",
    "trainer.test(test_dataloaders=loaders.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77c7f9",
   "metadata": {},
   "source": [
    "### 逻辑回归\n",
    "\n",
    "逻辑回归是用于分类的线性模型，即当我们有一个分类目标变量时。 此实现支持二元和多类分类。\n",
    "\n",
    "在二元情况下，我们将逻辑回归模型表述为一层神经网络，输出层有一个神经元，并有一个 sigmoid 激活函数。 在多类情况下，我们使用单层神经网络，但现在输出中有 k 个神经元，其中 k 是类的数量。 这也称为多项逻辑回归。\n",
    "\n",
    "通过指定正则化强度（默认为 0）添加 L1 或 L2 正则化，或两者。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a41d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pl_bolts.models.regression import LogisticRegression\n",
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# use any numpy or sklearn dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "dm = SklearnDataModule(X, y)\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(input_dim=4, num_classes=3)\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer(tpu_cores=8, precision=16)\n",
    "trainer.fit(model, train_dataloader=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "\n",
    "trainer.test(test_dataloaders=dm.test_dataloader(batch_size=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeecb4b",
   "metadata": {},
   "source": [
    "除了第一个（批次）之外，任何输入都将在所有维度上展平。 这意味着图像、声音等……开箱即用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dm = MNISTDataModule(num_workers=0, data_dir=tmpdir)\n",
    "\n",
    "model = LogisticRegression(input_dim=28 * 28, num_classes=10, learning_rate=0.001)\n",
    "model.prepare_data = dm.prepare_data\n",
    "model.train_dataloader = dm.train_dataloader\n",
    "model.val_dataloader = dm.val_dataloader\n",
    "model.test_dataloader = dm.test_dataloader\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=2)\n",
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "# {test_acc: 0.92}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e460d",
   "metadata": {},
   "source": [
    "# 视觉模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce5c1b",
   "metadata": {},
   "source": [
    "## 自编码器\n",
    "\n",
    "本节包含自动编码器和变分自动编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c94f6",
   "metadata": {},
   "source": [
    "### 基本AE\n",
    "\n",
    "这是最简单的自动编码器。 你可以像这样使用它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import AE\n",
    "\n",
    "model = AE()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8f864",
   "metadata": {},
   "source": [
    "您可以覆盖此 AE 的任何部分来构建您自己的变体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import AE\n",
    "\n",
    "class MyAEFlavor(AE):\n",
    "\n",
    "    def init_encoder(self, hidden_dim, latent_dim, input_width, input_height):\n",
    "        encoder = YourSuperFancyEncoder(...)\n",
    "        return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0c9d",
   "metadata": {},
   "source": [
    "您可以使用螺栓中存在的预训练模型。\n",
    "\n",
    "CIFAR-10 预训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f565f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import AE\n",
    "\n",
    "ae = AE(input_height=32)\n",
    "print(AE.pretrained_weights_available())\n",
    "ae = ae.from_pretrained('cifar10-resnet18')\n",
    "\n",
    "ae.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec900f",
   "metadata": {},
   "source": [
    "重建：\n",
    "\n",
    "输入和生成的图像都是标准化版本，因为训练是用这些图像完成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84293002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not pretrained\n",
    "ae = AE()\n",
    "\n",
    "# pretrained on cifar10\n",
    "ae = AE(input_height=32).from_pretrained('cifar10-resnet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d458002",
   "metadata": {},
   "source": [
    "### 变分自编码器\n",
    "\n",
    "**基础VAE**\n",
    "\n",
    "像这样使用 VAE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "model = VAE()\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f77fc2",
   "metadata": {},
   "source": [
    "您可以覆盖此 VAE 的任何部分以构建您自己的变体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "class MyVAEFlavor(VAE):\n",
    "\n",
    "    def get_posterior(self, mu, std):\n",
    "        # do something other than the default\n",
    "        # P = self.get_distribution(self.prior, loc=torch.zeros_like(mu), scale=torch.ones_like(std))\n",
    "\n",
    "        return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a2163",
   "metadata": {},
   "source": [
    "您可以使用螺栓中存在的预训练模型。\n",
    "\n",
    "CIFAR-10 预训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "vae = VAE(input_height=32)\n",
    "print(VAE.pretrained_weights_available())\n",
    "vae = vae.from_pretrained('cifar10-resnet18')\n",
    "\n",
    "vae.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbddbe",
   "metadata": {},
   "source": [
    "STL-10 预训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0145d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.autoencoders import VAE\n",
    "\n",
    "vae = VAE(input_height=96, first_conv=True)\n",
    "print(VAE.pretrained_weights_available())\n",
    "vae = vae.from_pretrained('cifar10-resnet18')\n",
    "\n",
    "vae.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993e0ee",
   "metadata": {},
   "source": [
    "具有高斯先验和近似后验的标准 VAE。\n",
    "\n",
    "模型可在不同的数据集上进行预训练：\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not pretrained\n",
    "vae = VAE()\n",
    "\n",
    "# pretrained on cifar10\n",
    "vae = VAE(input_height=32).from_pretrained('cifar10-resnet18')\n",
    "\n",
    "# pretrained on stl10\n",
    "vae = VAE(input_height=32).from_pretrained('stl10-resnet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc714d7a",
   "metadata": {},
   "source": [
    "## 卷积架构\n",
    "\n",
    "这个包列出了贡献的卷积架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200af13",
   "metadata": {},
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709296ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.vision import GPT2\n",
    "\n",
    "seq_len = 17\n",
    "batch_size = 32\n",
    "vocab_size = 16\n",
    "x = torch.randint(0, vocab_size, (seq_len, batch_size))\n",
    "model = GPT2(embed_dim=32, heads=2, layers=2, num_positions=seq_len, vocab_size=vocab_size, num_classes=4)\n",
    "results = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e111fd",
   "metadata": {},
   "source": [
    "### Image GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.vision import ImageGPT\n",
    "\n",
    "dm = MNISTDataModule('.')\n",
    "model = ImageGPT(dm)\n",
    "\n",
    "pl.Trainer(gpu=4).fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91a891",
   "metadata": {},
   "source": [
    "作为脚本：\n",
    "```bash\n",
    "cd pl_bolts/models/vision/image_gpt\n",
    "python igpt_module.py --learning_rate 1e-2 --batch_size 32 --gpus 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97fa0c",
   "metadata": {},
   "source": [
    "### 像素CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf7ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pl_bolts.models.vision import PixelCNN\n",
    "import torch\n",
    "\n",
    "model = PixelCNN(input_channels=3)\n",
    "x = torch.rand(5, 3, 64, 64)\n",
    "out = model(x)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33b97c",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1ded9",
   "metadata": {},
   "source": [
    "### 语义分割\n",
    "\n",
    "用于语义分割任务的模型模板。 该模型默认使用 UNet 架构。 覆盖此模型的任何部分以构建您自己的变体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73dc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.vision import SemSegment\n",
    "from pl_bolts.datamodules import KittiDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "dm = KittiDataModule('path/to/kitt/dataset/', batch_size=4)\n",
    "model = SemSegment(datamodule=dm)\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251868ca",
   "metadata": {},
   "source": [
    "## GANs\n",
    "\n",
    "\n",
    "生成对抗网络的集合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c5d5",
   "metadata": {},
   "source": [
    "### 基本的 GAN\n",
    "\n",
    "这是一个普通的 GAN。 该模型适用于任何数据集大小，但结果显示为 MNIST。 替换编码器、解码器或训练循环的任何部分以构建新方法，或者只是对数据进行微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import GAN\n",
    "...\n",
    "gan = GAN()\n",
    "trainer = Trainer()\n",
    "trainer.fit(gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fe84a",
   "metadata": {},
   "source": [
    "命令行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "python  basic_gan_module.py --gpus 1\n",
    "\n",
    "# imagenet\n",
    "python  basic_gan_module.py --gpus 1 --dataset 'imagenet2012'\n",
    "--data_dir /path/to/imagenet/folder/ --meta_dir ~/path/to/meta/bin/folder\n",
    "--batch_size 256 --learning_rate 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(batch_size, latent_dim)\n",
    "gan = GAN.load_from_checkpoint(PATH)\n",
    "img = gan(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1037f1",
   "metadata": {},
   "source": [
    "### DCGAN\n",
    "\n",
    "DCGAN 实现来自论文无监督表示学习与深度卷积生成对抗网络。 该实现基于 PyTorch 示例中的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee42ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.gans import DCGAN\n",
    "\n",
    "m = DCGAN()\n",
    "Trainer(gpus=2).fit(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95065c94",
   "metadata": {},
   "source": [
    "命令行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "python dcgan_module.py --gpus 1\n",
    "\n",
    "# cifar10\n",
    "python dcgan_module.py --gpus 1 --dataset cifar10 --image_channels 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2cbf5",
   "metadata": {},
   "source": [
    "forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand(batch_size, latent_dim)\n",
    "gan = GAN.load_from_checkpoint(PATH)\n",
    "img = gan(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493d5f7",
   "metadata": {},
   "source": [
    "## 强化学习\n",
    "\n",
    "该模块是在 Lightning 中实现的常见 RL 方法的集合。\n",
    "* mDQN\n",
    "* Double DQN\n",
    "* Dueling DQN\n",
    "* Noisy DQN\n",
    "* NStep DQN\n",
    "* Prioritized Experience Replay DQN\n",
    "* Reinforce\n",
    "* Vanilla Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed067f8",
   "metadata": {},
   "source": [
    "> RL 模型目前仅支持分布式后端=dp 的 CPU 和单 GPU 训练。 完整的 GPU 支持将在以后的更新中添加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa32c14",
   "metadata": {},
   "source": [
    "### DQN 模型\n",
    "\n",
    "以下模型基于 DQN。 DQN 使用基于值的学习，它根据模型的当前学习值 (V) 或当前状态的状态动作值 (Q) 决定采取什么行动。 这些值被定义为代理状态或状态动作对的折扣总奖励。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d419d29",
   "metadata": {},
   "source": [
    "深 Q 网络 (### DQN)\n",
    "\n",
    "DQN 模型在 Playing Atari with Deep Reinforcement Learning 中引入。 论文作者：Volodymyr Mnih、Koray Kavukcuoglu、David Silver、Alex Graves、Ioannis Antonoglou、Daan Wierstra、Martin Riedmiller。\n",
    "\n",
    "原始实施者：Donal Byrne\n",
    "\n",
    "DeepMind 的研究人员在 Playing Atari with Deep Reinforcement Learning 中引入了 DQN。 这采用了表格 Q 学习的概念，并通过使用深度神经网络逼近 Q 函数将其扩展到更大的问题。\n",
    "\n",
    "DQN 背后的目标是采用 Q 学习的简单控制方法并将其扩展以解决复杂的任务。 除此之外，该方法还需要稳定。 DQN 通过以下添加解决了这些问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fb200",
   "metadata": {},
   "source": [
    "近似 Q 函数\n",
    "\n",
    "将 Q 值存储在表中理论上效果很好，但完全不可扩展。 相反，作者使用深度神经网络近似 Q 函数。 这允许 DQN 用于更复杂的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ff18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import DQN\n",
    "dqn = DQN(\"PongNoFrameskip-v4\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ed514",
   "metadata": {},
   "source": [
    "### 双DQN\n",
    "\n",
    "双 DQN 模型在深度强化学习中引入双 Q 学习论文作者：Hado van Hasselt、Arthur Guez、David Silver\n",
    "\n",
    "原始实施者：Donal Byrne\n",
    "\n",
    "原始 DQN 在 Bellman 更新过程中往往会高估 Q 值，导致不稳定并且对训练有害。这是由于贝尔曼方程中的最大运算。\n",
    "\n",
    "在我们的更新过程中，我们不断地采用我们的代理估计的最大值。如果我们可以相信这些估计，这似乎是合理的。然而，在训练的早期阶段，这些值的估计将偏离中心，并可能导致训练不稳定，直到我们的估计变得更加可靠\n",
    "\n",
    "Double DQN 通过使用主要训练网络为下一个状态选择动作来修复这种高估，但使用来自更稳定目标网络的这些动作的值。所以我们仍然会采取贪婪的行动，但该值将不那么“乐观”，因为它是由目标网络选择的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f439d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import DoubleDQN\n",
    "ddqn = DoubleDQN(\"PongNoFrameskip-v4\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(ddqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9c208",
   "metadata": {},
   "source": [
    "### Dueling DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc93364",
   "metadata": {},
   "source": [
    "决斗 DQN 的好处\n",
    "* 能够有效地学习状态值函数。 在决斗网络中，每次 Q 更新也会更新价值流，而在 DQN 中，仅更新所选动作的值。 这提供了更好的值近似值\n",
    "* 给定状态的总 Q 值之间的差异与 Q 的大小有关。 最佳动作和次佳动作之间的 Q 值差异可能非常小，而平均状态值可能要大得多 . 规模的差异会引入噪音，这可能会导致贪婪的策略切换这些动作的优先级。 状态价值和优势的单独估计器使 Duling DQN 对这种类型的场景具有鲁棒性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6474af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import DuelingDQN\n",
    "dueling_dqn = DuelingDQN(\"PongNoFrameskip-v4\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(dueling_dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e16b2",
   "metadata": {},
   "source": [
    "### Noisy DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb3888",
   "metadata": {},
   "source": [
    "嘈杂的 DQN 的好处\n",
    "* 改进了探索功能。 我们不是仅仅执行完全随机的动作，而是在我们的策略中增加了减少的噪音和不确定性，允许在仍然利用其策略的同时进行探索。\n",
    "* 该方法自动调整的事实意味着我们不必为 epsilon-greedy 调整超参数！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import NoisyDQN\n",
    "noisy_dqn = NoisyDQN(\"PongNoFrameskip-v4\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(noisy_dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd9f54",
   "metadata": {},
   "source": [
    "### N-Step DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4494ad",
   "metadata": {},
   "source": [
    "N步优势\n",
    "* 多步学习能够比典型的一步学习方法更快地学习。\n",
    "* 请注意，此方法引入了一个新的超参数 n。 尽管 n=4 通常是一个很好的起点，并提供了全面的良好结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ac2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import DQN\n",
    "n_step_dqn = DQN(\"PongNoFrameskip-v4\", n_steps=4)\n",
    "trainer = Trainer()\n",
    "trainer.fit(n_step_dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce46ec5",
   "metadata": {},
   "source": [
    "### 优先体验重放 DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import PERDQN\n",
    "per_dqn = PERDQN(\"PongNoFrameskip-v4\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(per_dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f646d1",
   "metadata": {},
   "source": [
    "### 策略梯度模型\n",
    "\n",
    "以下模型基于策略梯度。与之前展示的 Q 学习模型不同，基于策略的模型不会尝试学习状态或状态动作对的特定值。相反，它省去了中间人，直接学习策略分布。在策略梯度模型中，我们按照策略梯度建议的方向更新网络参数，以找到产生最高结果的策略。\n",
    "政策梯度要点：\n",
    "* 输出动作的分布而不是离散的 Q 值\n",
    "* 直接优化策略，而不是通过优化 Q 值间接优化策略\n",
    "* 动作的策略分布允许模型处理更复杂的动作空间，例如连续动作\n",
    "* 策略分布引入了随机性，为模型提供了自然探索\n",
    "* 策略分布提供了更稳定的更新，因为权重的变化只会稍微改变总分布，而不是基于状态 S 的 Q 值更改权重会改变具有相似状态的所有 Q 值。\n",
    "\n",
    "策略梯度趋向于快速收敛，但是它们的样本效率不高，并且通常需要与环境进行更多的交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b4361",
   "metadata": {},
   "source": [
    "### REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b052d9",
   "metadata": {},
   "source": [
    "强化优点\n",
    "* 简单明了\n",
    "* 对于 Cartpole 等简单任务而言，计算效率比基于值的方法更高效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68701d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import Reinforce\n",
    "reinforce = Reinforce(\"CartPole-v0\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(reinforce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6dae3e",
   "metadata": {},
   "source": [
    "### Vanilla Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ecb07",
   "metadata": {},
   "source": [
    "VPG 优点\n",
    "* 添加基线减少了模型中的方差\n",
    "* 由于熵奖励改进了探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25badcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.rl import VanillaPolicyGradient\n",
    "vpg = VanillaPolicyGradient(\"CartPole-v0\")\n",
    "trainer = Trainer()\n",
    "trainer.fit(vpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7357a",
   "metadata": {},
   "source": [
    "## 自监督学习\n",
    "\n",
    "该 bolts 模块包含所有自监督学习模型的集合。\n",
    "\n",
    "自监督学习通过解决借口任务来提取输入的表示。 在这个包中，我们实现了许多当前最先进的自监督算法。\n",
    "\n",
    "使用未标记的数据集训练自监督模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b439469",
   "metadata": {},
   "source": [
    "### 提取图像特征\n",
    "\n",
    "该模块中的模型是无监督训练的，因此可以捕获更好的图像表示（特征）。\n",
    "\n",
    "在这个例子中，我们将加载一个 resnet 18，它使用 CPC 作为借口任务在 imagenet 上进行了预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "# load resnet50 pretrained using SimCLR on imagenet\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "\n",
    "simclr_resnet50 = simclr.encoder\n",
    "simclr_resnet50.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017718e",
   "metadata": {},
   "source": [
    "这意味着您现在可以提取通过无监督学习进行预训练的图像表示。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = SomeDataset()\n",
    "for batch in my_dataset:\n",
    "    x, y = batch\n",
    "    out = simclr_resnet50(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02df6ad",
   "metadata": {},
   "source": [
    "### 使用未标记的数据进行训练\n",
    "\n",
    "当您拥有大量未标记的图像时，这些模型非常适合从头开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.models.self_supervised.simclr import SimCLREvalDataTransform, SimCLRTrainDataTransform\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(transforms=SimCLRTrainDataTransform())\n",
    "val_dataset = MyDataset(transforms=SimCLREvalDataTransform())\n",
    "\n",
    "# simclr needs a lot of compute!\n",
    "model = SimCLR()\n",
    "trainer = Trainer(tpu_cores=128)\n",
    "trainer.fit(\n",
    "    model,\n",
    "    DataLoader(train_dataset),\n",
    "    DataLoader(val_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb024661",
   "metadata": {},
   "source": [
    "**研究**\n",
    "\n",
    "混合和匹配任何部分或子类以创建您自己的新方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389df92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import CPC_v2\n",
    "from pl_bolts.losses.self_supervised_learning import FeatureMapContrastiveTask\n",
    "\n",
    "amdim_task = FeatureMapContrastiveTask(comparisons='01, 11, 02', bidirectional=True)\n",
    "model = CPC_v2(contrastive_task=amdim_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3a416",
   "metadata": {},
   "source": [
    "### 对比学习模型\n",
    "\n",
    "对比自监督学习 (CSL) 是一种自监督学习方法，我们生成实例的表示，使得相似的实例彼此靠近而远离不同的实例。 这通常通过比较正、锚和负表示的三元组来完成。\n",
    "\n",
    "在本节中，我们列出了流行的对比学习方法的 Lightning 实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f693aea",
   "metadata": {},
   "source": [
    "#### AMDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaeb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import AMDIM\n",
    "\n",
    "model = AMDIM(encoder='resnet18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704514e0",
   "metadata": {},
   "source": [
    "训练:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276af020",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e021ea8",
   "metadata": {},
   "source": [
    "#### BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BYOL(num_classes=10)\n",
    "\n",
    "dm = CIFAR10DataModule(num_workers=0)\n",
    "dm.train_transforms = SimCLRTrainDataTransform(32)\n",
    "dm.val_transforms = SimCLREvalDataTransform(32)\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c272a",
   "metadata": {},
   "source": [
    "训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86840fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317a288",
   "metadata": {},
   "source": [
    "CLI命令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ea7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10\n",
    "python byol_module.py --gpus 1\n",
    "\n",
    "# imagenet\n",
    "python byol_module.py\n",
    "    --gpus 8\n",
    "    --dataset imagenet2012\n",
    "    --data_dir /path/to/imagenet/\n",
    "    --meta_dir /path/to/folder/with/meta.bin/\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545871b8",
   "metadata": {},
   "source": [
    "#### CPC (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.self_supervised import CPC_v2\n",
    "from pl_bolts.datamodules import CIFAR10DataModule\n",
    "from pl_bolts.models.self_supervised.cpc import (\n",
    "    CPCTrainTransformsCIFAR10, CPCEvalTransformsCIFAR10)\n",
    "\n",
    "# data\n",
    "dm = CIFAR10DataModule(num_workers=0)\n",
    "dm.train_transforms = CPCTrainTransformsCIFAR10()\n",
    "dm.val_transforms = CPCEvalTransformsCIFAR10()\n",
    "\n",
    "# model\n",
    "model = CPC_v2()\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff18bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python cpc_finetuner.py\n",
    "    --ckpt_path path/to/checkpoint.ckpt\n",
    "    --dataset cifar10\n",
    "    --gpus 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ba20c",
   "metadata": {},
   "source": [
    "#### Moco (v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c6b90",
   "metadata": {},
   "source": [
    "#### SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b63747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.datamodules import CIFAR10DataModule\n",
    "from pl_bolts.models.self_supervised.simclr.transforms import (\n",
    "    SimCLREvalDataTransform, SimCLRTrainDataTransform)\n",
    "\n",
    "# data\n",
    "dm = CIFAR10DataModule(num_workers=0)\n",
    "dm.train_transforms = SimCLRTrainDataTransform(32)\n",
    "dm.val_transforms = SimCLREvalDataTransform(32)\n",
    "\n",
    "# model\n",
    "model = SimCLR(num_samples=dm.num_samples, batch_size=dm.batch_size, dataset='cifar10')\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce1d870",
   "metadata": {},
   "source": [
    "CIFAR-10 预训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91820af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(weight_path, strict=False)\n",
    "\n",
    "simclr.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f2d6a",
   "metadata": {},
   "source": [
    "重现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain\n",
    "python simclr_module.py\n",
    "    --gpus 8\n",
    "    --dataset cifar10\n",
    "    --batch_size 256\n",
    "    -- num_workers 16\n",
    "    --optimizer sgd\n",
    "    --learning_rate 1.5\n",
    "    --exclude_bn_bias\n",
    "    --max_epochs 800\n",
    "    --online_ft\n",
    "\n",
    "# finetune\n",
    "python simclr_finetuner.py\n",
    "    --gpus 4\n",
    "    --ckpt_path path/to/simclr/ckpt\n",
    "    --dataset cifar10\n",
    "    --batch_size 64\n",
    "    --num_workers 8\n",
    "    --learning_rate 0.3\n",
    "    --num_epochs 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af5d74",
   "metadata": {},
   "source": [
    "#### SwAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.self_supervised import SwAV\n",
    "from pl_bolts.datamodules import STL10DataModule\n",
    "from pl_bolts.models.self_supervised.swav.transforms import (\n",
    "    SwAVTrainDataTransform, SwAVEvalDataTransform\n",
    ")\n",
    "from pl_bolts.transforms.dataset_normalizations import stl10_normalization\n",
    "\n",
    "# data\n",
    "batch_size = 128\n",
    "dm = STL10DataModule(data_dir='.', batch_size=batch_size)\n",
    "dm.train_dataloader = dm.train_dataloader_mixed\n",
    "dm.val_dataloader = dm.val_dataloader_mixed\n",
    "\n",
    "dm.train_transforms = SwAVTrainDataTransform(\n",
    "    normalize=stl10_normalization()\n",
    ")\n",
    "\n",
    "dm.val_transforms = SwAVEvalDataTransform(\n",
    "    normalize=stl10_normalization()\n",
    ")\n",
    "\n",
    "# model\n",
    "model = SwAV(\n",
    "    gpus=1,\n",
    "    num_samples=dm.num_unlabeled_samples,\n",
    "    dataset='stl10',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# fit\n",
    "trainer = pl.Trainer(precision=16)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add565f3",
   "metadata": {},
   "source": [
    "#### SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c082c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimSiam()\n",
    "\n",
    "dm = CIFAR10DataModule(num_workers=0)\n",
    "dm.train_transforms = SimCLRTrainDataTransform(32)\n",
    "dm.val_transforms = SimCLREvalDataTransform(32)\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f65979",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882899f",
   "metadata": {},
   "source": [
    "# 学习率调度器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f4b10",
   "metadata": {},
   "source": [
    "这个包列出了跨研究领域的常见学习率调度程序（这是一项正在进行的工作。如果你有任何想要贡献的学习率调度程序，请提交 PR！）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01ae8d",
   "metadata": {},
   "source": [
    "## 线性预热余弦退火学习率调度器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ae37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(10, 1)\n",
    "optimizer = Adam(layer.parameters(), lr=0.02)\n",
    "scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs=10, max_epochs=40)\n",
    "#\n",
    "# the default case\n",
    "for epoch in range(40):\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "#\n",
    "# passing epoch param case\n",
    "for epoch in range(40):\n",
    "    scheduler.step(epoch)\n",
    "    # train(...)\n",
    "    # validate(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ed44b",
   "metadata": {},
   "source": [
    "# 自监督学习的变换\n",
    "\n",
    "这些变换用于各种自监督学习方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa300df",
   "metadata": {},
   "source": [
    "## CPC转换\n",
    "\n",
    "用于CPC变换  \n",
    "可用的变换：\n",
    "```\n",
    "random_flip\n",
    "img_jitter\n",
    "col_jitter\n",
    "rnd_gray\n",
    "transforms.ToTensor()\n",
    "normalize\n",
    "Patchify(patch_size=patch_size, overlap_size=patch_size // 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a643b",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "CIFAR10(..., transforms=CPCTrainTransformsCIFAR10())\n",
    "\n",
    "# in a DataModule\n",
    "module = CIFAR10DataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCTrainTransformsCIFAR10())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24238a3",
   "metadata": {},
   "source": [
    "### CIFAR-10 Eval (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a9334",
   "metadata": {},
   "source": [
    "包含的变换：\n",
    "* random_flip\n",
    "* transforms.ToTensor()\n",
    "* normalize\n",
    "* Patchify(patch_size=patch_size, overlap_size=overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e2a22",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b380b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "CIFAR10(..., transforms=CPCEvalTransformsCIFAR10())\n",
    "\n",
    "# in a DataModule\n",
    "module = CIFAR10DataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCEvalTransformsCIFAR10())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a17ace",
   "metadata": {},
   "source": [
    "### Imagenet Train (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08149b9",
   "metadata": {},
   "source": [
    "* random_flip\n",
    "* transforms.ToTensor()\n",
    "* normalize\n",
    "* Patchify(patch_size=patch_size, overlap_size=patch_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6405e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "Imagenet(..., transforms=CPCTrainTransformsImageNet128())\n",
    "\n",
    "# in a DataModule\n",
    "module = ImagenetDataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCTrainTransformsImageNet128())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e7d26",
   "metadata": {},
   "source": [
    "### Imagenet Eval (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55435609",
   "metadata": {},
   "source": [
    "* random_flip\n",
    "* transforms.ToTensor()\n",
    "* normalize\n",
    "* Patchify(patch_size=patch_size, overlap_size=patch_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "Imagenet(..., transforms=CPCEvalTransformsImageNet128())\n",
    "\n",
    "# in a DataModule\n",
    "module = ImagenetDataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCEvalTransformsImageNet128())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493a03a",
   "metadata": {},
   "source": [
    "### STL-10 火车 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ede4bf",
   "metadata": {},
   "source": [
    "* random_flip\n",
    "* img_jitter\n",
    "* col_jitter\n",
    "* rnd_gray\n",
    "* transforms.ToTensor()\n",
    "* normalize\n",
    "* Patchify(patch_size=patch_size, overlap_size=patch_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "STL10(..., transforms=CPCTrainTransformsSTL10())\n",
    "\n",
    "# in a DataModule\n",
    "module = STL10DataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCTrainTransformsSTL10())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543026c7",
   "metadata": {},
   "source": [
    "### STL-10 Eval (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851db67",
   "metadata": {},
   "source": [
    "* random_flip\n",
    "* transforms.ToTensor()\n",
    "* normalize\n",
    "* Patchify(patch_size=patch_size, overlap_size=patch_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c54695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a regular dataset\n",
    "STL10(..., transforms=CPCEvalTransformsSTL10())\n",
    "\n",
    "# in a DataModule\n",
    "module = STL10DataModule(PATH)\n",
    "train_loader = module.train_dataloader(batch_size=32, transforms=CPCEvalTransformsSTL10())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed8e9a",
   "metadata": {},
   "source": [
    "## AMDIM 转换\n",
    "\n",
    "用于 AMDIM 的变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4d9d7",
   "metadata": {},
   "source": [
    "### CIFAR-10 Train (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f63bb",
   "metadata": {},
   "source": [
    "### CIFAR-10 Eval (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca4c9e",
   "metadata": {},
   "source": [
    "### Imagenet Train (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772b9a25",
   "metadata": {},
   "source": [
    "### Imagenet Eval (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63bc5c",
   "metadata": {},
   "source": [
    "### STL-10 Train (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb62698",
   "metadata": {},
   "source": [
    "### STL-10 Eval (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a25d1",
   "metadata": {},
   "source": [
    "## MOCO V2 变换\n",
    "\n",
    "用于 MOCO V2 的变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b3336",
   "metadata": {},
   "source": [
    "## SimCLR 变换\n",
    "\n",
    "用于 SimCLR 的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f240eff",
   "metadata": {},
   "source": [
    "# 自监督学习函数 \n",
    "\n",
    "用于自监督学习的有用函数的集合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dd83b",
   "metadata": {},
   "source": [
    "## Identity class\n",
    "用于替换预训练模型中任意层的身份类\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils import Identity\n",
    "\n",
    "model = resnet18()\n",
    "model.fc = Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6931f5",
   "metadata": {},
   "source": [
    "## SSL-ready resnets\n",
    "\n",
    "Torchvision resnets去除了 fc 层，并且能够返回所有特征图，而不仅仅是最后一个。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c44821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils.self_supervised import torchvision_ssl_encoder\n",
    "\n",
    "resnet = torchvision_ssl_encoder('resnet18', pretrained=False, return_all_feature_maps=True)\n",
    "x = torch.rand(3, 3, 32, 32)\n",
    "\n",
    "feat_maps = resnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b2ef2",
   "metadata": {},
   "source": [
    "## SSL backbone finetuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd4731",
   "metadata": {},
   "source": [
    "使用具有 1024 个单元的单层 MLP 的标准评估协议对自监督学习主干进行微调\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf02644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils.self_supervised import SSLFineTuner\n",
    "from pl_bolts.models.self_supervised import CPC_v2\n",
    "from pl_bolts.datamodules import CIFAR10DataModule\n",
    "from pl_bolts.models.self_supervised.cpc.transforms import CPCEvalTransformsCIFAR10,\n",
    "                                                            CPCTrainTransformsCIFAR10\n",
    "\n",
    "# pretrained model\n",
    "backbone = CPC_v2.load_from_checkpoint(PATH, strict=False)\n",
    "\n",
    "# dataset + transforms\n",
    "dm = CIFAR10DataModule(data_dir='.')\n",
    "dm.train_transforms = CPCTrainTransformsCIFAR10()\n",
    "dm.val_transforms = CPCEvalTransformsCIFAR10()\n",
    "\n",
    "# finetuner\n",
    "finetuner = SSLFineTuner(backbone, in_features=backbone.z_dim, num_classes=backbone.num_classes)\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(finetuner, dm)\n",
    "\n",
    "# test\n",
    "trainer.test(datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27591003",
   "metadata": {},
   "source": [
    "# 半监督学习\n",
    "\n",
    "用于半监督学习的实用程序集合，其中部分数据已标记，另一部分未标记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d14f9",
   "metadata": {},
   "source": [
    "## 平衡类\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils.semi_supervised import balance_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a45eaf",
   "metadata": {},
   "source": [
    "确保每个批次的每个类都有相同数量的数据。 完美平衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f02b6e",
   "metadata": {},
   "source": [
    "## 半标记批次\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.utils.semi_supervised import generate_half_labeled_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96a07d",
   "metadata": {},
   "source": [
    "给定一个标记数据集和一个未标记数据集，该函数生成一个联合对，其中一半批次被标记，另一半没有。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baef8da",
   "metadata": {},
   "source": [
    "# 自我监督学习对比任务\n",
    "\n",
    "本节实现了自监督学习中使用的流行对比学习任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3055f42",
   "metadata": {},
   "source": [
    "## FeatureMapContrastiveTask\n",
    "\n",
    "此任务比较特征图集。\n",
    "\n",
    "一般来说，特征图比较借口任务使用特征的三元组。 以下是比较的抽象步骤。\n",
    "\n",
    "生成同一图像的多个视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_view_1 = data_augmentation(x1)\n",
    "x1_view_2 = data_augmentation(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d86e94",
   "metadata": {},
   "source": [
    "使用不同的示例生成额外的视图（通常在同一批次或候选池中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_view_1 = data_augmentation(x2)\n",
    "x2_view_2 = data_augmentation(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64653b",
   "metadata": {},
   "source": [
    "选择 3 个视图进行比较，这些是锚点、正面和负面特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = x1_view_1\n",
    "positive = x1_view_2\n",
    "negative = x2_view_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a996d",
   "metadata": {},
   "source": [
    "为每个视图生成特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a0, a1, a2) = encoder(anchor)\n",
    "(p0, p1, p2) = encoder(positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d4011",
   "metadata": {},
   "source": [
    "对一组特征图进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = some_score_function()\n",
    "\n",
    "# the '01' comparison\n",
    "score = phi(a0, p1)\n",
    "\n",
    "# and can be bidirectional\n",
    "score = phi(p0, a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39cb39",
   "metadata": {},
   "source": [
    "在实践中，对比任务创建了一个 BxB 矩阵，其中 B 是批量大小。 特征图集合 1 的对角线是锚点，特征图集合 2 的对角线是正数，集合 1 的非对角线是负数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99d48c",
   "metadata": {},
   "source": [
    "对每个传递的特征图元组执行锚点、正负对比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7803b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature maps\n",
    "pos_0, pos_1, pos_2 = encoder(x_pos)\n",
    "anc_0, anc_1, anc_2 = encoder(x_anchor)\n",
    "\n",
    "# compare only the 0th feature maps\n",
    "task = FeatureMapContrastiveTask('00')\n",
    "loss, regularizer = task((pos_0), (anc_0))\n",
    "\n",
    "# compare (pos_0 to anc_1) and (pos_0, anc_2)\n",
    "task = FeatureMapContrastiveTask('01, 02')\n",
    "losses, regularizer = task((pos_0, pos_1, pos_2), (anc_0, anc_1, anc_2))\n",
    "loss = losses.sum()\n",
    "\n",
    "# compare (pos_1 vs a anc_random)\n",
    "task = FeatureMapContrastiveTask('0r')\n",
    "loss, regularizer = task((pos_0, pos_1, pos_2), (anc_0, anc_1, anc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec96dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with bidirectional the comparisons are done both ways\n",
    "task = FeatureMapContrastiveTask('01, 02')\n",
    "\n",
    "# will compare the following:\n",
    "# 01: (pos_0, anc_1), (anc_0, pos_1)\n",
    "# 02: (pos_0, anc_2), (anc_0, pos_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3cda4",
   "metadata": {},
   "source": [
    "Forward example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4fdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import torch\n",
    ">>> from pytorch_lightning import seed_everything\n",
    ">>> seed_everything(0)\n",
    "0\n",
    ">>> a1 = torch.rand(3, 5, 2, 2)\n",
    ">>> a2 = torch.rand(3, 5, 2, 2)\n",
    ">>> b1 = torch.rand(3, 5, 2, 2)\n",
    ">>> b2 = torch.rand(3, 5, 2, 2)\n",
    "...\n",
    ">>> task = FeatureMapContrastiveTask('01, 11')\n",
    "...\n",
    ">>> losses, regularizer = task((a1, a2), (b1, b2))\n",
    ">>> losses\n",
    "tensor([2.2351, 2.1902])\n",
    ">>> regularizer\n",
    "tensor(0.0324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
