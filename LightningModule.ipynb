{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clinical-bubble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 457 ms (started: 2021-08-28 21:31:30 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "packed-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main cd05707] 更新 #4 Aug 28, 2021\n",
      " 2 files changed, 484 insertions(+), 1 deletion(-)\n",
      " create mode 100644 LIGHTNINGMODULE.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/pytorch_lightning_study.git\n",
      "   0c6ecfd..cd05707  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.65 s (started: 2021-08-28 20:46:50 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #1 Aug 29, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closed-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.98 s (started: 2021-08-28 21:31:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-foundation",
   "metadata": {},
   "source": [
    "# LightningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-belfast",
   "metadata": {},
   "source": [
    "LightningModule 将您的 PyTorch 代码组织成 5 个部分\n",
    "* 计算（`Init`）。\n",
    "* 训练循环（`training_step`）\n",
    "* 验证循环（`validation_step`）\n",
    "* 测试循环（`test_step`）\n",
    "* 优化器（`configure_optimizers`）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-signal",
   "metadata": {},
   "source": [
    "**注意一些事情**\n",
    "\n",
    "1. 这是相同的代码。\n",
    "2.  PyTorch 代码不是抽象的——只是有组织的。\n",
    "3.  不在 LightningModule 中的所有其他代码已由trainer为您自动化。\n",
    "\n",
    "```\n",
    "net = Net()\n",
    "trainer = Trainer()\n",
    "trainer.fit(net)\n",
    "\n",
    "```\n",
    "4. 没有 `.cuda()` 或 `.to()` 调用……Lightning 为你做这些。\n",
    "\n",
    "```\n",
    "# don't do in lightning\n",
    "x = torch.Tensor(2, 3)\n",
    "x = x.cuda()\n",
    "x = x.to(device)\n",
    "\n",
    "# do this instead\n",
    "x = x  # leave it alone!\n",
    "\n",
    "# or to init a new tensor\n",
    "new_x = torch.Tensor(2, 3)\n",
    "new_x = new_x.type_as(x)\n",
    "```\n",
    "\n",
    "5. 默认情况下，Lightning 会为您处理分布式采样器。  \n",
    "\n",
    "```\n",
    "# Don't do in Lightning...\n",
    "data = MNIST(...)\n",
    "sampler = DistributedSampler(data)\n",
    "DataLoader(data, sampler=sampler)\n",
    "\n",
    "# do this instead\n",
    "data = MNIST(...)\n",
    "DataLoader(data)\n",
    "```\n",
    "\n",
    "6. LightningModule 是一个 torch.nn.Module，但具有附加功能。 这样使用它！\n",
    "\n",
    "```\n",
    "net = Net.load_from_checkpoint(PATH)\n",
    "net.freeze()\n",
    "out = net(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-assignment",
   "metadata": {},
   "source": [
    "因此，要使用 Lightning，你只需要组织你的代码，大约需要 30 分钟，（让我们现实点，你可能应该做任何事情）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-grade",
   "metadata": {},
   "source": [
    "# 最小示例\n",
    "\n",
    "以下是唯一需要的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-cricket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 860 µs (started: 2021-08-28 21:32:22 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-vatican",
   "metadata": {},
   "source": [
    "您可以通过以下方式进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "molecular-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 7.9 K \n",
      "--------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e075f96230441ba8ffaf4bb69a0d8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4h 42min 33s (started: 2021-08-28 22:56:21 +08:00)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(MNIST(os.getcwd(), \n",
    "                                download=True, \n",
    "                                transform=transforms.ToTensor()), \n",
    "                          num_workers = 8)\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "model = LitModel()\n",
    "\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-gauge",
   "metadata": {},
   "source": [
    "LightningModule 有很多方便的方法，但你需要了解的核心方法是："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-photography",
   "metadata": {},
   "source": [
    "|名称|描述|\n",
    "|----|----|\n",
    "|init|在此处定义计算|\n",
    "|forward|仅用于推理（与 training_step 分开）|\n",
    "|training_step|完整的训练循环|\n",
    "|validation_step|完整的验证循环|\n",
    "|test_step|完整的测试循环|\n",
    "|configure_optimizers|定义优化器和 LR 调度器|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-channel",
   "metadata": {},
   "source": [
    "# 训练\n",
    "\n",
    "## 训练循环\n",
    "\n",
    "要添加训练循环，请使用 `training_step` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 743 µs (started: 2021-08-28 21:32:12 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-kitty",
   "metadata": {},
   "source": [
    "在幕后，Lightning 执行以下操作（伪代码）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model in train mode\n",
    "model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "losses = []\n",
    "for batch in train_dataloader:\n",
    "    # forward\n",
    "    loss = training_step(batch)\n",
    "    losses.append(loss.detach())\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-radio",
   "metadata": {},
   "source": [
    "## 训练Epoch级别的指标\n",
    "\n",
    "如果要计算Epoch级指标并记录它们，请使用 `.log` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self.model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "    # 记录每个training_step 的指标，\n",
    "    # 和整个Epoch的平均值，到进度条和记录器\n",
    "    self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-renewal",
   "metadata": {},
   "source": [
    ".log 对象会自动减少整个 epoch 中请求的指标。 这是它在幕后所做的伪代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for batch in train_dataloader:\n",
    "    # forward\n",
    "    out = training_step(val_batch)\n",
    "    outs.append(out)\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "epoch_metric = torch.mean(torch.stack([x[\"train_loss\"] for x in outs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-harvest",
   "metadata": {},
   "source": [
    "## 训练Epoch级操作\n",
    "\n",
    "如果您需要对每个 training_step 的所有输出执行某些操作，请自己覆盖 training_epoch_end。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self.model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    preds = ...\n",
    "    return {\"loss\": loss, \"other_stuff\": preds}\n",
    "\n",
    "\n",
    "def training_epoch_end(self, training_step_outputs):\n",
    "    for pred in training_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-cheese",
   "metadata": {},
   "source": [
    "匹配的伪代码是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for batch in train_dataloader:\n",
    "    # forward\n",
    "    out = training_step(val_batch)\n",
    "    outs.append(out)\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "training_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-neighbor",
   "metadata": {},
   "source": [
    "## 使用 DataParallel 进行训练\n",
    "\n",
    "当使用加速器将每个批次的数据拆分到 GPU 上时，有时您可能需要在主 GPU 上聚合它们以进行处理（dp 或 ddp2）。\n",
    "\n",
    "在这种情况下，实现 training_step_end 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self.model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    pred = ...\n",
    "    return {\"loss\": loss, \"pred\": pred}\n",
    "\n",
    "\n",
    "def training_step_end(self, batch_parts):\n",
    "    # 每个 GPU 的预测\n",
    "    predictions = batch_parts[\"pred\"]\n",
    "    # 每个 GPU 的损失\n",
    "    losses = batch_parts[\"loss\"]\n",
    "\n",
    "    gpu_0_prediction = predictions[0]\n",
    "    gpu_1_prediction = predictions[1]\n",
    "\n",
    "    # 对两个输出做一些事情\n",
    "    return (losses[0] + losses[1]) / 2\n",
    "\n",
    "\n",
    "def training_epoch_end(self, training_step_outputs):\n",
    "    for out in training_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-english",
   "metadata": {},
   "source": [
    "PL在幕后所做的完整伪代码是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for train_batch in train_dataloader:\n",
    "    batches = split_batch(train_batch)\n",
    "    dp_outs = []\n",
    "    for sub_batch in batches:\n",
    "        # 1\n",
    "        dp_out = training_step(sub_batch)\n",
    "        dp_outs.append(dp_out)\n",
    "\n",
    "    # 2\n",
    "    out = training_step_end(dp_outs)\n",
    "    outs.append(out)\n",
    "\n",
    "# do something with the outputs for all batches\n",
    "# 3\n",
    "training_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-jenny",
   "metadata": {},
   "source": [
    "# 验证循环\n",
    "\n",
    "要添加验证循环，请覆盖 LightningModule 的 validation_step 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-deadline",
   "metadata": {},
   "source": [
    "在幕后，Lightning 执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "for batch in train_dataloader:\n",
    "    loss = model.training_step()\n",
    "    loss.backward()\n",
    "    # ...\n",
    "\n",
    "    if validate_at_some_point:\n",
    "        # disable grads + batchnorm + dropout\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "        # ----------------- VAL LOOP ---------------\n",
    "        for val_batch in model.val_dataloader:\n",
    "            val_out = model.validation_step(val_batch)\n",
    "        # ----------------- VAL LOOP ---------------\n",
    "\n",
    "        # enable grads + batchnorm + dropout\n",
    "        torch.set_grad_enabled(True)\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-posting",
   "metadata": {},
   "source": [
    "## 验证Epoch级别的指标\n",
    "\n",
    "如果您需要对每个validation_step 的所有输出执行某些操作，请覆盖validation_epoch_end。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self.model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    pred = ...\n",
    "    return pred\n",
    "\n",
    "\n",
    "def validation_epoch_end(self, validation_step_outputs):\n",
    "    for pred in validation_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-integrity",
   "metadata": {},
   "source": [
    "## 使用 DataParallel 进行验证\n",
    "\n",
    "当使用加速器将每个批次的数据拆分到 GPU 上时，有时您可能需要在主 GPU 上聚合它们以进行处理（dp 或 ddp2）。\n",
    "\n",
    "在这种情况下，实现validation_step_end 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self.model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    pred = ...\n",
    "    return {\"loss\": loss, \"pred\": pred}\n",
    "\n",
    "\n",
    "def validation_step_end(self, batch_parts):\n",
    "    # predictions from each GPU\n",
    "    predictions = batch_parts[\"pred\"]\n",
    "    # losses from each GPU\n",
    "    losses = batch_parts[\"loss\"]\n",
    "\n",
    "    gpu_0_prediction = predictions[0]\n",
    "    gpu_1_prediction = predictions[1]\n",
    "\n",
    "    # do something with both outputs\n",
    "    return (losses[0] + losses[1]) / 2\n",
    "\n",
    "\n",
    "def validation_epoch_end(self, validation_step_outputs):\n",
    "    for out in validation_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-minneapolis",
   "metadata": {},
   "source": [
    "PL在幕后所做的完整伪代码是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for batch in dataloader:\n",
    "    batches = split_batch(batch)\n",
    "    dp_outs = []\n",
    "    for sub_batch in batches:\n",
    "        # 1\n",
    "        dp_out = validation_step(sub_batch)\n",
    "        dp_outs.append(dp_out)\n",
    "\n",
    "    # 2\n",
    "    out = validation_step_end(dp_outs)\n",
    "    outs.append(out)\n",
    "\n",
    "# do something with the outputs for all batches\n",
    "# 3\n",
    "validation_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-cinema",
   "metadata": {},
   "source": [
    "# 测试循环\n",
    "\n",
    "添加测试循环的过程与添加验证循环的过程相同。 详情请参阅上一节。\n",
    "\n",
    "唯一的区别是只有在使用 .test() 时才会调用测试循环："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "trainer = Trainer()\n",
    "trainer.fit()\n",
    "\n",
    "# automatically loads the best weights for you\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-episode",
   "metadata": {},
   "source": [
    "有两种方法可以调用 test()："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练后调用\n",
    "trainer = Trainer()\n",
    "trainer.fit(model)\n",
    "\n",
    "# 自动加载最佳权重\n",
    "trainer.test(dataloaders=test_dataloader)\n",
    "\n",
    "# 或使用预训练模型调用\n",
    "model = MyLightningModule.load_from_checkpoint(PATH)\n",
    "trainer = Trainer()\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-bruce",
   "metadata": {},
   "source": [
    "# 推理\n",
    "\n",
    "对于研究，LightningModules 是作为系统的最好结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Autoencoder(pl.LightningModule):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 256), nn.ReLU(), nn.Linear(256, latent_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 256), nn.ReLU(), nn.Linear(256, 28 * 28))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        # encode\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "\n",
    "        # decode\n",
    "        recons = self.decoder(z)\n",
    "\n",
    "        # reconstruction\n",
    "        reconstruction_loss = nn.functional.mse_loss(recons, x)\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        recons = self.decoder(z)\n",
    "        reconstruction_loss = nn.functional.mse_loss(recons, x)\n",
    "        self.log(\"val_reconstruction\", reconstruction_loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        # encode\n",
    "        # 对于预测，我们可以根据需要返回嵌入或重建或两者。\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-uncle",
   "metadata": {},
   "source": [
    "可以这样训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "trainer.fit(autoencoder, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-summit",
   "metadata": {},
   "source": [
    "这个简单的模型生成的例子看起来像这样（编码器和解码器太弱了）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-piano",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gtwwudesc9j614q06sjrp02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-alias",
   "metadata": {},
   "source": [
    "以上方法是闪lightning接口的一部分：\n",
    "* training_step\n",
    "* validation_step\n",
    "* test_step\n",
    "* predict_step\n",
    "* configure_optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-measure",
   "metadata": {},
   "source": [
    "请注意，在这种情况下，train 循环和 val 循环完全相同。 我们当然可以重用这段代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 256), nn.ReLU(), nn.Linear(256, latent_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 256), nn.ReLU(), nn.Linear(256, 28 * 28))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        x, _ = batch\n",
    "\n",
    "        # encode\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "\n",
    "        # decode\n",
    "        recons = self.decoder(z)\n",
    "\n",
    "        # loss\n",
    "        return nn.functional.mse_loss(recons, x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-organ",
   "metadata": {},
   "source": [
    "我们创建了一个名为 shared_step 的新方法，所有循环都可以使用它。 此方法名称是任意的，不保留。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-paintball",
   "metadata": {},
   "source": [
    "## 研究中的推理\n",
    "\n",
    "在我们想要对系统进行推理的情况下，我们可以向 LightningModule 添加一个 forward 方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-embassy",
   "metadata": {},
   "source": [
    "> 使用 forward 时，您负责调用 eval() 并使用 no_grad() 上下文管理器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "model = Autoencoder()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstruction = model(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-extent",
   "metadata": {},
   "source": [
    "添加前向的好处在于，在复杂系统中，您可以执行更复杂的推理过程，例如文本生成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(pl.LightningModule):\n",
    "    def forward(self, x):\n",
    "        embeddings = self(x)\n",
    "        hidden_states = self.encoder(embeddings)\n",
    "        for h in hidden_states:\n",
    "            # decode\n",
    "            ...\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-message",
   "metadata": {},
   "source": [
    "在您想要扩展推理的情况下，您应该使用 predict_step()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        # 这里调用 forward\n",
    "        return self(batch)\n",
    "\n",
    "\n",
    "data_module = ...\n",
    "model = Autoencoder()\n",
    "trainer = Trainer(gpus=2)\n",
    "trainer.predict(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-lloyd",
   "metadata": {},
   "source": [
    "## 生产中的推理\n",
    "\n",
    "对于生产等情况，您可能希望在 LightningModule 中迭代不同的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "\n",
    "\n",
    "class ClassificationTask(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-youth",
   "metadata": {},
   "source": [
    "然后传入任何适合此任务的任意模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [resnet50(), vgg16(), BidirectionalRNN()]:\n",
    "    task = ClassificationTask(model)\n",
    "\n",
    "    trainer = Trainer(gpus=2)\n",
    "    trainer.fit(task, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-identification",
   "metadata": {},
   "source": [
    "任务可以是任意复杂的，例如实施 GAN 训练、自我监督甚至 RL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTask(pl.LightningModule):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-appendix",
   "metadata": {},
   "source": [
    "像这样使用时，模型可以与任务分离，从而在生产中使用，而无需将其保存在 LightningModule 中。\n",
    "* 您可以导出到onnx。\n",
    "* 或者使用 Jit 进行跟踪。\n",
    "* 或在 python 运行时中运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClassificationTask(model)\n",
    "\n",
    "trainer = Trainer(gpus=2)\n",
    "trainer.fit(task, train_dataloader, val_dataloader)\n",
    "\n",
    "# 训练后使用模型或加载权重并放入生产系统\n",
    "model.eval()\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-beach",
   "metadata": {},
   "source": [
    "# LightningModule API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-opposition",
   "metadata": {},
   "source": [
    "## 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-outside",
   "metadata": {},
   "source": [
    "### configure_callbacks\n",
    "```\n",
    "LightningModule.configure_callbacks()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-excuse",
   "metadata": {},
   "source": [
    "配置特定于模型的回调。 当模型被附加时，例如，当 `.fit()` 或 `.test()` 被调用时，此处返回的列表将与传递给 Trainer 的 callbacks 参数的回调列表合并。 如果此处返回的回调与 Trainer 的回调列表中已存在的一个或多个回调具有相同的类型，则它将优先并替换它们。 此外，Lightning 将确保 `ModelCheckpoint` 回调最后运行。\n",
    "\n",
    "返回：\n",
    "一个回调列表，它将扩展 `Trainer` 中的回调列表。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_callbacks(self):\n",
    "    early_stop = EarlyStopping(monitor\"val_acc\", mode=\"max\")\n",
    "    checkpoint = ModelCheckpoint(monitor=\"val_loss\")\n",
    "    return [early_stop, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-palace",
   "metadata": {},
   "source": [
    "> 某些回调方法如 on_init_start() 永远不会在此处返回的新回调上调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-magnitude",
   "metadata": {},
   "source": [
    "### configure_optimizers\n",
    "```\n",
    "LightningModule.configure_optimizers()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-madison",
   "metadata": {},
   "source": [
    "选择在优化中使用的优化器和学习率调度器。 通常你需要一个。 但是在 GAN 或类似的情况下，您可能有多个。\n",
    "\n",
    "返回\n",
    "这6个选项中的任何一个。\n",
    "* 单个优化器。\n",
    "* 优化器列表或元组。\n",
    "* 两个列表 - 第一个列表有多个优化器，第二个列表有多个 LR 调度程序（或多个 `lr_dict`）。\n",
    "* 字典，带有“优化器”键和（可选）“`lr_scheduler`”键，其值为单个 LR 调度器或 `lr_dict`。\n",
    "* 如上所述的字典元组，带有可选的“频率”键。\n",
    "* 无 - Fit 将在没有任何优化器的情况下运行。\n",
    "\n",
    "`lr_dict` 是一个包含调度程序及其相关配置的字典。 默认配置如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dict = {\n",
    "    # REQUIRED: 调度器实例\n",
    "    \"scheduler\": lr_scheduler,\n",
    "    # 调度器步长的单位，也可以是“step”。 \n",
    "    # 'epoch' 在 epoch 结束时更新调度程序，而 'step' 在优化程序更新后更新它。\n",
    "    \"interval\": \"epoch\",\n",
    "    # 在调用 `scheduler.step()` 之间应该传递多少个 epochs/steps。 \n",
    "    # 1 对应于在每个 epoch/step 之后更新学习率。\n",
    "    \"frequency\": 1,\n",
    "    # 监控调度程序的指标，如“ReduceLROnPlateau”\n",
    "    \"monitor\": \"val_loss\",\n",
    "    # 如果设置为 `True`，将强制指定的值在更新调度程序时可用，因此如果未找到则停止训练。 \n",
    "    # 如果设置为`False`，它只会产生一个警告\n",
    "    \"strict\": True,\n",
    "    # 如果使用`LearningRateMonitor`回调来监控学习率进度，\n",
    "    # 这个关键字可以用来指定一个自定义的日志名称\n",
    "    \"name\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-granny",
   "metadata": {},
   "source": [
    "当存在其中 `.step()` 方法以值为条件的调度程序时，例如 `torch.optim.lr_scheduler.ReduceLROnPlateau` 调度程序，Lightning 要求 `lr_dict` 包含关键字“`monitor`”设置为调度程序应的指标名称 有条件。`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau 调度器需要一个监视器\n",
    "def configure_optimizers(self):\n",
    "    optimizer = Adam(...)\n",
    "    return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n",
    "            \"monitor\": \"metric_to_track\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# 在两个优化器的情况下，只有一个使用 ReduceLROnPlateau 调度器\n",
    "def configure_optimizers(self):\n",
    "    optimizer1 = Adam(...)\n",
    "    optimizer2 = SGD(...)\n",
    "    scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n",
    "    scheduler2 = LambdaLR(optimizer2, ...)\n",
    "    return (\n",
    "        {\n",
    "            \"optimizer\": optimizer1,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler1,\n",
    "                \"monitor\": \"metric_to_track\",\n",
    "            },\n",
    "        },\n",
    "        {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-business",
   "metadata": {},
   "source": [
    "可以通过在 LightningModule 中使用 `self.log('metric_to_track', metric_val)` 简单地记录来使指标可用于监控。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-scout",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "dict 中指定的`frequency`值与优化器键一起是一个 int，对应于使用特定优化器优化的连续批次的数量。 它应该被赋予一个或所有的优化器。 在列表中传递多个优化器和在字典中以 1 的频率传递多个优化器之间存在差异：\n",
    "* 在前一种情况下，所有优化器将在每个优化步骤中对给定的批次进行操作。\n",
    "* 在后者中，每一步只有一个优化器会对给定的批次进行操作。\n",
    "\n",
    "这与上面提到的 lr_dict 中指定的频率值不同。\n",
    "\n",
    "```\n",
    "def configure_optimizers(self):\n",
    "    optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "    optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "    return [\n",
    "        {\"optimizer\": optimizer_one, \"frequency\": 5},\n",
    "        {\"optimizer\": optimizer_two, \"frequency\": 10},\n",
    "    ]\n",
    "```\n",
    "\n",
    "在此示例中，第一个优化器将用于前 5 个步骤，第二个优化器用于接下来的 10 个步骤，并且该循环将继续。 如果使用上述字典中的 `lr_scheduler` 键为优化器指定了 LR 调度器，则调度器将仅在使用其优化器时更新。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-basis",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在大多数情况下。 没有学习率调度程序\n",
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "# 多个优化器案例（例如：GAN）\n",
    "def configure_optimizers(self):\n",
    "    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
    "    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
    "    return gen_opt, dis_opt\n",
    "\n",
    "# 学习率调度器示例\n",
    "def configure_optimizers(self):\n",
    "    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
    "    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
    "    dis_sch = CosineAnnealing(dis_opt, T_max=10)\n",
    "    return [gen_opt, dis_opt], [dis_sch]\n",
    "\n",
    "# 基于步骤的学习率调度器的示例\n",
    "# 每个优化器都有自己的调度器\n",
    "def configure_optimizers(self):\n",
    "    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
    "    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
    "    gen_sch = {\n",
    "        'scheduler': ExponentialLR(gen_opt, 0.99),\n",
    "        'interval': 'step'  # called after each training step\n",
    "    }\n",
    "    dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch\n",
    "    return [gen_opt, dis_opt], [gen_sch, dis_sch]\n",
    "\n",
    "# 优化器频率示例\n",
    "# 参见“改进的 Wasserstein GAN 训练”中的训练程序，算法 1\n",
    "# https://arxiv.org/abs/1704.00028\n",
    "def configure_optimizers(self):\n",
    "    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
    "    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
    "    n_critic = 5\n",
    "    return (\n",
    "        {'optimizer': dis_opt, 'frequency': n_critic},\n",
    "        {'optimizer': gen_opt, 'frequency': 1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-stanley",
   "metadata": {},
   "source": [
    "> 需要知道的一些事情：\n",
    ">* Lightning 根据需要在每个优化器和学习率调度器上调用 .backward() 和 .step() 。\n",
    ">* 如果您使用 16 位精度（精度=16），Lightning 将自动处理优化器。\n",
    ">* 如果您使用多个优化器，则 training_step() 将有一个额外的 optimizer_idx 参数。\n",
    ">* 如果您使用 torch.optim.LBFGS，Lightning 会自动为您处理关闭功能。\n",
    ">* 如果使用多个优化器，则在每个训练步骤仅针对当前优化器的参数计算梯度。\n",
    ">* 如果您需要控制这些优化器执行或覆盖默认 .step() 计划的频率，请覆盖 optimizer_step() 挂钩。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-franklin",
   "metadata": {},
   "source": [
    "### foward\n",
    "```\n",
    "LightningModule.forward(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-sound",
   "metadata": {},
   "source": [
    "与 `torch.nn.Module.forward()` 相同。\n",
    "\n",
    "参数\n",
    "* `*args` – 无论你决定传递给 `forward` 方法。\n",
    "* `**kwargs` – 关键字参数也是可能的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-packaging",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "任何\n",
    "\n",
    "返回  \n",
    "你的模型输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-vampire",
   "metadata": {},
   "source": [
    "### freeze\n",
    "```\n",
    "LightningModule.freeze()\n",
    "```\n",
    "\n",
    "冻结所有参数以进行推理。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLightningModule(...)\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-picking",
   "metadata": {},
   "source": [
    "### log\n",
    "```\n",
    "LightningModule.log(name, value, prog_bar=False, logger=True, on_step=None, on_epoch=None, reduce_fx='default', tbptt_reduce_fx=None, tbptt_pad_token=None, enable_graph=False, sync_dist=False, sync_dist_op=None, sync_dist_group=None, add_dataloader_idx=True, batch_size=None, metric_attribute=None, rank_zero_only=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-dealer",
   "metadata": {},
   "source": [
    "记录一个键值对。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.log('train_loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-louisiana",
   "metadata": {},
   "source": [
    "每个钩子的默认行为如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-frost",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gtwxujqipkj617p0u075w02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-russia",
   "metadata": {},
   "source": [
    "**参数：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-affect",
   "metadata": {},
   "source": [
    "name – 登录键\n",
    "* value – 要记录的值。 可以是浮点数、张量、度量或前者的字典。\n",
    "* prog_bar – 如果 True 记录到进度条\n",
    "* logger – 如果 True 记录到记录器\n",
    "* on_step – 如果 True 在此步骤记录。 在training_step 没有自动记录但没有validation/test_step\n",
    "* on_epoch – 如果 True 记录纪元累积指标。 没有在 val/test 步骤自动记录，但不是 training_step\n",
    "* reduce_fx – Epoch结束时步长值的减少函数。 默认情况下，torch.mean()。\n",
    "* enable_graph – 如果为 True，则不会自动分离图形\n",
    "* sync_dist – 如果为 True，则减少跨 GPU/TPU 的指标\n",
    "* sync_dist_group – 要同步的 ddp 组\n",
    "* add_dataloader_idx – 如果为 True，则将当前数据加载器的索引附加到名称（使用多个时）。 如果为 False，则用户需要为每个数据加载器提供唯一名称，以免混合值\n",
    "* batch_size – 当前批次大小。 这将直接从加载的批次中推断出来，但某些数据结构可能需要显式提供它。\n",
    "* metric_attribute – 为了恢复度量状态，Lightning 需要模型中的 torchmetrics.Metric 的引用。 如果它是模型属性，则会自动找到它。\n",
    "* rank_zero_only – 该值是否仅记录在 rank 0 上。这将防止同步，因为并非所有进程都会执行此日志调用，因此会产生死锁。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-microwave",
   "metadata": {},
   "source": [
    "### log_dict\n",
    "```\n",
    "LightningModule.log_dict(dictionary, prog_bar=False, logger=True, on_step=None, on_epoch=None, reduce_fx='default', tbptt_reduce_fx=None, tbptt_pad_token=None, enable_graph=False, sync_dist=False, sync_dist_op=None, sync_dist_group=None, add_dataloader_idx=True, batch_size=None, rank_zero_only=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-contact",
   "metadata": {},
   "source": [
    "一次记录一个值字典。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'loss': loss, 'acc': acc, ..., 'metric_n': metric_n}\n",
    "self.log_dict(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-legislation",
   "metadata": {},
   "source": [
    "参数:\n",
    "* dictionary (Mapping[str, Union[Metric, Tensor, Number, Mapping[str, Union[Metric, Tensor, Number]]]]) – 键值对。 值可以是浮点数、张量、度量或前者的字典。\n",
    "* prog_bar (bool) – 如果 True 记录到进度库\n",
    "* logger (bool) – 如果 True 记录到记录器\n",
    "* on_step (Optional[bool]) – 如果 True 在此步骤记录。 training_step 没有自动记录，但没有验证/test_step\n",
    "* on_epoch (Optional[bool]) – 如果 True 记录纪元累积指标。 没有自动记录 val/test 步骤但不是 training_step\n",
    "* reduce_fx (Union[str, Callable]) – 纪元结束时步长值的减少函数。 默认情况下，torch.mean()。\n",
    "* enable_graph (bool) – 如果为 True，则不会自动分离图形\n",
    "* sync_dist (bool) – 如果为 True，则减少跨 GPU/TPU 的指标\n",
    "* sync_dist_group (Optional[Any]) – ddp 组同步\n",
    "* add_dataloader_idx (bool) – 如果为 True，则将当前数据加载器的索引附加到名称（使用多个时）。 如果为 False，则用户需要为每个数据加载器提供唯一名称，以免混合值\n",
    "* batch_size (Optional[int]) – 当前批次大小。 这将直接从加载的批次中推断出来，但某些数据结构可能需要显式提供它。\n",
    "* rank_zero_only (Optional[bool]) – 该值是否仅记录在 rank 0 上。这将防止同步，因为并非所有进程都会执行此日志调用，因此会产生死锁。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-colon",
   "metadata": {},
   "source": [
    "### manual_backward\n",
    "```\n",
    "LightningModule.manual_backward(loss, *args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-prayer",
   "metadata": {},
   "source": [
    "手动进行优化时，直接从您的 `training_step()` 调用它。 通过使用它，Lightning 可以确保在使用混合精度时应用所有正确的缩放比例。\n",
    "\n",
    "有关更多示例，请参阅手动优化。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(...):\n",
    "    opt = self.optimizers()\n",
    "    loss = ...\n",
    "    opt.zero_grad()\n",
    "    # 自动应用缩放等...\n",
    "    self.manual_backward(loss)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-specific",
   "metadata": {},
   "source": [
    "参数\n",
    "* `loss (Tensor)` – 计算梯度的张量。 必须附上图表。\n",
    "* `*args` – 要转发到`backward（）`的其他位置参数\n",
    "* `**kwargs` – 要转发到 `backward()` 的其他关键字参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-prince",
   "metadata": {},
   "source": [
    "### print\n",
    "```\n",
    "LightningModule.print(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-queensland",
   "metadata": {},
   "source": [
    "仅从进程 0 打印。在任何分布式模式下使用它只记录一次。\n",
    "\n",
    "参数\n",
    "* `*args` – 要打印的东西。 与 Python 的内置打印功能相同。\n",
    "* `**kwargs` – 与 Python 的内置打印功能相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-grant",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    self.print(x, 'in forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-madonna",
   "metadata": {},
   "source": [
    "### predict_step\n",
    "```\n",
    "LightningModule.predict_step(batch, batch_idx, dataloader_idx=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-alpha",
   "metadata": {},
   "source": [
    "在 `predict()` 期间调用的步进函数。 默认情况下，它调用 `forward()`。 覆盖以添加任何处理逻辑。\n",
    "\n",
    "`predict_step()` 用于在多设备上扩展推理。\n",
    "\n",
    "为了防止 OOM 错误，可以使用 BasePredictionWriter 回调在每批之后或在 epoch 结束时将预测写入磁盘或数据库。\n",
    "\n",
    "BasePredictionWriter 应该在使用基于 spawn 的加速器时使用。 这种情况发生在 `Trainer(accelerator=\"ddp_spawn\")` 或使用 `Trainer(tpu_cores=8)` 在 8 个 TPU 核心上训练，因为不会返回预测。\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(LightningModule):\n",
    "\n",
    "    def predicts_step(self, batch, batch_idx, dataloader_idx):\n",
    "        return self(batch)\n",
    "\n",
    "dm = ...\n",
    "model = MyModel()\n",
    "trainer = Trainer(gpus=2)\n",
    "predictions = trainer.predict(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-quarter",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch（任何）– 当前批次\n",
    "* batch_idx (int) – 当前批次的索引\n",
    "* dataloader_idx (Optional[int]) – 当前数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-spice",
   "metadata": {},
   "source": [
    "返回  \n",
    "预测输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-racing",
   "metadata": {},
   "source": [
    "### save_hyperparameters\n",
    "```\n",
    "LightningModule.save_hyperparameters(*args, ignore=None, frame=None, logger=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-hughes",
   "metadata": {},
   "source": [
    "将参数保存到 hparams 属性。\n",
    "\n",
    "参数\n",
    "* args – dict、NameSpace 或 OmegaConf 的单个对象或来自 __init__ 类的字符串名称或参数\n",
    "* ignore (Union[Sequence[str], str, None]) – 要忽略的类 __init__ 中的参数名称或参数名称列表\n",
    "* frame (Optional[frame]) – 一个框架对象。 默认为无\n",
    "* logger (bool) – 是否将超参数发送到记录器。 默认值：真"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-integrity",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManuallyArgsModel(HyperparametersMixin):\n",
    "    def __init__(self, arg1, arg2, arg3):\n",
    "        super().__init__()\n",
    "        # 手动分配参数\n",
    "        self.save_hyperparameters('arg1', 'arg3')\n",
    "    def forward(self, *args, **kwargs):\n",
    "        ...\n",
    "model = ManuallyArgsModel(1, 'abc', 3.14)\n",
    "model.hparams\n",
    "\"arg1\": 1\n",
    "\"arg3\": 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomaticArgsModel(HyperparametersMixin):\n",
    "    def __init__(self, arg1, arg2, arg3):\n",
    "        super().__init__()\n",
    "        # 等效自动\n",
    "        self.save_hyperparameters()\n",
    "    def forward(self, *args, **kwargs):\n",
    "        ...\n",
    "model = AutomaticArgsModel(1, 'abc', 3.14)\n",
    "model.hparams\n",
    "\"arg1\": 1\n",
    "\"arg2\": abc\n",
    "\"arg3\": 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleArgModel(HyperparametersMixin):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        # 手动分配单个参数\n",
    "        self.save_hyperparameters(params)\n",
    "    def forward(self, *args, **kwargs):\n",
    "        ...\n",
    "model = SingleArgModel(Namespace(p1=1, p2='abc', p3=3.14))\n",
    "model.hparams\n",
    "\"p1\": 1\n",
    "\"p2\": abc\n",
    "\"p3\": 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManuallyArgsModel(HyperparametersMixin):\n",
    "    def __init__(self, arg1, arg2, arg3):\n",
    "        super().__init__()\n",
    "        # 将要忽略的参数作为字符串或在列表中传递\n",
    "        self.save_hyperparameters(ignore='arg2')\n",
    "    def forward(self, *args, **kwargs):\n",
    "        ...\n",
    "model = ManuallyArgsModel(1, 'abc', 3.14)\n",
    "model.hparams\n",
    "\"arg1\": 1\n",
    "\"arg3\": 3.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-priority",
   "metadata": {},
   "source": [
    "### test_step\n",
    "```\n",
    "LightningModule.test_step(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-literature",
   "metadata": {},
   "source": [
    "对来自测试集的单批数据进行操作。 在此步骤中，您通常会生成示例或计算任何感兴趣的内容，例如准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些调用的伪代码\n",
    "test_outs = []\n",
    "for test_batch in test_data:\n",
    "    out = test_step(test_batch)\n",
    "    test_outs.append(out)\n",
    "test_epoch_end(test_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-harrison",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch (Tensor | (Tensor, …) | [Tensor, …]) – DataLoader 的输出。 张量、元组或列表。\n",
    "* batch_idx (int) – 该批次的索引。\n",
    "* dataloader_idx (int) – 生成此批次的数据加载器的索引（仅当使用多个测试数据加载器时）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-devil",
   "metadata": {},
   "source": [
    "返回类型\n",
    "联合[张量，字典[str，任何]，无]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-stuff",
   "metadata": {},
   "source": [
    "返回  \n",
    "任何。\n",
    "* 任何对象或值\n",
    "* 无 - 测试将跳到下一批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果您有一个测试数据加载器：\n",
    "def test_step(self, batch, batch_idx):\n",
    "    ...\n",
    "\n",
    "\n",
    "# 如果您有多个测试数据加载器：\n",
    "def test_step(self, batch, batch_idx, dataloader_idx):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-harmony",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: 单个测试数据集\n",
    "def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "\n",
    "    # 实现你自己的\n",
    "    out = self(x)\n",
    "    loss = self.loss(out, y)\n",
    "\n",
    "    # 记录 6 个示例图像\n",
    "    # 或生成的文本...或其他\n",
    "    sample_imgs = x[:6]\n",
    "    grid = torchvision.utils.make_grid(sample_imgs)\n",
    "    self.logger.experiment.add_image('example_images', grid, 0)\n",
    "\n",
    "    # 计算acc\n",
    "    labels_hat = torch.argmax(out, dim=1)\n",
    "    test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n",
    "\n",
    "    # 记录输出！\n",
    "    self.log_dict({'test_loss': loss, 'test_acc': test_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-musician",
   "metadata": {},
   "source": [
    "如果您传入多个测试数据加载器，则 test_step() 将有一个额外的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 2: 多个测试数据加载器\n",
    "def test_step(self, batch, batch_idx, dataloader_idx):\n",
    "    # dataloader_idx 告诉您这是哪个数据集。\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-piece",
   "metadata": {},
   "source": [
    "> 如果不需要测试，则不需要实现此方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-fleece",
   "metadata": {},
   "source": [
    "> 当 test_step() 被调用时，模型已被置于 eval 模式并且 PyTorch 梯度已被禁用。 在测试阶段结束时，模型返回训练模式并启用梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-korea",
   "metadata": {},
   "source": [
    "### test_step_end\n",
    "```\n",
    "LightningModule.test_step_end(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-humidity",
   "metadata": {},
   "source": [
    "在使用 dp 或 ddp2 进行测试时使用此选项，因为 test_step() 将仅对批处理的一部分进行操作。 但是，这仍然是可选的，并且仅在诸如 softmax 或 NCE 损失之类的情况下才需要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-science",
   "metadata": {},
   "source": [
    "> 如果您稍后切换到 ddp 或其他某种模式，它仍会被调用，因此您不必更改代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode\n",
    "sub_batches = split_batches_for_dp(batch)\n",
    "batch_parts_outputs = [test_step(sub_batch) for sub_batch in sub_batches]\n",
    "test_step_end(batch_parts_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-gazette",
   "metadata": {},
   "source": [
    "参数\n",
    "* `batch_parts_outputs` – 您在 test_step() 中为每个批处理部分返回的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-tucson",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Union[Tensor, Dict[str, Any], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 没有 test_step_end\n",
    "# 如果在DP或者DDP2中使用，这个batch是1/num_gpus大\n",
    "def test_step(self, batch, batch_idx):\n",
    "    # 批次为 1/num_gpus 大\n",
    "    x, y = batch\n",
    "\n",
    "    out = self(x)\n",
    "    loss = self.softmax(out)\n",
    "    self.log(\"test_loss\", loss)\n",
    "\n",
    "\n",
    "# --------------\n",
    "# 使用 test_step_end 对整批进行 softmax\n",
    "def test_step(self, batch, batch_idx):\n",
    "    # 批次为 1/num_gpus 大\n",
    "    x, y = batch\n",
    "\n",
    "    out = self.encoder(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def test_step_end(self, output_results):\n",
    "    # 这现在是批次的全尺寸\n",
    "    all_test_step_outs = output_results.out\n",
    "    loss = nce_loss(all_test_step_outs)\n",
    "    self.log(\"test_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-manner",
   "metadata": {},
   "source": [
    "### test_epoch_end\n",
    "```\n",
    "LightningModule.test_epoch_end(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-premises",
   "metadata": {},
   "source": [
    "在测试Epoch结束时调用所有测试步骤的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些调用的伪代码\n",
    "test_outs = []\n",
    "for test_batch in test_data:\n",
    "    out = test_step(test_batch)\n",
    "    test_outs.append(out)\n",
    "test_epoch_end(test_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-april",
   "metadata": {},
   "source": [
    "参数  \n",
    "输出 (List[Union[Tensor, Dict[str, Any]]]) – 您在 test_step_end() 中定义的输出列表，或者如果有多个数据加载器，则包含每个数据加载器的输出列表的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-wells",
   "metadata": {},
   "source": [
    "> 如果您没有定义 test_step()，则不会调用它。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-ukraine",
   "metadata": {},
   "source": [
    "例子\n",
    "\n",
    "使用单个数据加载器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_end(self, outputs):\n",
    "    # 对所有测试批次的输出做一些事情\n",
    "    all_test_preds = test_step_outputs.predictions\n",
    "\n",
    "    some_result = calc_all_results(all_test_preds)\n",
    "    self.log(some_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-offer",
   "metadata": {},
   "source": [
    "对于多个数据加载器，输出将是一个列表列表。 外部列表包含每个数据加载器的一个条目，而内部列表包含该数据加载器的每个测试步骤的单独输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_end(self, outputs):\n",
    "    final_value = 0\n",
    "    for dataloader_outputs in outputs:\n",
    "        for test_step_out in dataloader_outputs:\n",
    "            # do something\n",
    "            final_value += test_step_out\n",
    "\n",
    "    self.log(\"final_metric\", final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-assignment",
   "metadata": {},
   "source": [
    "### to_onnx\n",
    "```\n",
    "LightningModule.to_onnx(file_path, input_sample=None, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-census",
   "metadata": {},
   "source": [
    "以 ONNX 格式保存模型。\n",
    "\n",
    "参数\n",
    "* `file_path (Union[str, Path])` – onnx 模型应保存到的文件路径。\n",
    "* `input_sample (Optional[Any])` – 用于跟踪的输入。 默认值：无（使用 self.example_input_array）\n",
    "* `**kwargs – 将传递给 torch.onnx.export` 函数。\n",
    "\n",
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(in_features=64, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as tmpfile:\n",
    "    model = SimpleModel()\n",
    "    input_sample = torch.randn((1, 64))\n",
    "    model.to_onnx(tmpfile.name, input_sample, export_params=True)\n",
    "    os.path.isfile(tmpfile.name)\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-quantum",
   "metadata": {},
   "source": [
    "### to_torchscript\n",
    "```\n",
    "LightningModule.to_torchscript(file_path=None, method='script', example_inputs=None, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-requirement",
   "metadata": {},
   "source": [
    "默认情况下将整个模型编译为 ScriptModule。 如果要使用跟踪，请提供参数 method='trace' 并确保提供了 example_inputs 参数，或者模型设置了 example_input_array。 如果您想自定义脚本化模块，您应该覆盖此方法。 如果您想返回多个模块，我们建议使用字典。\n",
    "\n",
    "参数\n",
    "* `file_path (Union[str, Path, None])` – 保存火炬脚本的路径。 默认值：无（不保存文件）。\n",
    "* `method (Optional[str])` – 是否使用 TorchScript 的脚本或跟踪方法。 默认值：‘脚本’\n",
    "* `example_inputs (Optional[Any])` – 当方法设置为“trace”时用于进行跟踪的输入。 默认值：无（使用 `example_input_array`）\n",
    "* `**kwargs` – 将传递给 `torch.jit.script()` 或 `torch.jit.trace()`` 函数的附加参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-abuse",
   "metadata": {},
   "source": [
    "> * 需要实现 forward() 方法。  \n",
    "> * 导出的脚本将设置为评估模式。  \n",
    "> * 建议您安装最新支持的 PyTorch 版本以不受限制地使用此功能。 另请参阅 torch.jit 文档了解支持的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-moisture",
   "metadata": {},
   "source": [
    "例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(in_features=64, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "model = SimpleModel()\n",
    "torch.jit.save(model.to_torchscript(), \"model.pt\")  \n",
    "os.path.isfile(\"model.pt\")  \n",
    "torch.jit.save(model.to_torchscript(file_path=\"model_trace.pt\", method='trace', \n",
    "                                    example_inputs=torch.randn(1, 64)))  \n",
    "os.path.isfile(\"model_trace.pt\")  \n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-banks",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Union[ScriptModule, Dict[str, ScriptModule]]\n",
    "\n",
    "返回  \n",
    "无论 `file_path` 是否定义，此 LightningModule 作为 torchscript。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-youth",
   "metadata": {},
   "source": [
    "### training_step\n",
    "```\n",
    "LightningModule.training_step(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-february",
   "metadata": {},
   "source": [
    "在这里你计算并返回训练损失和一些额外的指标，例如 进度条或记录器。\n",
    "\n",
    "参数\n",
    "* `batch (Tensor | (Tensor, …) | [Tensor, …])` – DataLoader 的输出。 张量、元组或列表。\n",
    "* `batch_idx (int)` – 该批次的整数显示索引\n",
    "* `optimizer_idx (int)` – 当使用多个优化器时，这个参数也会出现。\n",
    "* `hiddens (Tensor)` – 如果 `truncated_bptt_steps > 0`，则传入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-benefit",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Union[Tensor, Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-mainstream",
   "metadata": {},
   "source": [
    "返回\n",
    "任何。\n",
    "* Tensor - 损失张量\n",
    "* dict - 字典。 可以包含任何键，但必须包含键“loss”\n",
    "* 无 - 训练将跳到下一批"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-student",
   "metadata": {},
   "source": [
    "> 多 GPU 或 TPU 或启用 16 位精度当前不支持返回 None。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-tooth",
   "metadata": {},
   "source": [
    "在这一步中，您通常会进行前向传递并计算批次的损失。 你还可以做更有趣的事情，比如多次向前传球或特定于模型的东西。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    x, y, z = batch\n",
    "    out = self.encoder(x)\n",
    "    loss = self.loss(out, x)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-identification",
   "metadata": {},
   "source": [
    "如果您定义了多个优化器，则将使用附加的 optimizer_idx 参数调用此步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple optimizers (e.g.: GANs)\n",
    "def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "    if optimizer_idx == 0:\n",
    "        # do training_step with encoder\n",
    "        ...\n",
    "    if optimizer_idx == 1:\n",
    "        # do training_step with decoder\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-gasoline",
   "metadata": {},
   "source": [
    "如果您通过时间添加截断的反向传播，您还将获得带有上一步隐藏状态的附加参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated back-propagation through time\n",
    "def training_step(self, batch, batch_idx, hiddens):\n",
    "    # hiddens are the hidden states from the previous truncated backprop step\n",
    "    ...\n",
    "    out, hiddens = self.lstm(data, hiddens)\n",
    "    ...\n",
    "    return {\"loss\": loss, \"hiddens\": hiddens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-magnet",
   "metadata": {},
   "source": [
    "> 进度条中显示的损失值在最后一个值上进行了平滑（平均），因此它不同于训练/验证步骤中返回的实际损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-seminar",
   "metadata": {},
   "source": [
    "### training_step_end\n",
    "```\n",
    "LightningModule.training_step_end(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-framing",
   "metadata": {},
   "source": [
    "在使用 dp 或 ddp2 进行训练时使用此选项，因为 training_step() 将仅对批次的一部分进行操作。 但是，这仍然是可选的，并且仅在诸如 softmax 或 NCE 损失之类的情况下才需要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-florist",
   "metadata": {},
   "source": [
    "> 如果您稍后切换到 ddp 或其他一些模式，它仍然会被调用，这样您就不必更改您的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode\n",
    "sub_batches = split_batches_for_dp(batch)\n",
    "batch_parts_outputs = [training_step(sub_batch) for sub_batch in sub_batches]\n",
    "training_step_end(batch_parts_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-amazon",
   "metadata": {},
   "source": [
    "参数  \n",
    "batch_parts_outputs – 您在 training_step 中为每个批次部分返回的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-design",
   "metadata": {},
   "source": [
    "当使用 dp/ddp2 分布式后端时，只有一部分批次在 training_step 中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    # batch is 1/num_gpus big\n",
    "    x, y = batch\n",
    "\n",
    "    out = self(x)\n",
    "\n",
    "    # softmax 仅使用分母中批次的一部分\n",
    "    loss = self.softmax(out)\n",
    "    loss = nce_loss(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-trailer",
   "metadata": {},
   "source": [
    "如果你想对批次的所有部分做一些事情，那么使用这个方法来做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    # batch is 1/num_gpus big\n",
    "    x, y = batch\n",
    "\n",
    "    out = self.encoder(x)\n",
    "    return {\"pred\": out}\n",
    "\n",
    "\n",
    "def training_step_end(self, training_step_outputs):\n",
    "    gpu_0_pred = training_step_outputs[0][\"pred\"]\n",
    "    gpu_1_pred = training_step_outputs[1][\"pred\"]\n",
    "    gpu_n_pred = training_step_outputs[n][\"pred\"]\n",
    "\n",
    "    # 这个 softmax 现在使用完整的批处理\n",
    "    loss = nce_loss([gpu_0_pred, gpu_1_pred, gpu_n_pred])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-bread",
   "metadata": {},
   "source": [
    "### training_epoch_end\n",
    "```\n",
    "LightningModule.training_epoch_end(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-january",
   "metadata": {},
   "source": [
    "在训练阶段结束时使用所有训练步骤的输出调用。 如果您需要对 `training_step()` 返回的所有输出执行某些操作，请使用此选项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pseudocode for these calls\n",
    "train_outs = []\n",
    "for train_batch in train_data:\n",
    "    out = training_step(train_batch)\n",
    "    train_outs.append(out)\n",
    "training_epoch_end(train_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-median",
   "metadata": {},
   "source": [
    "参数  \n",
    "输出 (List[Union[Tensor, Dict[str, Any]]]) – 您在 training_step() 中定义的输出列表，或者如果有多个数据加载器，则包含每个数据加载器的输出列表的列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-gauge",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "None\n",
    "\n",
    "返回  \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-consumption",
   "metadata": {},
   "source": [
    "> 如果此方法未被覆盖，则不会调用此方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-federation",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch_end(self, training_step_outputs):\n",
    "    # 对所有 training_step 输出做一些事情\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-guatemala",
   "metadata": {},
   "source": [
    "对于多个数据加载器，输出将是一个列表列表。 外部列表包含每个数据加载器的一个条目，而内部列表包含该数据加载器的每个训练步骤的各个输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch_end(self, training_step_outputs):\n",
    "    for out in training_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-steel",
   "metadata": {},
   "source": [
    "### unfreeze\n",
    "```\n",
    "LightningModule.unfreeze()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-corps",
   "metadata": {},
   "source": [
    "解冻所有训练参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLightningModule(...)\n",
    "model.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-current",
   "metadata": {},
   "source": [
    "### validation_step\n",
    "```\n",
    "LightningModule.validation_step(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-filename",
   "metadata": {},
   "source": [
    "对验证集中的单批数据进行操作。 在此步骤中，您可能会生成示例或计算任何感兴趣的内容，例如准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pseudocode for these calls\n",
    "val_outs = []\n",
    "for val_batch in val_data:\n",
    "    out = validation_step(val_batch)\n",
    "    val_outs.append(out)\n",
    "validation_epoch_end(val_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-wales",
   "metadata": {},
   "source": [
    "参数\n",
    "* `batch (Tensor | (Tensor, …) | [Tensor, …])` – DataLoader 的输出。 张量、元组或列表。\n",
    "* `batch_idx (int)` – 该批次的索引\n",
    "* `dataloader_idx (int)` – 生成此批次的数据加载器的索引（仅当使用多个 val 数据加载器时）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-bunch",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Union[Tensor, Dict[str, Any], None]\n",
    "\n",
    "返回  \n",
    "任何对象或值\n",
    "无 - 验证将跳到下一批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode of order\n",
    "val_outs = []\n",
    "for val_batch in val_data:\n",
    "    out = validation_step(val_batch)\n",
    "    if defined(\"validation_step_end\"):\n",
    "        out = validation_step_end(out)\n",
    "    val_outs.append(out)\n",
    "val_outs = validation_epoch_end(val_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have one val dataloader:\n",
    "def validation_step(self, batch, batch_idx):\n",
    "    ...\n",
    "\n",
    "\n",
    "# if you have multiple val dataloaders:\n",
    "def validation_step(self, batch, batch_idx, dataloader_idx):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-commercial",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: 单个验证数据集\n",
    "def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "\n",
    "    # implement your own\n",
    "    out = self(x)\n",
    "    loss = self.loss(out, y)\n",
    "\n",
    "    # log 6 example images\n",
    "    # or generated text... or whatever\n",
    "    sample_imgs = x[:6]\n",
    "    grid = torchvision.utils.make_grid(sample_imgs)\n",
    "    self.logger.experiment.add_image('example_images', grid, 0)\n",
    "\n",
    "    # calculate acc\n",
    "    labels_hat = torch.argmax(out, dim=1)\n",
    "    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n",
    "\n",
    "    # log the outputs!\n",
    "    self.log_dict({'val_loss': loss, 'val_acc': val_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-bracket",
   "metadata": {},
   "source": [
    "如果传入多个 val 数据加载器，validation_step() 将有一个额外的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 2: 多个验证数据加载器\n",
    "def validation_step(self, batch, batch_idx, dataloader_idx):\n",
    "    # dataloader_idx 告诉您这是哪个数据集。\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-landscape",
   "metadata": {},
   "source": [
    "> 如果不需要验证，则不需要实现此方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-renewal",
   "metadata": {},
   "source": [
    "> 当调用validation_step() 时，模型已被置于评估模式并且PyTorch 梯度已被禁用。 在验证结束时，模型返回训练模式并启用梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-behalf",
   "metadata": {},
   "source": [
    "### validation_step_end\n",
    "```\n",
    "LightningModule.validation_step_end(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-aircraft",
   "metadata": {},
   "source": [
    "在使用 dp 或 ddp2 进行验证时使用此选项，因为 validation_step() 将仅对批处理的一部分进行操作。 但是，这仍然是可选的，并且仅在诸如 softmax 或 NCE 损失之类的情况下才需要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-harvest",
   "metadata": {},
   "source": [
    "如果您稍后切换到 ddp 或其他某种模式，它仍会被调用，因此您不必更改代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode\n",
    "sub_batches = split_batches_for_dp(batch)\n",
    "batch_parts_outputs = [validation_step(sub_batch) for sub_batch in sub_batches]\n",
    "validation_step_end(batch_parts_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-disabled",
   "metadata": {},
   "source": [
    "参数  \n",
    "batch_parts_outputs – 您在 validation_step() 中为每个批处理部分返回的内容。\n",
    "\n",
    "返回类型    \n",
    "Union[Tensor, Dict[str, Any], None]\n",
    "\n",
    "返回  \n",
    "没有或任何东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 没有validation_step_end\n",
    "# 如果在DP或者DDP2中使用，这个batch是1/num_gpus大\n",
    "def validation_step(self, batch, batch_idx):\n",
    "    # batch is 1/num_gpus big\n",
    "    x, y = batch\n",
    "\n",
    "    out = self.encoder(x)\n",
    "    loss = self.softmax(out)\n",
    "    loss = nce_loss(loss)\n",
    "    self.log(\"val_loss\", loss)\n",
    "\n",
    "\n",
    "# --------------\n",
    "# 使用validation_step_end 对整批进行softmax\n",
    "def validation_step(self, batch, batch_idx):\n",
    "    # batch is 1/num_gpus big\n",
    "    x, y = batch\n",
    "\n",
    "    out = self(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def validation_step_end(self, val_step_outputs):\n",
    "    for out in val_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-championship",
   "metadata": {},
   "source": [
    "#### validation_epoch_end\n",
    "```\n",
    "LightningModule.validation_epoch_end(outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-wedding",
   "metadata": {},
   "source": [
    "在验证时期结束时使用所有验证步骤的输出调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pseudocode for these calls\n",
    "val_outs = []\n",
    "for val_batch in val_data:\n",
    "    out = validation_step(val_batch)\n",
    "    val_outs.append(out)\n",
    "validation_epoch_end(val_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-calgary",
   "metadata": {},
   "source": [
    "参数  \n",
    "输出 (List[Union[Tensor, Dict[str, Any]]]) – 您在 validation_step() 中定义的输出列表，或者如果有多个数据加载器，则包含每个数据加载器的输出列表的列表。\n",
    "\n",
    "返回类型  \n",
    "没有任何\n",
    "\n",
    "返回。\n",
    "没有任何"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-element",
   "metadata": {},
   "source": [
    "> 如果你没有定义一个validation_step()，它不会被调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-colonial",
   "metadata": {},
   "source": [
    "例子\n",
    "\n",
    "使用单个数据加载器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch_end(self, val_step_outputs):\n",
    "    for out in val_step_outputs:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-trainer",
   "metadata": {},
   "source": [
    "对于多个数据加载器，输出将是一个列表列表。 外部列表包含每个数据加载器的一个条目，而内部列表包含该数据加载器的每个验证步骤的各个输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch_end(self, outputs):\n",
    "    for dataloader_output_result in outputs:\n",
    "        dataloader_outs = dataloader_output_result.dataloader_i_outputs\n",
    "\n",
    "    self.log(\"final_metric\", final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-scheme",
   "metadata": {},
   "source": [
    "## 属性\n",
    "\n",
    "这些是 LightningModule 中可用的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-poultry",
   "metadata": {},
   "source": [
    "### current_epoch\n",
    "\n",
    "现在的epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    if self.current_epoch == 0:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-beginning",
   "metadata": {},
   "source": [
    "### device\n",
    "\n",
    "模块所在的设备。 使用它来保持您的代码设备不可知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    z = torch.rand(2, 3, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-phrase",
   "metadata": {},
   "source": [
    "### global_rank\n",
    "\n",
    "此 LightningModule 的 global_rank。 Lightning 仅从 global_rank = 0 保存日志、权重等。您通常不需要使用此属性\n",
    "\n",
    "全局排名是指该 GPU 在所有 GPU 中的索引。 例如，如果使用 10 台机器，每台机器有 4 个 GPU，则第 10 台机器上的第 4 个 GPU 的 global_rank = 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-michigan",
   "metadata": {},
   "source": [
    "### global_step\n",
    "\n",
    "当前步骤（不重置每个 epoch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    self.logger.experiment.log_image(..., step=self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-monitor",
   "metadata": {},
   "source": [
    "### hparams\n",
    "\n",
    "通过 `__init__()` 传递的调用 `save_hyperparameters` 保存的参数\n",
    "可以通过 hparams 属性访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, learning_rate):\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "\n",
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-trigger",
   "metadata": {},
   "source": [
    "### logger\n",
    "\n",
    "当前正在使用的记录器（张量板或其他支持的记录器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    # 通用记录器（无论是张量板还是其他支持的记录器都相同）\n",
    "    self.logger\n",
    "\n",
    "    # 特定的记录器\n",
    "    tensorboard_logger = self.logger.experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-overhead",
   "metadata": {},
   "source": [
    "### local_rank\n",
    "\n",
    "此 LightningModule 的 local_rank。 Lightning 仅从 global_rank = 0 保存日志、权重等。您通常不需要使用此属性\n",
    "\n",
    "本地排名是指该机器上的排名。 例如，如果使用 10 台机器，则每台机器上索引 0 处的 GPU 的 local_rank = 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-wellington",
   "metadata": {},
   "source": [
    "### precision\n",
    "\n",
    "使用的精度类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    if self.precision == 16:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-glory",
   "metadata": {},
   "source": [
    "### trainer\n",
    "\n",
    "指向训练器的指针"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self):\n",
    "    max_steps = self.trainer.max_steps\n",
    "    any_flag = self.trainer.any_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-screen",
   "metadata": {},
   "source": [
    "### use_amp\n",
    "\n",
    "如果使用自动混合精度 (AMP)，则为真"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-poster",
   "metadata": {},
   "source": [
    "### automatic_optimization\n",
    "\n",
    "设置为 False 时，Lightning 不会自动执行优化过程。 这意味着您负责处理优化器。 但是，我们确实会注意精度和使用的任何加速器。\n",
    "\n",
    "有关详细信息，请参阅手动优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.automatic_optimization = False\n",
    "\n",
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    opt = self.optimizers(use_pl_optimizer=True)\n",
    "\n",
    "    loss = ...\n",
    "    opt.zero_grad()\n",
    "    self.manual_backward(loss)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-technical",
   "metadata": {},
   "source": [
    "仅当使用 2+ 优化器并且您知道如何正确执行优化过程时才建议这样做。 请注意，通过依赖 `optimizer_idx` 参数，自动优化仍然可以与多个优化器一起使用。 手动优化对于强化学习、稀疏编码和 GAN 研究等研究主题最有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.automatic_optimization = False\n",
    "\n",
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    # 使用 use_pl_optimizer=False 访问您的优化器。 默认为真\n",
    "    opt_a, opt_b = self.optimizers(use_pl_optimizer=True)\n",
    "\n",
    "    gen_loss = ...\n",
    "    opt_a.zero_grad()\n",
    "    self.manual_backward(gen_loss)\n",
    "    opt_a.step()\n",
    "\n",
    "    disc_loss = ...\n",
    "    opt_b.zero_grad()\n",
    "    self.manual_backward(disc_loss)\n",
    "    opt_b.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-magnitude",
   "metadata": {},
   "source": [
    "### example_input_array\n",
    "\n",
    "设置和访问 example_input_array ，它基本上是一个批处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.example_input_array = ...\n",
    "    self.generator = ...\n",
    "\n",
    "\n",
    "def on_train_epoch_end(self):\n",
    "    # 使用 example_input_array 生成一些图像\n",
    "    gen_images = self.generator(self.example_input_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-insertion",
   "metadata": {},
   "source": [
    "### datamodule\n",
    "\n",
    "设置或访问您的数据模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    num_training_samples = len(self.trainer.datamodule.train_dataloader())\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-scott",
   "metadata": {},
   "source": [
    "### model_size\n",
    "\n",
    "使用 LightningModule 中的 `self.model_size` 获取模型文件大小（以兆字节为单位）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-nancy",
   "metadata": {},
   "source": [
    "## truncated_bptt_steps\n",
    "\n",
    "截断的反向传播间隔在更长的序列中每 k 步执行一次反向传播。 这是通过将沿时间维度分割成大小为 k 的分割的训练批次传递给 training_step 来实现的。 为了保持相同的前向传播行为，所有隐藏状态都应该保持在每个时间维度分割之间。\n",
    "\n",
    "如果启用此选项，您的批次将自动被截断，并且训练器将对其应用截断的反向传播。\n",
    "\n",
    "（威廉姆斯等人。“一种有效的基于梯度的算法，用于循环网络轨迹的在线训练。”）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "class MyModel(LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        # batch_first 必须设置为 True\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        ...\n",
    "\n",
    "        # 重要提示：此属性激活随时间截断的反向传播\n",
    "        # 将此值设置为 2 会将批次拆分为大小为 2 的序列\n",
    "        self.truncated_bptt_steps = 2\n",
    "\n",
    "    # 通过时间截断反向传播\n",
    "    def training_step(self, batch, batch_idx, hiddens):\n",
    "        x, y = batch\n",
    "\n",
    "        # 必须更新训练步骤以接受 ``hiddens`` 参数\n",
    "        # hiddens 是前一个被截断的反向传播步骤的隐藏\n",
    "        out, hiddens = self.lstm(x, hiddens)\n",
    "\n",
    "        ...\n",
    "\n",
    "        return {\"loss\": ..., \"hiddens\": hiddens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-communication",
   "metadata": {},
   "source": [
    "Lightning 负责沿时间维度拆分您的批次。 它被假定为批次的第二个维度。 因此，在上面的示例中，我们设置了 batch_first=True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用第二个作为时间维度\n",
    "# (batch, time, ...)\n",
    "sub_batch = batch[0, 0:t, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-ratio",
   "metadata": {},
   "source": [
    "要修改批处理的拆分方式，请重载 pytorch_lightning.core.LightningModule.tbptt_split_batch()："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(LightningModule):\n",
    "    def tbptt_split_batch(self, batch, split_size):\n",
    "        # 对批次进行自己的拆分\n",
    "        return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-custom",
   "metadata": {},
   "source": [
    "## Hooks\n",
    "\n",
    "这是描述 fit() 结构的伪代码。 为简单起见，未表示每个函数的输入和输出。 请查看每个函数的 API 参考以获取更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self):\n",
    "    if global_rank == 0:\n",
    "        # prepare data is called on GLOBAL_ZERO only\n",
    "        prepare_data()\n",
    "\n",
    "    configure_callbacks()\n",
    "\n",
    "    with parallel(devices):\n",
    "        # devices can be GPUs, TPUs, ...\n",
    "        train_on_device(model)\n",
    "\n",
    "\n",
    "def train_on_device(model):\n",
    "    # called PER DEVICE\n",
    "    on_fit_start()\n",
    "    setup(\"fit\")\n",
    "    configure_optimizers()\n",
    "\n",
    "    on_pretrain_routine_start()\n",
    "    on_pretrain_routine_end()\n",
    "\n",
    "    # the sanity check runs here\n",
    "\n",
    "    on_train_start()\n",
    "    for epoch in epochs:\n",
    "        train_loop()\n",
    "    on_train_end()\n",
    "\n",
    "    on_fit_end()\n",
    "    teardown(\"fit\")\n",
    "\n",
    "\n",
    "def train_loop():\n",
    "    on_epoch_start()\n",
    "    on_train_epoch_start()\n",
    "\n",
    "    for batch in train_dataloader():\n",
    "        on_train_batch_start()\n",
    "\n",
    "        on_before_batch_transfer()\n",
    "        transfer_batch_to_device()\n",
    "        on_after_batch_transfer()\n",
    "\n",
    "        training_step()\n",
    "\n",
    "        on_before_zero_grad()\n",
    "        optimizer_zero_grad()\n",
    "\n",
    "        on_before_backward()\n",
    "        backward()\n",
    "        on_after_backward()\n",
    "\n",
    "        on_before_optimizer_step()\n",
    "        optimizer_step()\n",
    "\n",
    "        on_train_batch_end()\n",
    "\n",
    "        if should_check_val:\n",
    "            val_loop()\n",
    "    # end training epoch\n",
    "    training_epoch_end()\n",
    "\n",
    "    on_train_epoch_end()\n",
    "    on_epoch_end()\n",
    "\n",
    "\n",
    "def val_loop():\n",
    "    on_validation_model_eval()  # calls `model.eval()`\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    on_validation_start()\n",
    "    on_epoch_start()\n",
    "    on_validation_epoch_start()\n",
    "\n",
    "    for batch in val_dataloader():\n",
    "        on_validation_batch_start()\n",
    "\n",
    "        on_before_batch_transfer()\n",
    "        transfer_batch_to_device()\n",
    "        on_after_batch_transfer()\n",
    "\n",
    "        validation_step()\n",
    "\n",
    "        on_validation_batch_end()\n",
    "    validation_epoch_end()\n",
    "\n",
    "    on_validation_epoch_end()\n",
    "    on_epoch_end()\n",
    "    on_validation_end()\n",
    "\n",
    "    # set up for train\n",
    "    on_validation_model_train()  # calls `model.train()`\n",
    "    torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-letter",
   "metadata": {},
   "source": [
    "### backward\n",
    "```\n",
    "LightningModule.backward(loss, optimizer, optimizer_idx, *args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-portland",
   "metadata": {},
   "source": [
    "调用以对 training_step() 中返回的损失执行向后执行。 如果需要，请使用您自己的实现覆盖此挂钩。\n",
    "\n",
    "参数\n",
    "* loss (Tensor) – training_step() 返回的损失张量。 如果使用梯度累积，这里的损失保持归一化值（按 1 / 累积步骤缩放）。\n",
    "* optimizer (Optional[Optimizer]) – 当前使用的优化器。 如果使用手动优化，则无。\n",
    "* optimizer_idx (Optional[int]) – 当前使用的优化器的索引。 如果使用手动优化，则无。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, loss, optimizer, optimizer_idx):\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-spouse",
   "metadata": {},
   "source": [
    "### get_progress_bar_dict\n",
    "```\n",
    "LightningModule.get_progress_bar_dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-pressure",
   "metadata": {},
   "source": [
    "实现它以覆盖进度条中显示的默认项目。 默认情况下，它包括平均损失值、BPTT 的拆分索引（如果使用）和使用记录器时的实验版本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-supply",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gtx22wwgn8j6180044aa902.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-senator",
   "metadata": {},
   "source": [
    "以下是如何覆盖默认值的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress_bar_dict(self):\n",
    "    # 不显示版本号\n",
    "    items = super().get_progress_bar_dict()\n",
    "    items.pop(\"v_num\", None)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-guyana",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Dict[str, Union[int, str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-commissioner",
   "metadata": {},
   "source": [
    "返回  \n",
    "包含要显示在进度条中的项目的字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-tucson",
   "metadata": {},
   "source": [
    "### on_before_backward\n",
    "```\n",
    "ModelHooks.on_before_backward(loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-mercury",
   "metadata": {},
   "source": [
    "在 `loss.backward()` 之前调用。\n",
    "\n",
    "参数  \n",
    "`loss`（张量）——损失除以梯度积累的批次数，如果使用原生 AMP，则按比例缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-terminal",
   "metadata": {},
   "source": [
    "### on_after_backward\n",
    "```\n",
    "ModelHooks.on_after_backward()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-windows",
   "metadata": {},
   "source": [
    "在 `loss.backward()` 之后和优化器被执行之前调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-solution",
   "metadata": {},
   "source": [
    "> 如果使用原生 AMP，此时梯度不会被取消缩放。 如果您需要未缩放的梯度，请使用 on_before_optimizer_step。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-contrast",
   "metadata": {},
   "source": [
    "### on_before_zero_grad\n",
    "```\n",
    "ModelHooks.on_before_zero_grad(optimizer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-minute",
   "metadata": {},
   "source": [
    "在 training_step() 之后和 optimizer.zero_grad() 之前调用。\n",
    "\n",
    "在执行优化器步骤之后和归零梯度之前在训练循环中调用。 检查重量信息并更新重量的好地方。\n",
    "\n",
    "这就是它被调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in optimizers:\n",
    "    out = training_step(...)\n",
    "\n",
    "    model.on_before_zero_grad(optimizer) # < ---- 在这里调用\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-wholesale",
   "metadata": {},
   "source": [
    "参数  \n",
    "optimizer（optimizer）– 应该将其归零的优化器。\n",
    "\n",
    "返回类型  \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-calgary",
   "metadata": {},
   "source": [
    "### on_fit_start\n",
    "```\n",
    "ModelHooks.on_fit_start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-replication",
   "metadata": {},
   "source": [
    "在 fit 开始时调用。 如果在 DDP 上，它会在每个进程上调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-invitation",
   "metadata": {},
   "source": [
    "### on_fit_end\n",
    "```\n",
    "ModelHooks.on_fit_end()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-commercial",
   "metadata": {},
   "source": [
    "在拟合结束时调用。 如果在 DDP 上，它会在每个进程上调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-senate",
   "metadata": {},
   "source": [
    "### on_load_checkpoint\n",
    "```\n",
    "CheckpointHooks.on_load_checkpoint（检查点）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-ranch",
   "metadata": {},
   "source": [
    "由 Lightning 调用以恢复您的模型。 如果你用 on_save_checkpoint() 保存了一些东西，这是你恢复它的机会。\n",
    "\n",
    "参数  \n",
    "checkpoint (Dict[str, Any]) – 加载的检查点\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_load_checkpoint(self, checkpoint):\n",
    "    # 99% 的情况下你不需要实现这个方法\n",
    "    self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-orbit",
   "metadata": {},
   "source": [
    "Lightning 自动恢复全局步长、Epoch和训练状态，包括放大器缩放。 您无需恢复任何有关培训的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-algorithm",
   "metadata": {},
   "source": [
    "### on_save_checkpoint\n",
    "```\n",
    "CheckpointHooks.on_save_checkpoint(checkpoint)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-crystal",
   "metadata": {},
   "source": [
    "保存检查点时由闪电调用，让您有机会存储您可能想要保存的任何其他内容。\n",
    "\n",
    "参数  \n",
    "checkpoint (Dict[str, Any]) – 转储到文件之前的完整检查点字典。 这个钩子的实现可以在这个字典中插入额外的数据。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_save_checkpoint(self, checkpoint):\n",
    "    # 99% 的用例你不需要实现这个方法\n",
    "    checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-range",
   "metadata": {},
   "source": [
    "> Lightning 保存了训练的所有方面（epoch、全局步骤等），包括放大器缩放。 您无需存储任何有关培训的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-numbers",
   "metadata": {},
   "source": [
    "### on_train_start\n",
    "```\n",
    "ModelHooks.on_train_start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-classification",
   "metadata": {},
   "source": [
    "在健全性检查后在训练开始时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-oregon",
   "metadata": {},
   "source": [
    "### on_train_end\n",
    "```\n",
    "ModelHooks.on_train_end()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-reader",
   "metadata": {},
   "source": [
    "在记录器实验关闭之前在训练结束时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-heath",
   "metadata": {},
   "source": [
    "### on_validation_start\n",
    "```\n",
    "ModelHooks.on_validation_start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-visitor",
   "metadata": {},
   "source": [
    "在验证开始时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-corpus",
   "metadata": {},
   "source": [
    "### on_validation_end\n",
    "```\n",
    "ModelHooks.on_validation_end()\n",
    "```\n",
    "在验证结束时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-thumb",
   "metadata": {},
   "source": [
    "### on_pretrain_routine_start\n",
    "```\n",
    "ModelHooks.on_pretrain_routine_start()[来源]\n",
    "```\n",
    "在预训练例程开始时调用（在拟合和训练开始之间）。\n",
    "* fit\n",
    "* pretrain_routine start\n",
    "* pretrain_routine end\n",
    "* training_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-poster",
   "metadata": {},
   "source": [
    "### on_pretrain_routine_end\n",
    "```\n",
    "ModelHooks.on_pretrain_routine_end()[来源]\n",
    "```\n",
    "在训练前例程结束时调用（在拟合和训练开始之间）。\n",
    "* fit\n",
    "* pretrain_routine start\n",
    "* pretrain_routine end\n",
    "* training_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-headquarters",
   "metadata": {},
   "source": [
    "### on_test_batch_start\n",
    "```\n",
    "ModelHooks.on_test_batch_start(batch, batch_idx, dataloader_idx)\n",
    "```\n",
    "\n",
    "在该批次发生任何事情之前在测试循环中调用。\n",
    "\n",
    "参数\n",
    "* batch (Any) – 测试 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-today",
   "metadata": {},
   "source": [
    "### on_test_batch_end\n",
    "```\n",
    "ModelHooks.on_test_batch_end（输出，批次，batch_idx，dataloader_idx)\n",
    "```\n",
    "批处理后在测试循环中调用。\n",
    "\n",
    "参数\n",
    "* outputs (Union[Tensor, Dict[str, Any], None]) – test_step_end(test_step(x)) 的输出\n",
    "* batch (Any) – 测试 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-electricity",
   "metadata": {},
   "source": [
    "### on_test_epoch_start\n",
    "```\n",
    "ModelHooks.on_test_epoch_start()\n",
    "```\n",
    "在Epoch开始时在测试循环中调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-curtis",
   "metadata": {},
   "source": [
    "### on_test_epoch_end\n",
    "```\n",
    "ModelHooks.on_test_epoch_end()\n",
    "```\n",
    "在 epoch 结束时在测试循环中调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-warren",
   "metadata": {},
   "source": [
    "### on_test_start\n",
    "```\n",
    "ModelHooks.on_test_start()\n",
    "```\n",
    "在测试开始时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-prisoner",
   "metadata": {},
   "source": [
    "### on_test_end\n",
    "```\n",
    "ModelHooks.on_test_end()\n",
    "```\n",
    "在测试结束时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-mixer",
   "metadata": {},
   "source": [
    "### on_train_batch_start\n",
    "```\n",
    "ModelHooks.on_train_batch_start(batch, batch_idx, dataloader_idx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-valve",
   "metadata": {},
   "source": [
    "在该批次发生任何事情之前在训练循环中调用。\n",
    "\n",
    "如果您在此处返回 -1，您将跳过当前 epoch 剩余时间的训练。\n",
    "\n",
    "参数\n",
    "* batch (Any) – 训练 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次的索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-polish",
   "metadata": {},
   "source": [
    "### on_train_batch_end\n",
    "```\n",
    "ModelHooks.on_train_batch_end(outputs, batch, batch_idx, dataloader_idx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-vienna",
   "metadata": {},
   "source": [
    "在批处理之后在训练循环中调用。\n",
    "\n",
    "参数\n",
    "* outputs (Union[Tensor, Dict[str, Any]]) – training_step_end(training_step(x)) 的输出\n",
    "* batch (Any) – 训练 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次的索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-breath",
   "metadata": {},
   "source": [
    "### on_epoch_start\n",
    "```\n",
    "ModelHooks.on_epoch_start()\n",
    "```\n",
    "在任一训练/验证/测试时期开始时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-suffering",
   "metadata": {},
   "source": [
    "### on_epoch_end\n",
    "```\n",
    "ModelHooks.on_epoch_end()\n",
    "```\n",
    "当任一训练/验证/测试时期结束时调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-cemetery",
   "metadata": {},
   "source": [
    "### on_train_epoch_start\n",
    "```\n",
    "ModelHooks.on_train_epoch_start()\n",
    "```\n",
    "在 epoch 开始时在训练循环中调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-crowd",
   "metadata": {},
   "source": [
    "### on_train_epoch_end\n",
    "```\n",
    "ModelHooks.on_train_epoch_end()\n",
    "```\n",
    "在 epoch 结束时在训练循环中调用。\n",
    "\n",
    "要在 epoch 结束时访问所有批处理输出，请执行以下任一操作：\n",
    "1. 在 LightningModule 中实现 training_epoch_end 或\n",
    "2. 在 LightningModule 的属性上跨步骤缓存数据并在此挂钩中访问它们"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-denver",
   "metadata": {},
   "source": [
    "### on_validation_batch_start\n",
    "```\n",
    "ModelHooks.on_validation_batch_start(batch, batch_idx, dataloader_idx)\n",
    "```\n",
    "在该批次发生任何事情之前在验证循环中调用。\n",
    "\n",
    "参数\n",
    "* batch (Any) – 验证 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次的索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-southwest",
   "metadata": {},
   "source": [
    "### on_validation_batch_end\n",
    "```\n",
    "ModelHooks.on_validation_batch_end（输出，批次，batch_idx，dataloader_idx）\n",
    "```\n",
    "\n",
    "在批处理之后在验证循环中调用。\n",
    "\n",
    "参数\n",
    "* outputs (Union[Tensor, Dict[str, Any], None]) – validation_step_end(validation_step(x)) 的输出\n",
    "* batch (Any) – 验证 DataLoader 返回的批处理数据。\n",
    "* batch_idx (int) – 批次的索引\n",
    "* dataloader_idx (int) – 数据加载器的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-saying",
   "metadata": {},
   "source": [
    "### on_validation_epoch_start\n",
    "```\n",
    "ModelHooks.on_validation_epoch_start()\n",
    "```\n",
    "在纪元开始时在验证循环中调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-nebraska",
   "metadata": {},
   "source": [
    "### on_validation_epoch_end\n",
    "```\n",
    "ModelHooks.on_validation_epoch_end()\n",
    "```\n",
    "在纪元结束时在验证循环中调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-outline",
   "metadata": {},
   "source": [
    "### on_post_move_to_device\n",
    "```\n",
    "ModelHooks.on_post_move_to_device()\n",
    "```\n",
    "在调用 to() 之后在 parameter_validation 装饰器中调用。 这是将模块移动到设备后在模块之间绑定权重的好地方。 可在 TPU 上训练具有权重共享属性的模型时使用。\n",
    "\n",
    "解决了 TPU 上共享权重的处理：https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#xla-tensor-quirks\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_post_move_to_device(self):\n",
    "    self.decoder.weight = self.encoder.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-session",
   "metadata": {},
   "source": [
    "### on_validation_model_eval\n",
    "```\n",
    "ModelHooks.on_validation_model_eval()\n",
    "```\n",
    "在 val 循环期间将模型设置为 eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-smell",
   "metadata": {},
   "source": [
    "### on_validation_model_train\n",
    "```\n",
    "ModelHooks.on_validation_model_train()\n",
    "```\n",
    "将模型设置为在 val 循环期间进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-toolbox",
   "metadata": {},
   "source": [
    "### on_test_model_eval\n",
    "```\n",
    "ModelHooks.on_test_model_eval()\n",
    "```\n",
    "在测试循环期间将模型设置为 eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-authentication",
   "metadata": {},
   "source": [
    "### on_test_model_train\n",
    "```\n",
    "ModelHooks.on_test_model_train()\n",
    "```\n",
    "将模型设置为在测试循环期间进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-facility",
   "metadata": {},
   "source": [
    "### on_before_optimizer_step\n",
    "```\n",
    "ModelHooks.on_before_optimizer_step(optimizer, optimizer_idx)\n",
    "```\n",
    "在 optimizer.step() 之前调用。\n",
    "\n",
    "仅当不需要累积梯度时才调用钩子。 请参阅：accumulate_grad_batches。 如果使用本机 AMP，则在调用此钩子之前将不缩放损失。 有关渐变缩放的更多信息，请参阅这些文档。\n",
    "\n",
    "参数\n",
    "* optimizer(Optimizer) – 当前使用的优化器。\n",
    "* optimizer_idx (int) – 当前使用的优化器的索引。\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_before_optimizer_step(self, optimizer, optimizer_idx):\n",
    "    # 检查张量板中的梯度信息的示例\n",
    "    if self.trainer.global_step % 25 == 0:  # don't make the tf file huge\n",
    "        for k, v in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(\n",
    "                tag=k, values=v.grad, global_step=self.trainer.global_step\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-brazilian",
   "metadata": {},
   "source": [
    "### optimizer_step\n",
    "```\n",
    "LightningModule.optimizer_step(epoch=None, batch_idx=None, optimizer=None, optimizer_idx=None, optimizer_closure=None, on_tpu=None, using_native_amp=None, using_lbfgs=None)[source]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-transition",
   "metadata": {},
   "source": [
    "覆盖此方法以调整 Trainer 调用每个优化器的默认方式。 默认情况下，Lightning 会调用 step() 和 zero_grad()，如示例中所示，每个优化器都会调用一次。 当 Trainer(accumulate_grad_batches != 1) 时，在累积阶段不会调用此方法（和 zero_grad()）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-stake",
   "metadata": {},
   "source": [
    "> 如果您要覆盖此方法，请确保将 optimizer_closure 参数传递给 optimizer.step() 函数，如示例中所示。 这确保了 training_step()、optimizer.zero_grad()、backward() 在训练循环中被调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-score",
   "metadata": {},
   "source": [
    "参数\n",
    "* epoch (Optional[int]) – Current epoch\n",
    "* batch_idx (Optional[int]) – Index of current batch\n",
    "* optimizer (Optional[Optimizer]) – A PyTorch optimizer\n",
    "* optimizer_idx (Optional[int]) – 如果您使用了多个优化器，则此索引到该列表中。\n",
    "* optimizer_closure (Optional[Callable]) – Closure for all optimizers\n",
    "* on_tpu (Optional[bool]) – True if TPU backward is required\n",
    "* using_native_amp (Optional[bool]) – True if using native amp\n",
    "* using_lbfgs (Optional[bool]) – True if the matching optimizer is torch.optim.LBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-mixer",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT\n",
    "def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx,\n",
    "                   optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n",
    "    optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "# 优化器步骤的交替计划（即：GAN）\n",
    "def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx,\n",
    "                   optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n",
    "    # 更新生成器选择每一步\n",
    "    if optimizer_idx == 0:\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "    # 每 2 步更新鉴别器 opt\n",
    "    if optimizer_idx == 1:\n",
    "        if (batch_idx + 1) % 2 == 0 :\n",
    "            optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "    # ...\n",
    "    # add as many optimizers as you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-affect",
   "metadata": {},
   "source": [
    "这是另一个示例，展示了如何将其用于更高级的事情，例如学习率热身："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate warm-up\n",
    "def optimizer_step(\n",
    "    self,\n",
    "    epoch,\n",
    "    batch_idx,\n",
    "    optimizer,\n",
    "    optimizer_idx,\n",
    "    optimizer_closure,\n",
    "    on_tpu,\n",
    "    using_native_amp,\n",
    "    using_lbfgs,\n",
    "):\n",
    "    # warm up lr\n",
    "    if self.trainer.global_step < 500:\n",
    "        lr_scale = min(1.0, float(self.trainer.global_step + 1) / 500.0)\n",
    "        for pg in optimizer.param_groups:\n",
    "            pg[\"lr\"] = lr_scale * self.learning_rate\n",
    "\n",
    "    # update params\n",
    "    optimizer.step(closure=optimizer_closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-ministry",
   "metadata": {},
   "source": [
    "### optimizer_zero_grad\n",
    "```\n",
    "LightningModule.optimizer_zero_grad(epoch, batch_idx, optimizer, optimizer_idx)\n",
    "```\n",
    "\n",
    "覆盖此方法以更改 optimizer.zero_grad() 的默认行为。\n",
    "\n",
    "参数\n",
    "* epoch (int) – 当前纪元\n",
    "* batch_idx (int) – 当前批次的索引\n",
    "* optimizer（Optimizer）——一个 PyTorch 优化器\n",
    "* optimizer_idx (int) – 如果您使用了多个优化器，则该索引到该列表中。\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT\n",
    "def optimizer_zero_grad(self, epoch, batch_idx, optimizer, optimizer_idx):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# 将梯度设置为“None”而不是零以提高性能。\n",
    "def optimizer_zero_grad(self, epoch, batch_idx, optimizer, optimizer_idx):\n",
    "    optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-jewel",
   "metadata": {},
   "source": [
    "> 有关上述示例的说明，请参阅 torch.optim.Optimizer.zero_grad()。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-front",
   "metadata": {},
   "source": [
    "### prepare_data\n",
    "```\n",
    "LightningModule.prepare_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-springer",
   "metadata": {},
   "source": [
    "使用它来下载和准备数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-shock",
   "metadata": {},
   "source": [
    "> 不要为模型设置状态（改为使用设置），因为这不会在 DDP/TPU 中的每个 GPU 上调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-ghana",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(self):\n",
    "    # good\n",
    "    download_data()\n",
    "    tokenize()\n",
    "    etc()\n",
    "\n",
    "    # bad\n",
    "    self.split = data_split\n",
    "    self.some_state = some_other_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-adobe",
   "metadata": {},
   "source": [
    "在 DDP 中可以通过两种方式调用 prepare_data（使用 Trainer(prepare_data_per_node)）：\n",
    "\n",
    "1. 每个节点一次。 这是默认设置，仅在 LOCAL_RANK=0 时调用。\n",
    "2. 总共一次。 仅在 GLOBAL_RANK=0 时调用。\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT\n",
    "# 每个节点在该节点的 LOCAL_RANK=0 上调用一次\n",
    "Trainer(prepare_data_per_node=True)\n",
    "\n",
    "# 调用 GLOBAL_RANK=0（非常适合共享文件系统）\n",
    "Trainer(prepare_data_per_node=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-objective",
   "metadata": {},
   "source": [
    "> 不推荐使用 trainer 标志设置 prepare_data_per_node 并将在 v1.7.0 中删除。 请直接在 LightningDataModule 或 LightningModule 中设置 prepare_data_per_node。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-wholesale",
   "metadata": {},
   "source": [
    "这是在请求数据加载器之前调用的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_data()\n",
    "initialize_distributed()\n",
    "model.setup(stage)\n",
    "model.train_dataloader()\n",
    "model.val_dataloader()\n",
    "model.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-madison",
   "metadata": {},
   "source": [
    "### setup\n",
    "```\n",
    "DataHooks.setup(stage=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-fever",
   "metadata": {},
   "source": [
    "在拟合开始时调用（训练 + 验证）、验证、测试和预测。 当您需要动态构建模型或调整模型时，这是一个很好的钩子。 使用 DDP 时，每个进程都会调用此钩子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-pocket",
   "metadata": {},
   "source": [
    "参数  \n",
    "stage (Optional[str]) – either 'fit', 'validate', 'test', or 'predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-cameroon",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(...):\n",
    "    def __init__(self):\n",
    "        self.l1 = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        download_data()\n",
    "        tokenize()\n",
    "\n",
    "        # don't do this\n",
    "        self.something = else\n",
    "\n",
    "    def setup(stage):\n",
    "        data = Load_data(...)\n",
    "        self.l1 = nn.Linear(28, data.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-niger",
   "metadata": {},
   "source": [
    "### tbptt_split_batch\n",
    "```\n",
    "LightningModule.tbptt_split_batch(batch, split_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-oxide",
   "metadata": {},
   "source": [
    "在使用截断的时间反向传播时，必须沿时间维度拆分每个批次。 默认情况下，Lightning 会处理此问题，但对于自定义行为，请覆盖此功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-parallel",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch (Tensor) – Current batch\n",
    "* split_size (int) – The size of the split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-insight",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "列表\n",
    "\n",
    "返回\n",
    "批量拆分列表。 每个拆分将传递给 training_step() 以启用随时间截断的反向传播。 默认实现在dim=1（即时间dim）处拆分根级张量和序列。 它假设每次dim 的长度都相同。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tbptt_split_batch(self, batch, split_size):\n",
    "  splits = []\n",
    "  for t in range(0, time_dims[0], split_size):\n",
    "      batch_split = []\n",
    "      for i, x in enumerate(batch):\n",
    "          if isinstance(x, torch.Tensor):\n",
    "              split_x = x[:, t:t + split_size]\n",
    "          elif isinstance(x, collections.Sequence):\n",
    "              split_x = [None] * len(x)\n",
    "              for batch_idx in range(len(x)):\n",
    "                  split_x[batch_idx] = x[batch_idx][t:t + split_size]\n",
    "\n",
    "          batch_split.append(split_x)\n",
    "\n",
    "      splits.append(batch_split)\n",
    "\n",
    "  return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-sauce",
   "metadata": {},
   "source": [
    "> 如果 truncated_bptt_steps > 0，则在 on_batch_start() 之后在训练循环中调用。每个返回的批次拆分单独传递给 training_step()。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-visit",
   "metadata": {},
   "source": [
    "### teardown\n",
    "```\n",
    "DataHooks.teardown(stage=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-oxford",
   "metadata": {},
   "source": [
    "在拟合结束时调用（训练 + 验证）、验证、测试、预测或调整。\n",
    "\n",
    "参数  \n",
    "stage (Optional[str]) – 'fit'、'validate'、'test' 或 'predict'\n",
    "\n",
    "返回类型\n",
    "无"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-cream",
   "metadata": {},
   "source": [
    "### train_dataloader\n",
    "```\n",
    "DataHooks.train_dataloader()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-packing",
   "metadata": {},
   "source": [
    "实施一个或多个 PyTorch DataLoader 进行训练。\n",
    "\n",
    "返回类型  \n",
    "`Union[DataLoader, Sequence[DataLoader], Sequence[Sequence[DataLoader]], Sequence[Dict[str, DataLoader]], Dict[str, DataLoader], Dict[str, Dict[str, DataLoader]], Dict[str, Sequence[DataLoader]]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-school",
   "metadata": {},
   "source": [
    "返回  \n",
    "指定训练样本的 torch.utils.data.DataLoader 的集合。 如果有多个数据加载器，请参阅此页面。\n",
    "\n",
    "除非您将 reload_dataloaders_every_n_epochs 设置为正整数，否则您返回的数据加载器将不会重新加载。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-cinema",
   "metadata": {},
   "source": [
    "对于数据处理，请使用以下模式：\n",
    "* 在 prepare_data() 中下载\n",
    "* 在 setup() 中处理和拆分\n",
    "\n",
    "但是，以上仅是分布式处理所必需的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-allah",
   "metadata": {},
   "source": [
    "> 不要在 prepare_data 中分配状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-coupon",
   "metadata": {},
   "source": [
    "* fit()\n",
    "* …\n",
    "* prepare_data()\n",
    "* setup()\n",
    "* train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-caution",
   "metadata": {},
   "source": [
    "> Lightning 为分布式和任意硬件添加了正确的采样器。 无需自己设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-orbit",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single dataloader\n",
    "def train_dataloader(self):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (1.0,))])\n",
    "    dataset = MNIST(root='/path/to/mnist/', train=True, transform=transform,\n",
    "                    download=True)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=self.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "# multiple dataloaders, return as list\n",
    "def train_dataloader(self):\n",
    "    mnist = MNIST(...)\n",
    "    cifar = CIFAR(...)\n",
    "    mnist_loader = torch.utils.data.DataLoader(\n",
    "        dataset=mnist, batch_size=self.batch_size, shuffle=True\n",
    "    )\n",
    "    cifar_loader = torch.utils.data.DataLoader(\n",
    "        dataset=cifar, batch_size=self.batch_size, shuffle=True\n",
    "    )\n",
    "    # each batch will be a list of tensors: [batch_mnist, batch_cifar]\n",
    "    return [mnist_loader, cifar_loader]\n",
    "\n",
    "# multiple dataloader, return as dict\n",
    "def train_dataloader(self):\n",
    "    mnist = MNIST(...)\n",
    "    cifar = CIFAR(...)\n",
    "    mnist_loader = torch.utils.data.DataLoader(\n",
    "        dataset=mnist, batch_size=self.batch_size, shuffle=True\n",
    "    )\n",
    "    cifar_loader = torch.utils.data.DataLoader(\n",
    "        dataset=cifar, batch_size=self.batch_size, shuffle=True\n",
    "    )\n",
    "    # each batch will be a dict of tensors: {'mnist': batch_mnist, 'cifar': batch_cifar}\n",
    "    return {'mnist': mnist_loader, 'cifar': cifar_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-jordan",
   "metadata": {},
   "source": [
    "### val_dataloader\n",
    "```\n",
    "DataHooks.val_dataloader()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-occupation",
   "metadata": {},
   "source": [
    "实现一个或多个 PyTorch DataLoader 以进行验证。\n",
    "\n",
    "除非您将 reload_dataloaders_every_n_epochs 设置为正整数，否则您返回的数据加载器将不会重新加载。\n",
    "\n",
    "建议所有数据下载和准备都在 prepare_data() 中进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-township",
   "metadata": {},
   "source": [
    "* fit()\n",
    "* …\n",
    "* prepare_data()\n",
    "* train_dataloader()\n",
    "* val_dataloader()\n",
    "* test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-reservoir",
   "metadata": {},
   "source": [
    "> Lightning为分布式和任意硬件添加了正确的采样器，无需自己设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-gross",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "Union[DataLoader, Sequence[DataLoader]]\n",
    "\n",
    "返回：  \n",
    "A torch.utils.data.DataLoader or 它们的序列指定验证样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-creation",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_dataloader(self):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (1.0,))])\n",
    "    dataset = MNIST(root='/path/to/mnist/', train=False,\n",
    "                    transform=transform, download=True)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=self.batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return loader\n",
    "\n",
    "# can also return multiple dataloaders\n",
    "def val_dataloader(self):\n",
    "    return [loader_a, loader_b, ..., loader_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-planning",
   "metadata": {},
   "source": [
    "> 如果不需要验证数据集和validation_step()，则不需要实现此方法。\n",
    "\n",
    "> 在您返回多个验证数据加载器的情况下，validation_step() 将有一个参数 dataloader_idx 与此处的顺序匹配。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-companion",
   "metadata": {},
   "source": [
    "### test_dataloader\n",
    "```\n",
    "DataHooks.test_dataloader()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-growth",
   "metadata": {},
   "source": [
    "实现一个或多个 PyTorch DataLoader 进行测试。\n",
    "\n",
    "除非您将 `reload_dataloaders_every_n_epochs` 设置为正整数，否则您返回的数据加载器不会重新加载。\n",
    "\n",
    "对于数据处理，请使用以下模式：\n",
    "* 在 `prepare_data()` 中下载\n",
    "* 在 `setup()` 中处理和拆分\n",
    "\n",
    "但是，以上仅是分布式处理所必需的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-lafayette",
   "metadata": {},
   "source": [
    "> 不要在 prepare_data 中分配状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-handy",
   "metadata": {},
   "source": [
    "* fit()\n",
    "* …\n",
    "* prepare_data()\n",
    "* setup()\n",
    "* train_dataloader()\n",
    "* val_dataloader()\n",
    "* test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-deployment",
   "metadata": {},
   "source": [
    "> Lightning 为分布式和任意硬件添加了正确的采样器。 无需自己设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-knock",
   "metadata": {},
   "source": [
    "返回类型  \n",
    "联合[DataLoader, Sequence[DataLoader]]\n",
    "\n",
    "返回  \n",
    "torch.utils.data.DataLoader 或它们的序列指定测试样本。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataloader(self):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (1.0,))])\n",
    "    dataset = MNIST(root='/path/to/mnist/', train=False, transform=transform,\n",
    "                    download=True)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=self.batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return loader\n",
    "\n",
    "# can also return multiple dataloaders\n",
    "def test_dataloader(self):\n",
    "    return [loader_a, loader_b, ..., loader_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-blond",
   "metadata": {},
   "source": [
    "> 如果不需要测试数据集和 test_step()，则不需要实现此方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-supplier",
   "metadata": {},
   "source": [
    "> 如果您返回多个测试数据加载器，则 test_step() 将有一个参数 dataloader_idx 与此处的顺序匹配。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-booth",
   "metadata": {},
   "source": [
    "### transfer_batch_to_device\n",
    "```\n",
    "DataHooks.transfer_batch_to_device(batch, device, dataloader_idx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-insight",
   "metadata": {},
   "source": [
    "如果您的 DataLoader 返回包装在自定义数据结构中的张量，则覆盖此挂钩。\n",
    "\n",
    "下面列出的数据类型（以及它们的任意嵌套）是开箱即用的：\n",
    "* torch.Tensor 或任何实现 .to(...)\n",
    "* 列表\n",
    "* 字典\n",
    "* 元组\n",
    "* torchtext.data.batch.Batch\n",
    "\n",
    "对于其他任何事情，您需要定义如何将数据移动到目标设备（CPU、GPU、TPU 等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-spirit",
   "metadata": {},
   "source": [
    "> 这个钩子应该只传输数据而不修改它，也不应该将数据移动到任何其他设备而不是作为参数传入的设备（除非你知道你在做什么）。 要检查此钩子的当前执行状态，您可以使用 self.trainer.training/testing/validating/predicting 以便您可以根据需要添加不同的逻辑。\n",
    "\n",
    "> 该钩子仅在单 GPU 训练和 DDP（无数据并行）上运行。 数据并行支持将在不久的将来出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-compiler",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch (Any) – 需要传输到新设备的一批数据。\n",
    "* device (device) – PyTorch 中定义的目标设备。\n",
    "* dataloader_idx (int) – 批处理所属的数据加载器的索引。\n",
    "\n",
    "返回类型  \n",
    "任何\n",
    "\n",
    "返回。\n",
    "对新设备上数据的引用。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_batch_to_device(self, batch, device):\n",
    "    if isinstance(batch, CustomBatch):\n",
    "        # 将自定义数据结构中的所有张量移动到设备\n",
    "        batch.samples = batch.samples.to(device)\n",
    "        batch.targets = batch.targets.to(device)\n",
    "    else:\n",
    "        batch = super().transfer_batch_to_device(data, device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-chorus",
   "metadata": {},
   "source": [
    "### on_before_batch_transfer\n",
    "```\n",
    "DataHooks.on_before_batch_transfer(batch, dataloader_idx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-surname",
   "metadata": {},
   "source": [
    "覆盖以在批次传输到设备之前更改或应用批次扩充。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-shape",
   "metadata": {},
   "source": [
    "> 要检查此钩子的当前执行状态，您可以使用 self.trainer.training/testing/validating/predicting 以便您可以根据需要添加不同的逻辑。\n",
    "\n",
    "> 该钩子仅在单 GPU 训练和 DDP（无数据并行）上运行。 数据并行支持将在不久的将来出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-seminar",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch (Any) – 需要更改或扩充的一批数据。\n",
    "* dataloader_idx (int) – 批处理所属的数据加载器的索引。\n",
    "返回类型 \n",
    "任何\n",
    "\n",
    "返回  \n",
    "一批数据\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_before_batch_transfer(self, batch, dataloader_idx):\n",
    "    batch['x'] = transforms(batch['x'])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-process",
   "metadata": {},
   "source": [
    "### on_after_batch_transfer\n",
    "```\n",
    "DataHooks.on_after_batch_transfer(batch, dataloader_idx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-daughter",
   "metadata": {},
   "source": [
    "在将批次传输到设备后，覆盖以更改或应用批次扩充到您的批次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-essex",
   "metadata": {},
   "source": [
    "> 检查此钩子的当前执行状态，您可以使用 self.trainer.training/testing/validating/predicting 以便您可以根据需要添加不同的逻辑。\n",
    "\n",
    "> 该钩子仅在单 GPU 训练和 DDP（无数据并行）上运行。 数据并行支持将在不久的将来出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-dominant",
   "metadata": {},
   "source": [
    "参数\n",
    "* batch (Any) – 需要更改或扩充的一批数据。\n",
    "* dataloader_idx (int) – 批处理所属的数据加载器的索引。\n",
    "返回类型  \n",
    "任何\n",
    "\n",
    "返回  \n",
    "一批数据\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_after_batch_transfer(self, batch, dataloader_idx):\n",
    "    batch['x'] = gpu_transforms(batch['x'])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-preparation",
   "metadata": {},
   "source": [
    "### add_to_queue\n",
    "```\n",
    "LightningModule.add_to_queue(queue)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-tackle",
   "metadata": {},
   "source": [
    "将 trainer.callback_metrics 字典附加到给定的队列。 为了避免内存共享问题，我们将数据转换为 numpy。\n",
    "\n",
    "参数  \n",
    "queue (SimpleQueue) – 要追加数据的队列实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-prompt",
   "metadata": {},
   "source": [
    "### get_from_queue\n",
    "```\n",
    "LightningModule.get_from_queue(queue)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-grocery",
   "metadata": {},
   "source": [
    "从给定队列中检索 trainer.callback_metrics 字典。 为了保持一致性，我们将数据回传到 torch.Tensor。\n",
    "\n",
    "参数  \n",
    "queue (SimpleQueue) – 从哪里获取数据的队列实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
