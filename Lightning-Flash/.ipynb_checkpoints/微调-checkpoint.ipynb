{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbadfb98",
   "metadata": {},
   "source": [
    "微调（或迁移学习）是将在大型数据集上训练的模型调整为您的特定（可能小得多）数据集的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa28d8",
   "metadata": {},
   "source": [
    "# 术语\n",
    "\n",
    "以下是您需要熟悉的常用术语："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ba9df",
   "metadata": {},
   "source": [
    "|术语|定义|\n",
    "|----|----|\n",
    "|微调(Finetuning)|将在大型数据集上训练的模型调整为您的特定（可能更小）数据集的过程|\n",
    "|迁移学习（Transfer learning）|微调的通用名称|\n",
    "|骨干(Backbone)|在不同数据集上预训练的神经网络|\n",
    "|头（Head）|另一个神经网络（通常较小）将主干映射到您的特定数据集|\n",
    "|冻结(Freeze)|禁用模型的梯度更新（即：不学习）|\n",
    "|解冻(Unfreeze)|启用模型的梯度更新|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38aeb7d",
   "metadata": {},
   "source": [
    "# 在 Flash 中进行微调\n",
    "\n",
    "从快速入门指南。\n",
    "\n",
    "要使用任务进行微调：\n",
    "* 使用为任务定制的 DataModule 加载您的数据并组织它（例如：ImageClassificationData）。\n",
    "* 选择并初始化您的任务，其中内置了最先进的主干（例如：ImageClassifier）。\n",
    "* 初始化 flash.core.trainer.Trainer。\n",
    "* 选择微调策略（例如：“冻结”）并使用您的数据调用 flash.core.trainer.Trainer.finetune()。\n",
    "* 保存您的微调模型。\n",
    "\n",
    "这是一个微调的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67428cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import flash\n",
    "from flash.core.classification import Labels\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "\n",
    "# set the random seeds.\n",
    "seed_everything(42)\n",
    "\n",
    "# 1. 下载和组织数据\n",
    "download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", \"data/\")\n",
    "\n",
    "datamodule = ImageClassificationData.from_folders(\n",
    "    train_folder=\"data/hymenoptera_data/train/\",\n",
    "    val_folder=\"data/hymenoptera_data/val/\",\n",
    "    test_folder=\"data/hymenoptera_data/test/\",\n",
    ")\n",
    "\n",
    "# 2. 使用所需的任务构建模型\n",
    "model = ImageClassifier(backbone=\"resnet18\", num_classes=datamodule.num_classes)\n",
    "\n",
    "# 3. 创建训练器（运行一个 epoch 进行演示）\n",
    "trainer = flash.Trainer(max_epochs=1, gpus=torch.cuda.device_count())\n",
    "\n",
    "# 4. 微调模型\n",
    "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")\n",
    "\n",
    "# 5. 保存模型！\n",
    "trainer.save_checkpoint(\"image_classification_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c34b4",
   "metadata": {},
   "source": [
    "# 使用微调模型\n",
    "\n",
    "微调后，使用模型进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize predictions as labels, automatically inferred from the training data in part 2.\n",
    "model.serializer = Labels()\n",
    "\n",
    "predictions = model.predict(\n",
    "    [\n",
    "        \"data/hymenoptera_data/val/bees/65038344_52a45d090d.jpg\",\n",
    "        \"data/hymenoptera_data/val/ants/2255445811_dabcdf7258.jpg\",\n",
    "    ]\n",
    ")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffdc2d",
   "metadata": {},
   "source": [
    "我们得到以下输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada26798",
   "metadata": {},
   "outputs": [],
   "source": [
    "['bees', 'ants']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d976d9",
   "metadata": {},
   "source": [
    "或者您可以在任何地方使用保存的模型进行预测！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.image import ImageClassifier\n",
    "\n",
    "# load finetuned checkpoint\n",
    "model = ImageClassifier.load_from_checkpoint(\"image_classification_model.pt\")\n",
    "\n",
    "predictions = model.predict(\"path/to/your/own/image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e1433",
   "metadata": {},
   "source": [
    "# 微调策略\n",
    "\n",
    "微调是非常特定于任务的。 每个任务都编码了该任务的最佳微调实践。 但是，Flash 为您提供了一些默认的微调策略。\n",
    "\n",
    "微调对两件事进行操作，模型主干和头部。 主干是预先训练好的神经网络。 头部是另一个神经网络，它在主干和您的特定数据集之间架起桥梁。\n",
    "\n",
    "## 不冻结\n",
    "\n",
    "在这个策略中，脊椎和头部从一开始就解冻了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24936385",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finetune(model, datamodule, strategy=\"no_freeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94256ff",
   "metadata": {},
   "source": [
    "在伪代码中，这看起来像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Resnet50()\n",
    "head = nn.Linear(...)\n",
    "\n",
    "backbone.unfreeze()\n",
    "head.unfreeze()\n",
    "\n",
    "train(backbone, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3a0d1",
   "metadata": {},
   "source": [
    "## 冻结\n",
    "\n",
    "冻结策略始终保持主干冻结。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07036a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finetune(model, datamodule, strategy=\"freeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391a96b",
   "metadata": {},
   "source": [
    "伪代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Resnet50()\n",
    "head = nn.Linear(...)\n",
    "\n",
    "# freeze backbone\n",
    "backbone.freeze()\n",
    "head.unfreeze()\n",
    "\n",
    "train(backbone, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0e7f1",
   "metadata": {},
   "source": [
    "# 高级策略\n",
    "每个微调策略也可以定制。\n",
    "## 冻结解冻\n",
    "默认情况下，在此策略中，主干被冻结 5 个时期，然后解冻："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904cbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finetune(model, datamodule, strategy=\"freeze_unfreeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eec88e",
   "metadata": {},
   "source": [
    "或者我们可以自定义它在不同的周期后解冻主干。 例如，要在 epoch 7 之后解冻："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.core.finetuning import FreezeUnfreeze\n",
    "\n",
    "trainer.finetune(model, datamodule, strategy=FreezeUnfreeze(unfreeze_epoch=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4827251",
   "metadata": {},
   "source": [
    "在幕后，伪代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Resnet50()\n",
    "head = nn.Linear(...)\n",
    "\n",
    "# freeze backbone\n",
    "backbone.freeze()\n",
    "head.unfreeze()\n",
    "\n",
    "train(backbone, head, epochs=10)\n",
    "\n",
    "# unfreeze after 10 epochs\n",
    "backbone.unfreeze()\n",
    "\n",
    "train(backbone, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0e6b5",
   "metadata": {},
   "source": [
    "## unfreeze_milestones\n",
    "\n",
    "此策略允许您以预定的时间间隔解冻部分主干\n",
    "\n",
    "这是一个示例，其中： - 主干开始冻结 - 在 epoch 3 最后 2 层解冻 - 在 epoch 8 时，完整的主干解冻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16465d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.core.finetuning import UnfreezeMilestones\n",
    "\n",
    "trainer.finetune(model, datamodule, strategy=UnfreezeMilestones(unfreeze_milestones=(3, 8), num_layers=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038e5c2",
   "metadata": {},
   "source": [
    "在幕后，伪代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7260d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Resnet50()\n",
    "head = nn.Linear(...)\n",
    "\n",
    "# freeze backbone\n",
    "backbone.freeze()\n",
    "head.unfreeze()\n",
    "\n",
    "train(backbone, head, epochs=3)\n",
    "\n",
    "# unfreeze last 2 layers at epoch 3\n",
    "backbone.unfreeze_last_layers(2)\n",
    "\n",
    "train(backbone, head, epochs=8)\n",
    "\n",
    "# unfreeze the full backbone\n",
    "backbone.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb892456",
   "metadata": {},
   "source": [
    "# 自定义策略\n",
    "\n",
    "如需更多自定义，请创建您自己的微调回调。 在此处了解有关回调的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46815fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.core.finetuning import FlashBaseFinetuning\n",
    "\n",
    "# 创建微调回调\n",
    "class FeatureExtractorFreezeUnfreeze(FlashBaseFinetuning):\n",
    "    def __init__(self, unfreeze_epoch: int = 5, train_bn: bool = True):\n",
    "        # this will set self.attr_names as [\"backbone\"]\n",
    "        super().__init__(\"backbone\", train_bn)\n",
    "        self._unfreeze_epoch = unfreeze_epoch\n",
    "\n",
    "    def finetune_function(self, pl_module, current_epoch, optimizer, opt_idx):\n",
    "        # unfreeze any module you want by overriding this function\n",
    "\n",
    "        # When ``current_epoch`` is 5, backbone will start to be trained.\n",
    "        if current_epoch == self._unfreeze_epoch:\n",
    "            self.unfreeze_and_add_param_group(\n",
    "                pl_module.backbone,\n",
    "                optimizer,\n",
    "            )\n",
    "\n",
    "\n",
    "# Pass the callback to trainer.finetune\n",
    "trainer.finetune(model, datamodule, strategy=FeatureExtractorFreezeUnfreeze(unfreeze_epoch=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfeea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
