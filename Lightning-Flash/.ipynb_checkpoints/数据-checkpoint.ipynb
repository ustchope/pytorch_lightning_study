{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46a6ba2",
   "metadata": {},
   "source": [
    "# 如何使用开箱即用的 Flash DataModules\n",
    "\n",
    "Flash 提供了几个带有辅助函数的 DataModules。 查看图像分类部分（或我们任何其他任务的部分）以了解更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d5b8f",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "\n",
    "目前，通常的做法是实现 torch.utils.data.Dataset 并将其提供给 torch.utils.data.DataLoader。然而，在模型训练之后，需要大量的工程开销来对原始数据进行推理并将模型部署到生产环境中。通常，应该添加额外的处理逻辑来弥合训练数据和原始数据之间的差距。\n",
    "\n",
    "DataSource 类可用于从多个源（例如文件夹、numpy 等）生成数据集，然后所有这些都可以以相同的方式进行转换。 Preprocess 和 Postprocess 类可用于管理预处理和后处理转换。 Serializer 类提供将 Postprocess 输出转换为所需预测格式（例如类、标签、概率等）的逻辑。\n",
    "\n",
    "通过提供一系列可被自定义数据处理逻辑覆盖（或仅针对转换）的钩子，Flash 为用户提供了对其数据处理流程的更精细的控制。\n",
    "\n",
    "以下是主要优点：\n",
    "* 使对原始数据的推断变得简单\n",
    "* 使代码更具可读性、模块化和自包含\n",
    "* 数据增强实验更简单"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6837a",
   "metadata": {},
   "source": [
    "要仅在给定挂钩的特定阶段更改处理行为，您可以通过添加 train、val、test 或 predict 为每个 Preprocess 和 Postprocess 挂钩添加前缀。\n",
    "\n",
    "查看预处理以获取一些示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd4a42",
   "metadata": {},
   "source": [
    "# 如何自定义现有的 DataModules\n",
    "\n",
    "任何 Flash DataModule 都可以使用 from_datasets() 直接从数据集创建，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash import DataModule, Trainer\n",
    "\n",
    "data_module = DataModule.from_datasets(train_dataset=MyDataset())\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, data_module=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c489a6e",
   "metadata": {},
   "source": [
    "DataModule 提供了额外的类方法助手 (from_*) 用于从各种来源加载数据。 在每个 from_* 方法中，DataModule 在内部从预处理中检索要使用的正确数据源。 Flash AutoDataset 实例是从用于训练、验证、测试和预测的数据源创建的。 DataModule 使用相应的 AutoDataset 为每个阶段填充 DataLoader。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd07fe8",
   "metadata": {},
   "source": [
    "# 自定义数据模块的预处理\n",
    "\n",
    "Preprocess 包含与给定任务相关的处理逻辑。 每个 Preprocess 通过 default_transforms() 方法提供一些默认的转换。 用户可以通过向 DataModule 提供他们自己的转换来轻松地覆盖这些。 下面是一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbabd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash.core.data.transforms import ApplyToKeys\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "\n",
    "transform = {\"to_tensor_transform\": ApplyToKeys(\"input\", my_to_tensor_transform)}\n",
    "\n",
    "datamodule = ImageClassificationData.from_folders(\n",
    "    train_folder=\"data/hymenoptera_data/train/\",\n",
    "    val_folder=\"data/hymenoptera_data/val/\",\n",
    "    test_folder=\"data/hymenoptera_data/test/\",\n",
    "    train_transform=transform,\n",
    "    val_transform=transform,\n",
    "    test_transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3478239",
   "metadata": {},
   "source": [
    "或者，用户可以根据自己的需要直接覆盖钩子，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "from flash.image import ImageClassificationData, ImageClassifier, ImageClassificationPreprocess\n",
    "\n",
    "\n",
    "class CustomImageClassificationPreprocess(ImageClassificationPreprocess):\n",
    "    def to_tensor_transform(sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        sample[\"input\"] = my_to_tensor_transform(sample[\"input\"])\n",
    "        return sample\n",
    "\n",
    "\n",
    "datamodule = ImageClassificationData.from_folders(\n",
    "    train_folder=\"data/hymenoptera_data/train/\",\n",
    "    val_folder=\"data/hymenoptera_data/val/\",\n",
    "    test_folder=\"data/hymenoptera_data/test/\",\n",
    "    preprocess=CustomImageClassificationPreprocess(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b18f8",
   "metadata": {},
   "source": [
    "# 创建自己的 Preprocess 和 DataModule\n",
    "\n",
    "下面的示例显示了一个非常简单的 ImageClassificationPreprocess，其中包含一个 ImageClassificationFoldersDataSource 和一个 ImageClassificationDataModule。\n",
    "\n",
    "1. 面向用户的API设计\n",
    "\n",
    "设计一个易于使用的 API 是关键。 这是第一步，也是最重要的一步。 我们希望 ImageClassificationDataModule 从以这种方式排列的图像文件夹生成数据集。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train/dog/xxx.png\n",
    "train/dog/xxy.png\n",
    "train/dog/xxz.png\n",
    "train/cat/123.png\n",
    "train/cat/nsdf3.png\n",
    "train/cat/asd932.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc813a",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71127fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ImageClassificationDataModule.from_folders(\n",
    "    train_folder=\"./data/train\",\n",
    "    val_folder=\"./data/val\",\n",
    "    test_folder=\"./data/test\",\n",
    "    predict_folder=\"./data/predict\",\n",
    ")\n",
    "\n",
    "model = ImageClassifier(...)\n",
    "trainer = Trainer(...)\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2228597",
   "metadata": {},
   "source": [
    "2. 数据源\n",
    "\n",
    "我们首先实现 ImageClassificationFoldersDataSource。 load_data 方法将从给定目录生成文件和目标列表。 load_sample 方法会将给定的文件加载为 PIL.Image。 这是完整的 ImageClassificationFoldersDataSource："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b34473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.datasets.folder import make_dataset\n",
    "from typing import Any, Dict\n",
    "from flash.core.data.data_source import DataSource, DefaultDataKeys\n",
    "\n",
    "\n",
    "class ImageClassificationFoldersDataSource(DataSource):\n",
    "    def load_data(self, folder: str, dataset: Any) -> Iterable:\n",
    "        # The dataset is optional but can be useful to save some metadata.\n",
    "\n",
    "        # `metadata` contains the image path and its corresponding label\n",
    "        # with the following structure:\n",
    "        # [(image_path_1, label_1), ... (image_path_n, label_n)].\n",
    "        metadata = make_dataset(folder)\n",
    "\n",
    "        # for the train `AutoDataset`, we want to store the `num_classes`.\n",
    "        if self.training:\n",
    "            dataset.num_classes = len(np.unique([m[1] for m in metadata]))\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                DefaultDataKeys.INPUT: file,\n",
    "                DefaultDataKeys.TARGET: target,\n",
    "            }\n",
    "            for file, target in metadata\n",
    "        ]\n",
    "\n",
    "    def predict_load_data(self, predict_folder: str) -> Iterable:\n",
    "        # This returns [image_path_1, ... image_path_m].\n",
    "        return [{DefaultDataKeys.INPUT: file} for file in os.listdir(folder)]\n",
    "\n",
    "    def load_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        sample[DefaultDataKeys.INPUT] = Image.open(sample[DefaultDataKeys.INPUT])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ae1fe",
   "metadata": {},
   "source": [
    "3. 预处理\n",
    "\n",
    "接下来，使用一些默认转换和对数据源的引用来实现您的自定义 ImageClassificationPreprocess："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2baebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Optional\n",
    "from flash.core.data.data_source import DefaultDataKeys, DefaultDataSources\n",
    "from flash.core.data.process import Preprocess\n",
    "import torchvision.transforms.functional as T\n",
    "\n",
    "# Subclass `Preprocess`\n",
    "class ImageClassificationPreprocess(Preprocess):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_transform: Optional[Dict[str, Callable]] = None,\n",
    "        val_transform: Optional[Dict[str, Callable]] = None,\n",
    "        test_transform: Optional[Dict[str, Callable]] = None,\n",
    "        predict_transform: Optional[Dict[str, Callable]] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            train_transform=train_transform,\n",
    "            val_transform=val_transform,\n",
    "            test_transform=test_transform,\n",
    "            predict_transform=predict_transform,\n",
    "            data_sources={\n",
    "                DefaultDataSources.FOLDERS: ImageClassificationFoldersDataSource(),\n",
    "            },\n",
    "            default_data_source=DefaultDataSources.FOLDERS,\n",
    "        )\n",
    "\n",
    "    def get_state_dict(self) -> Dict[str, Any]:\n",
    "        return {**self.transforms}\n",
    "\n",
    "    @classmethod\n",
    "    def load_state_dict(cls, state_dict: Dict[str, Any], strict: bool = False):\n",
    "        return cls(**state_dict)\n",
    "\n",
    "    def default_transforms(self) -> Dict[str, Callable]:\n",
    "        return {\"to_tensor_transform\": ApplyToKeys(DefaultDataKeys.INPUT, T.to_tensor)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cf7f1",
   "metadata": {},
   "source": [
    "4. 数据模块\n",
    "\n",
    "最后，让我们实现 ImageClassificationDataModule。 我们免费获得 from_folders 类方法，因为我们在 ImageClassificationPreprocess 中注册了 DefaultDataSources.FOLDERS 数据源。 我们需要做的就是像这样附加我们的 Preprocess 类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash import DataModule\n",
    "\n",
    "\n",
    "class ImageClassificationDataModule(DataModule):\n",
    "\n",
    "    # Set `preprocess_cls` with your custom `Preprocess`.\n",
    "    preprocess_cls = ImageClassificationPreprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544faa0c",
   "metadata": {},
   "source": [
    "# 幕后工作原理\n",
    "\n",
    "## DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b36ce2",
   "metadata": {},
   "source": [
    "这是 AutoDataset 伪代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: List[Any],  # output of `DataSource.load_data`\n",
    "        data_source: DataSource,\n",
    "        running_stage: RunningStage,\n",
    "    ):\n",
    "\n",
    "        self.data = data\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.data_source.load_sample(self.data[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9f20d",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c0db7",
   "metadata": {},
   "source": [
    "这是使用预处理钩子名称的伪代码。 Flash 负责为每个阶段调用正确的钩子。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be wrapped into a :class:`~flash.core.data.batch._Preprocessor`.\n",
    "def collate_fn(samples: Sequence[Any]) -> Any:\n",
    "\n",
    "    # This will be wrapped into a :class:`~flash.core.data.batch._Sequential`\n",
    "    for sample in samples:\n",
    "        sample = pre_tensor_transform(sample)\n",
    "        sample = to_tensor_transform(sample)\n",
    "        sample = post_tensor_transform(sample)\n",
    "\n",
    "    samples = type(samples)(samples)\n",
    "\n",
    "    # if :func:`flash.core.data.process.Preprocess.per_sample_transform_on_device` hook is overridden,\n",
    "    # those functions below will be no-ops\n",
    "\n",
    "    samples = collate(samples)\n",
    "    samples = per_batch_transform(samples)\n",
    "    return samples\n",
    "\n",
    "dataloader = DataLoader(dataset, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6d1ce",
   "metadata": {},
   "source": [
    "这是使用预处理钩子名称的伪代码。 Flash 负责为每个阶段调用正确的钩子。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be wrapped into a :class:`~flash.core.data.batch._Preprocessor`\n",
    "def collate_fn(samples: Sequence[Any]) -> Any:\n",
    "\n",
    "    # if ``per_batch_transform`` hook is overridden, those functions below will be no-ops\n",
    "    samples = [per_sample_transform_on_device(sample) for sample in samples]\n",
    "    samples = type(samples)(samples)\n",
    "    samples = collate(samples)\n",
    "\n",
    "    samples = per_batch_transform_on_device(samples)\n",
    "    return samples\n",
    "\n",
    "# move the data to device\n",
    "data = lightning_module.transfer_data_to_device(data)\n",
    "data = collate_fn(data)\n",
    "predictions = lightning_module(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17969408",
   "metadata": {},
   "source": [
    "## 后处理和序列化程序\n",
    "\n",
    "一旦 Flash 任务生成预测，Flash DataPipeline 将在幕后执行 Postprocess 钩子和 Serializer。\n",
    "\n",
    "首先， per_batch_transform() 钩子将应用于批量预测。 然后， uncollate() 会将批次拆分为单独的预测。 接下来， per_sample_transform() 将应用于每个预测。 最后，将调用 serialize() 方法来序列化预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ca878",
   "metadata": {},
   "source": [
    "这是伪代码：\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be wrapped into a :class:`~flash.core.data.batch._Postprocessor`\n",
    "def uncollate_fn(batch: Any) -> Any:\n",
    "\n",
    "    batch = per_batch_transform(batch)\n",
    "\n",
    "    samples = uncollate(batch)\n",
    "\n",
    "    samples = [per_sample_transform(sample) for sample in samples]\n",
    "    # only if serializers are enabled.\n",
    "    return [serialize(sample) for sample in samples]\n",
    "\n",
    "predictions = lightning_module(data)\n",
    "return uncollate_fn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3866b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
