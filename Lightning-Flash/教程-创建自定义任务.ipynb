{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6a90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 299 ms (started: 2021-09-03 13:57:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dec0331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main 2159ffa] 更新 #3 Sept 03, 2021\n",
      " 5 files changed, 1475 insertions(+), 6 deletions(-)\n",
      " create mode 100644 \"Lightning-Flash/.ipynb_checkpoints/\\345\\277\\253\\351\\200\\237\\345\\274\\200\\345\\247\\213-checkpoint.ipynb\"\n",
      " create mode 100644 \"Lightning-Flash/.ipynb_checkpoints/\\346\\225\\231\\347\\250\\213-\\345\\210\\233\\345\\273\\272\\350\\207\\252\\345\\256\\232\\344\\271\\211\\344\\273\\273\\345\\212\\241-checkpoint.ipynb\"\n",
      " delete mode 100644 \"Lightning-Flash/.ipynb_checkpoints/\\346\\234\\252\\345\\221\\275\\345\\220\\215-checkpoint.ipynb\"\n",
      " create mode 100644 \"Lightning-Flash/\\345\\277\\253\\351\\200\\237\\345\\274\\200\\345\\247\\213.ipynb\"\n",
      " create mode 100644 \"Lightning-Flash/\\346\\225\\231\\347\\250\\213-\\345\\210\\233\\345\\273\\272\\350\\207\\252\\345\\256\\232\\344\\271\\211\\344\\273\\273\\345\\212\\241.ipynb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:ustchope/pytorch_lightning_study.git\n",
      "   fb6a44a..2159ffa  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.79 s (started: 2021-09-03 13:57:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb */*.ipynb\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #3 Sept 03, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9769a452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.07 s (started: 2021-09-03 13:57:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
    "from pytorch_lightning import LightningModule, seed_everything, Trainer, LightningDataModule\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from torchmetrics.functional import accuracy\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed_everything(7)\n",
    "\n",
    "PATH_DATASETS = os.environ.get('PATH_DATASETS', '.')\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd4611",
   "metadata": {},
   "source": [
    "在本教程中，我们将介绍创建自定义任务以及自定义 DataModule 的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25c660",
   "metadata": {},
   "source": [
    "> 本教程仅旨在帮助您为个人项目创建小型自定义任务。 如果您需要更详细的指南，请查看我们的关于向 Flash 贡献任务的指南。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6108328",
   "metadata": {},
   "source": [
    "本教程的目标是创建一个 RegressionTask 来学习预测某人是否患有糖尿病。 我们将使用 scikit-learn 糖尿病数据集。 它存储为 numpy 数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896acab7",
   "metadata": {},
   "source": [
    "> 在 flash_examples/custom_task.py 中找到完整的教程示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27640085",
   "metadata": {},
   "source": [
    "# 导入\n",
    "\n",
    "我们首先导入我们将要使用的所有内容，并使用 seed_everything() 设置随机种子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743f1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.61 s (started: 2021-09-03 14:00:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "from sklearn import datasets\n",
    "from torch import nn, Tensor\n",
    "\n",
    "import flash\n",
    "from flash.core.data.data_source import DataSource, DefaultDataKeys, DefaultDataSources\n",
    "from flash.core.data.process import Preprocess\n",
    "from flash.core.data.transforms import ApplyToKeys\n",
    "\n",
    "# set the random seeds.\n",
    "seed_everything(42)\n",
    "\n",
    "ND = np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b77d3",
   "metadata": {},
   "source": [
    "# 任务：线性回归\n",
    "\n",
    "在这里，我们通过子类化 Task 创建了一个基本的线性回归任务。 对于大多数任务，您可能需要覆盖 __init__、forward 和 {train,val,test,predict}_step 方法。 应该覆盖 __init__ 以配置模型和要传递给基本任务的任何其他参数。 可能需要覆盖前向以将模型前向传递应用于输入。 Flash 中的最佳实践是将数据作为字典提供，将字符串键映射到它们的值。 {train,val,test,predict}_step 方法需要被覆盖才能从输入字典中提取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTask(flash.Task):\n",
    "    def __init__(self, num_inputs, learning_rate=0.2, metrics=None):\n",
    "        # 我们想要什么样的模型？\n",
    "        model = torch.nn.Linear(num_inputs, 1)\n",
    "\n",
    "        # 我们想要什么损失函数？\n",
    "        loss_fn = torch.nn.functional.mse_loss\n",
    "\n",
    "        # 我们想要什么优化器？\n",
    "        optimizer = torch.optim.Adam\n",
    "\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            metrics=metrics,\n",
    "            learning_rate=learning_rate,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int) -> Any:\n",
    "        return super().training_step(\n",
    "            (batch[DefaultDataKeys.INPUT], batch[DefaultDataKeys.TARGET]),\n",
    "            batch_idx,\n",
    "        )\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        return super().validation_step(\n",
    "            (batch[DefaultDataKeys.INPUT], batch[DefaultDataKeys.TARGET]),\n",
    "            batch_idx,\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        return super().test_step(\n",
    "            (batch[DefaultDataKeys.INPUT], batch[DefaultDataKeys.TARGET]),\n",
    "            batch_idx,\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        return super().predict_step(\n",
    "            batch[DefaultDataKeys.INPUT],\n",
    "            batch_idx,\n",
    "            dataloader_idx,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对于这个例子，我们实际上不需要覆盖这个方法\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb28ff4",
   "metadata": {},
   "source": [
    "> Lightning Flash 提供注册表。 注册表是 Flash 内部键值数据库，用于存储名称和函数之间的映射。 简单来说，它们只是高级字典，用于存储来自键字符串的函数。 它们可用于存储主干列表并使它们可用于任务。 查看可用注册表以了解更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57538e7c",
   "metadata": {},
   "source": [
    "## 训练步骤在哪里？\n",
    "\n",
    "大多数模型可以简单地通过将 forward 的输出传递给提供的 loss_fn，然后将产生的损失传递给提供的优化器来训练。 如果您需要更自定义的配置，您可以覆盖 step（为训练、验证和测试调用）或单独覆盖 training_step、validation_step 和 test_step。 这些方法的行为与 PyTorch Lightning 的方法相同。\n",
    "\n",
    "这是任务步骤背后的伪代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, batch: Any, batch_idx: int) -> Any:\n",
    "    \"\"\"\n",
    "    The training/validation/test step. Override for custom behavior.\n",
    "    \"\"\"\n",
    "    x, y = batch\n",
    "    y_hat = self(x)\n",
    "    # compute the logs, loss and metrics as an output dictionary\n",
    "    ...\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086eabde",
   "metadata": {},
   "source": [
    "# 数据源 API\n",
    "\n",
    "现在我们已经定义了我们的 RegressionTask，我们需要加载我们的数据。 我们将定义一个扩展 DataSource 的自定义 NumpyDataSource。 NumpyDataSource 包含一个 load_data 和 predict_load_data 方法，它们处理从输入 numpy 数组加载一系列字典。 加载训练数据时（如果 self.training:），NumpyDataSource 设置可选数据集参数的 num_inputs 属性。 在可选数据集参数上设置的任何属性也将在生成的数据集上设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataSource(DataSource[Tuple[ND, ND]]):\n",
    "    def load_data(self, data: Tuple[ND, ND], dataset: Optional[Any] = None) -> List[Dict[str, Any]]:\n",
    "        if self.training:\n",
    "            dataset.num_inputs = data[0].shape[1]\n",
    "        return [{DefaultDataKeys.INPUT: x, DefaultDataKeys.TARGET: y} for x, y in zip(*data)]\n",
    "\n",
    "    def predict_load_data(self, data: ND) -> List[Dict[str, Any]]:\n",
    "        return [{DefaultDataKeys.INPUT: x} for x in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d3eec",
   "metadata": {},
   "source": [
    "# 预处理 API\n",
    "\n",
    "现在我们有了一个 DataSource 实现，我们可以定义我们的 Preprocess。 Preprocess 对象提供了一系列钩子，这些钩子可以被自定义数据处理逻辑覆盖，并且可以附加转换。 它允许用户对其数据处理流程进行更精细的控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550c125",
   "metadata": {},
   "source": [
    "> 为什么要引入 Preprocess ？\n",
    "> \n",
    "> 与传统数据集相比，预处理对象减少了对原始数据进行推理或在生产环境中部署模型的工程开销。\n",
    "> \n",
    "> 您可以覆盖 predict_{hook_name} 钩子或 default_predict_transforms 来处理特定于推理的数据处理逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecaea91",
   "metadata": {},
   "source": [
    "## 定义自定义 Preprocess 的推荐方式如下：\n",
    "* 定义一个接受转换参数的 __init__。\n",
    "* 将这些参数传递给 super().__init__ 并指定 data_sources 和 default_data_source。\n",
    "    * data_sources 将与 Preprocess 一起使用的 DataSource 对象作为从数据源名称到 DataSource 的映射。数据源名称可以是任何字符串，但出于我们的目的，我们可以使用 DefaultDataSources 中的 NUMPY。\n",
    "    * default_data_source 是预测时默认使用的数据源的名称。\n",
    "* 覆盖 get_state_dict 和 load_state_dict 方法。这些方法用于从检查点保存和加载您的 Preprocess。\n",
    "* 覆盖 {train,val,test,predict}_default_transforms 方法以指定要在每个阶段使用的默认转换（如果 __init__ 中传递的转换为 None，则将使用这些转换）。\n",
    "    * 转换作为从钩子名称到可调用转换的映射给出。您应该使用 ApplyToKeys 将每个转换仅应用于数据字典中的特定键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyPreprocess(Preprocess):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_transform: Optional[Dict[str, Callable]] = None,\n",
    "        val_transform: Optional[Dict[str, Callable]] = None,\n",
    "        test_transform: Optional[Dict[str, Callable]] = None,\n",
    "        predict_transform: Optional[Dict[str, Callable]] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            train_transform=train_transform,\n",
    "            val_transform=val_transform,\n",
    "            test_transform=test_transform,\n",
    "            predict_transform=predict_transform,\n",
    "            data_sources={DefaultDataSources.NUMPY: NumpyDataSource()},\n",
    "            default_data_source=DefaultDataSources.NUMPY,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def to_float(x: Tensor):\n",
    "        return x.float()\n",
    "\n",
    "    @staticmethod\n",
    "    def format_targets(x: Tensor):\n",
    "        return x.unsqueeze(0)\n",
    "\n",
    "    @property\n",
    "    def to_tensor(self) -> Dict[str, Callable]:\n",
    "        return {\n",
    "            \"to_tensor_transform\": nn.Sequential(\n",
    "                ApplyToKeys(\n",
    "                    DefaultDataKeys.INPUT,\n",
    "                    torch.from_numpy,\n",
    "                    self.to_float,\n",
    "                ),\n",
    "                ApplyToKeys(\n",
    "                    DefaultDataKeys.TARGET,\n",
    "                    torch.as_tensor,\n",
    "                    self.to_float,\n",
    "                    self.format_targets,\n",
    "                ),\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def default_transforms(self) -> Optional[Dict[str, Callable]]:\n",
    "        return self.to_tensor\n",
    "\n",
    "    def get_state_dict(self) -> Dict[str, Any]:\n",
    "        return self.transforms\n",
    "\n",
    "    @classmethod\n",
    "    def load_state_dict(cls, state_dict: Dict[str, Any], strict: bool = False):\n",
    "        return cls(*state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1856d6",
   "metadata": {},
   "source": [
    "# 数据模块 API\n",
    "\n",
    "现在我们有一个 Preprocess 知道它支持的 DataSource 对象，我们只需要创建一个 DataModule，它具有对我们希望它使用的 preprocess_cls 的引用。 对于名称在 DefaultDataSources 中的任何数据源，都有一个提供预期输入的标准 DataModule.from_* 方法。 所以在这种情况下， from_numpy() 将使用我们的 numpy 数据源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68956328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataModule(flash.DataModule):\n",
    "\n",
    "    preprocess_cls = NumpyPreprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ca2aa",
   "metadata": {},
   "source": [
    "您现在有了一个新的自定义 Flash 任务！ 恭喜！\n",
    "\n",
    "您可以直接使用这些对象进行拟合、微调、验证和预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacfea5",
   "metadata": {},
   "source": [
    "# fit\n",
    "\n",
    "对于此任务，以下是如何在 scikit-learn 糖尿病数据集上拟合 RegressionTask 任务。\n",
    "\n",
    "像任何 Flash 任务一样，我们可以使用 flash.Trainer 通过提供任务本身和相关数据来拟合我们的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datasets.load_diabetes(return_X_y=True)\n",
    "datamodule = NumpyDataModule.from_numpy(x, y)\n",
    "\n",
    "model = RegressionTask(num_inputs=datamodule.train_dataset.num_inputs)\n",
    "\n",
    "trainer = flash.Trainer(\n",
    "    max_epochs=20, progress_bar_refresh_rate=20, checkpoint_callback=False, gpus=torch.cuda.device_count()\n",
    ")\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2300f8",
   "metadata": {},
   "source": [
    "# 预测\n",
    "\n",
    "使用经过训练的模型，我们现在可以执行推理。 在这里，我们将使用我们数据测试集中的一些示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = np.array(\n",
    "    [\n",
    "        [0.0199, 0.0507, 0.1048, 0.0701, -0.0360, -0.0267, -0.0250, -0.0026, 0.0037, 0.0403],\n",
    "        [-0.0128, -0.0446, 0.0606, 0.0529, 0.0480, 0.0294, -0.0176, 0.0343, 0.0702, 0.0072],\n",
    "        [0.0381, 0.0507, 0.0089, 0.0425, -0.0428, -0.0210, -0.0397, -0.0026, -0.0181, 0.0072],\n",
    "        [-0.0128, -0.0446, -0.0235, -0.0401, -0.0167, 0.0046, -0.0176, -0.0026, -0.0385, -0.0384],\n",
    "        [-0.0237, -0.0446, 0.0455, 0.0907, -0.0181, -0.0354, 0.0707, -0.0395, -0.0345, -0.0094],\n",
    "    ]\n",
    ")\n",
    "\n",
    "predictions = model.predict(predict_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3896227",
   "metadata": {},
   "source": [
    "我们得到以下输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tensor([189.1198]), tensor([196.0839]), tensor([161.2461]), tensor([130.7591]), tensor([149.1780])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch19]",
   "language": "python",
   "name": "conda-env-torch19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
