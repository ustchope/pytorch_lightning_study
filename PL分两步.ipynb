{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 703 ms (started: 2021-08-28 14:19:18 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immune-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (fetch)\n",
      "origin\tgit@github.com:ustchope/pytorch_lightning_study.git (push)\n",
      "[main 944aae4] 更新 #1 Aug 28, 2021\n",
      " 1 file changed, 6 insertions(+)\n",
      " create mode 100644 \"PL\\345\\210\\206\\344\\270\\244\\346\\255\\245.ipynb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/pytorch_lightning_study.git\n",
      "   9704207..944aae4  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.73 s (started: 2021-08-28 14:19:31 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #1 Aug 28, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-architect",
   "metadata": {},
   "source": [
    "使用 PyTorch Lightning 组织您的代码使您的代码：\n",
    "* 保持所有的灵活性（这都是纯 PyTorch），但删除了大量的样板\n",
    "* 通过将研究代码与工程分离，更具可读性\n",
    "* 更容易重现\n",
    "* 通过自动化大部分训练循环和棘手的工程来减少出错的可能性\n",
    "* 无需更改模型即可扩展到任何硬件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-newfoundland",
   "metadata": {},
   "source": [
    "# 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hindu-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.88 s (started: 2021-08-28 14:21:27 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-consolidation",
   "metadata": {},
   "source": [
    "# 第 1 步：定义 LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 ms (started: 2021-08-28 14:42:04 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在 Lightning 中，forward 定义了预测/推理动作\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step 定义了训练循环。\n",
    "        # 独立于forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # 默认登录到 TensorBoard\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-dispute",
   "metadata": {},
   "source": [
    "## 系统与模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-sphere",
   "metadata": {},
   "source": [
    "lightning module 模块定义的是系统而不是模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-alberta",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gtwhk8xdjgj615y0p4jsp02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-latter",
   "metadata": {},
   "source": [
    "系统示例如下：\n",
    "* Autoencoder\n",
    "* BERT\n",
    "* DQN\n",
    "* GAN\n",
    "* Image classifier\n",
    "* Seq2seq\n",
    "* SimCLR\n",
    "* VAE\n",
    "* and a lot more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-definition",
   "metadata": {},
   "source": [
    "在幕后，LightningModule 仍然只是一个 torch.nn.Module，它将所有研究代码分组到一个文件中以使其独立：\n",
    "* 训练循环\n",
    "* 验证循环\n",
    "* 测试循环\n",
    "* 模型或模型系统\n",
    "* 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-frost",
   "metadata": {},
   "source": [
    "您可以通过覆盖可用回调钩子中的 20 多个钩子中的任何一个来自定义训练的任何部分（例如向后传递）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "similar-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.01 ms (started: 2021-08-28 14:33:51 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def backward(self, loss, optimizer, optimizer_idx):\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-musical",
   "metadata": {},
   "source": [
    "## FORWARD vs TRAINING_STEP\n",
    "\n",
    "在 Lightning 中，我们将训练与推理分开。 `training_step` 定义了完整的训练循环。 我们鼓励用户使用`forward`来定义推理操作。\n",
    "\n",
    "例如，在这种情况下，我们可以定义自动编码器作为嵌入提取器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    embeddings = self.encoder(x)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-resource",
   "metadata": {},
   "source": [
    "当然，没有什么能阻止您在 training_step 中使用 forward。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    ...\n",
    "    z = self(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-applicant",
   "metadata": {},
   "source": [
    "这真的归结为您的应用程序。 但是，我们建议您将两个意图分开。\n",
    "* 使用`forward`进行推理（预测）。\n",
    "* 使用 `training_step` 进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-domestic",
   "metadata": {},
   "source": [
    "# 第 2 步：使用 Lightning Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-paraguay",
   "metadata": {},
   "source": [
    "首先，根据需要定义数据。 Lightning 只需要一个 DataLoader 用于训练/验证/测试拆分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "differential-atlas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.1 ms (started: 2021-08-28 14:39:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-competition",
   "metadata": {},
   "source": [
    "接下来，初始化PL模块和 PyTorch Lightning训练器，然后使用数据和模型调用 fit。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "autoencoder = LitAutoEncoder()\n",
    "\n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(gpus=8) (if you have GPUs)\n",
    "trainer = pl.Trainer(gpus=2)\n",
    "trainer.fit(autoencoder, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-aspect",
   "metadata": {},
   "source": [
    "`Trainer`自动化：\n",
    "* Epoch 和批量迭代\n",
    "* 调用 optimizer.step()，backward()，zero_grad()\n",
    "* 调用 .eval()，启用/禁用 grads\n",
    "* 权重装载\n",
    "* Tensorboard（见记录器选项）\n",
    "* 多 GPU 支持\n",
    "* TPU\n",
    "* 16 位精度 AMP 支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-ocean",
   "metadata": {},
   "source": [
    "就是这样！\n",
    "\n",
    "这些是您在 Lightning 中需要了解的主要 2 个概念。 PL的所有其他特性要么是 Trainer 的特性，要么是 LightningModule 的特性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-mathematics",
   "metadata": {},
   "source": [
    "**基本功能**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-charles",
   "metadata": {},
   "source": [
    "# 手动与自动优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-culture",
   "metadata": {},
   "source": [
    "## 自动优化\n",
    "\n",
    "使用 Lightning，您无需担心何时启用/禁用 grads、执行反向传递或更新优化器，只要您从 training_step 返回带有附加图的损失，Lightning 将自动执行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    loss = self.encoder(batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-display",
   "metadata": {},
   "source": [
    "## 手动优化\n",
    "\n",
    "但是，对于某些研究，例如 GAN、强化学习或具有多个优化器或内部循环的研究，您可以关闭自动优化并完全控制自己的训练循环。\n",
    "\n",
    "关闭自动优化，您可以控制训练循环！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.automatic_optimization = False\n",
    "\n",
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    # 使用 use_pl_optimizer=False 访问您的优化器。 默认为真\n",
    "    opt_a, opt_b = self.optimizers(use_pl_optimizer=True)\n",
    "\n",
    "    loss_a = self.generator(batch)\n",
    "    opt_a.zero_grad()\n",
    "    # 使用 `manual_backward()` 而不是 `loss.backward` 来自动化半精度等......\n",
    "    self.manual_backward(loss_a)\n",
    "    opt_a.step()\n",
    "\n",
    "    loss_b = self.discriminator(batch)\n",
    "    opt_b.zero_grad()\n",
    "    self.manual_backward(loss_b)\n",
    "    opt_b.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-indication",
   "metadata": {},
   "source": [
    "# 预测或部署\n",
    "\n",
    "完成训练后，您有 3 个选项可以使用 LightningModule 进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-advancement",
   "metadata": {},
   "source": [
    "## 选项 1：子模型\n",
    "\n",
    "拉出系统内的任何模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 用作嵌入提取器\n",
    "# ----------------------------------\n",
    "autoencoder = LitAutoEncoder.load_from_checkpoint(\"path/to/checkpoint_file.ckpt\")\n",
    "encoder_model = autoencoder.encoder\n",
    "encoder_model.eval()\n",
    "\n",
    "# ----------------------------------\n",
    "# 用作图像生成器\n",
    "# ----------------------------------\n",
    "decoder_model = autoencoder.decoder\n",
    "decoder_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-discipline",
   "metadata": {},
   "source": [
    "## 选项 2：`forward`\n",
    "\n",
    "您还可以添加`forward`方法来根据需要进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 使用 AE 提取嵌入\n",
    "# ----------------------------------\n",
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "autoencoder = LitAutoEncoder()\n",
    "autoencoder = autoencoder(torch.rand(1, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 或使用AE生成图像\n",
    "# ----------------------------------\n",
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential()\n",
    "\n",
    "    def forward(self):\n",
    "        z = torch.rand(1, 3)\n",
    "        image = self.decoder(z)\n",
    "        image = image.view(1, 1, 28, 28)\n",
    "        return image\n",
    "\n",
    "\n",
    "autoencoder = LitAutoEncoder()\n",
    "image_sample = autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-courage",
   "metadata": {},
   "source": [
    "## 选项 3：生产\n",
    "\n",
    "对于生产系统，onnx 或 torchscript 要快得多。 确保您已添加转发方法或仅跟踪您需要的子模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# torchscript\n",
    "# ----------------------------------\n",
    "autoencoder = LitAutoEncoder()\n",
    "torch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n",
    "os.path.isfile(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# onnx\n",
    "# ----------------------------------\n",
    "with tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n",
    "    autoencoder = LitAutoEncoder()\n",
    "    input_sample = torch.randn((1, 28 * 28))\n",
    "    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n",
    "    os.path.isfile(tmpfile.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-assist",
   "metadata": {},
   "source": [
    "# 使用 CPU/GPU/TPU\n",
    "\n",
    "在 Lightning 中使用 CPU、GPU 或 TPU 是微不足道的。 无需更改您的代码，只需更改 Trainer 选项即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on CPU\n",
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 8 CPUs\n",
    "trainer = Trainer(num_processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 1024 CPUs across 128 machines\n",
    "trainer = pl.Trainer(num_processes=8, num_nodes=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 1 GPU\n",
    "trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on multiple GPUs across nodes (32 gpus here)\n",
    "trainer = pl.Trainer(gpus=4, num_nodes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on gpu 1, 3, 5 (3 gpus total)\n",
    "trainer = pl.Trainer(gpus=[1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi GPU with mixed precision\n",
    "trainer = pl.Trainer(gpus=2, precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on TPUs\n",
    "trainer = pl.Trainer(tpu_cores=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-flush",
   "metadata": {},
   "source": [
    "无需更改一行代码，您现在可以使用上述代码执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 16 位精度在 TPU 上训练\n",
    "# 只使用一半的训练数据并在训练周期的每个epoch检查验证\n",
    "trainer = pl.Trainer(tpu_cores=8, precision=16, limit_train_batches=0.5, val_check_interval=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-student",
   "metadata": {},
   "source": [
    "# Checkpoints\n",
    "\n",
    "Lightning 会自动保存您的模型。 训练完成后，您可以按如下方式加载检查点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-compact",
   "metadata": {},
   "source": [
    "上面的检查点包含初始化模型和设置状态字典所需的所有参数。 如果你更喜欢手动完成，这里是等效的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ckpt\n",
    "ckpt = torch.load(\"path/to/checkpoint.ckpt\")\n",
    "\n",
    "# equivalent to the above\n",
    "model = LitModel()\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-integral",
   "metadata": {},
   "source": [
    "# 数据流\n",
    "\n",
    "每个循环（训练、验证、测试）都有三个可以实现的钩子：\n",
    "* x_step\n",
    "* x_step_end\n",
    "* x_epoch_end\n",
    "\n",
    "为了说明数据如何流动，我们将使用训练循环（即：x=training）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for batch in data:\n",
    "    out = training_step(batch)\n",
    "    outs.append(out)\n",
    "training_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-receiver",
   "metadata": {},
   "source": [
    "Lightning 中的等效项是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    prediction = ...\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def training_epoch_end(self, training_step_outputs):\n",
    "    for prediction in predictions:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-america",
   "metadata": {},
   "source": [
    "如果您使用 DP 或 DDP2 分布式模式（即：跨 GPU 拆分批次），请使用 x_step_end 手动聚合（或不实施它以让 Lightning 自动聚合）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data:\n",
    "    model_copies = copy_model_per_gpu(model, num_gpus)\n",
    "    batch_split = split_batch_per_gpu(batch, num_gpus)\n",
    "\n",
    "    gpu_outs = []\n",
    "    for model, batch_part in zip(model_copies, batch_split):\n",
    "        # LightningModule hook\n",
    "        gpu_out = model.training_step(batch_part)\n",
    "        gpu_outs.append(gpu_out)\n",
    "\n",
    "    # LightningModule hook\n",
    "    out = training_step_end(gpu_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-nation",
   "metadata": {},
   "source": [
    "Lightning 中的等效项是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    loss = ...\n",
    "    return loss\n",
    "\n",
    "\n",
    "def training_step_end(self, losses):\n",
    "    gpu_0_loss = losses[0]\n",
    "    gpu_1_loss = losses[1]\n",
    "    return (gpu_0_loss + gpu_1_loss) * 1 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-healthcare",
   "metadata": {},
   "source": [
    "# 日志记录\n",
    "\n",
    "要登录 Tensorboard、您最喜欢的记录器和/或进度条，请使用 `log()` 方法，该方法可以从 `LightningModule`中的任何方法调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_metric\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-disclaimer",
   "metadata": {},
   "source": [
    "`log()` 方法有几个选项：\n",
    "* `on_step`（记录训练中该步骤的指标）\n",
    "* `on_epoch`（在`epoch`结束时自动累积和记录）\n",
    "* `prog_bar`（记录到进度条）\n",
    "* `logger`（像 `Tensorboard` 一样记录到记录器）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-offer",
   "metadata": {},
   "source": [
    "根据调用日志的位置，Lightning 会自动为您确定正确的模式。 但是当然您可以通过手动设置标志来覆盖默认行为"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-replacement",
   "metadata": {},
   "source": [
    "> 设置 on_epoch=True 将在整个训练时期累积您的记录值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log(\"my_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-pension",
   "metadata": {},
   "source": [
    "> 进度条中显示的损失值在最后一个值上进行了平滑（平均），因此它不同于训练/验证步骤中返回的实际损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-digit",
   "metadata": {},
   "source": [
    "您还可以直接使用记录器的任何方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    tensorboard = self.logger.experiment\n",
    "    tensorboard.any_summary_writer_method_you_want()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-distinction",
   "metadata": {},
   "source": [
    "训练开始后，您可以使用自己喜欢的记录器或启动 Tensorboard 日志来查看日志："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-processing",
   "metadata": {},
   "source": [
    "> Lightning 会在进度条中自动显示从 `training_step` 返回的损失值。 所以，不需要像 `self.log('loss', loss, prog_bar=True)` 那样显式地记录日志。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-charge",
   "metadata": {},
   "source": [
    "# 可选扩展\n",
    "\n",
    "## 回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-toronto",
   "metadata": {},
   "source": [
    "回调是一个任意的自包含程序，可以在训练循环的任意部分执行。\n",
    "\n",
    "这是一个添加一个不太花哨的学习率衰减规则的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class DecayLearningRate(Callback):\n",
    "    def __init__(self):\n",
    "        self.old_lrs = []\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        # 跟踪初始学习率\n",
    "        for opt_idx, optimizer in enumerate(trainer.optimizers):\n",
    "            group = [param_group[\"lr\"] for param_group in optimizer.param_groups]\n",
    "            self.old_lrs.append(group)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        for opt_idx, optimizer in enumerate(trainer.optimizers):\n",
    "            old_lr_group = self.old_lrs[opt_idx]\n",
    "            new_lr_group = []\n",
    "            for p_idx, param_group in enumerate(optimizer.param_groups):\n",
    "                old_lr = old_lr_group[p_idx]\n",
    "                new_lr = old_lr * 0.98\n",
    "                new_lr_group.append(new_lr)\n",
    "                param_group[\"lr\"] = new_lr\n",
    "            self.old_lrs[opt_idx] = new_lr_group\n",
    "\n",
    "\n",
    "# And pass the callback to the Trainer\n",
    "decay_callback = DecayLearningRate()\n",
    "trainer = Trainer(callbacks=[decay_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-contact",
   "metadata": {},
   "source": [
    "你可以用回调做的事情：\n",
    "* 在训练的某个时候发送电子邮件\n",
    "* 培养模型\n",
    "* 更新学习率\n",
    "* 可视化渐变\n",
    "* …\n",
    "* 你只受限于你的想象力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-taiwan",
   "metadata": {},
   "source": [
    "# LightningDataModules\n",
    "\n",
    "DataLoaders 和数据处理代码往往会散落在各处。 通过将数据代码组织到 LightningDataModule 中，使其可重用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # 在进行分布式训练时，Datamodules 有两个可选参数用于对下载/准备/拆分数据进行粒度控制：\n",
    "\n",
    "    # 可选，仅在 1 个 GPU/机器上调用\n",
    "    def prepare_data(self):\n",
    "        MNIST(os.getcwd(), train=True, download=True)\n",
    "        MNIST(os.getcwd(), train=False, download=True)\n",
    "\n",
    "    # 可选，为每个 GPU/机器调用（分配状态正常）\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # 变换\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        # 分割数据集\n",
    "        if stage in (None, \"fit\"):\n",
    "            mnist_train = MNIST(os.getcwd(), train=True, transform=transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    "        if stage == (None, \"test\"):\n",
    "            self.mnist_test = MNIST(os.getcwd(), train=False, transform=transform)\n",
    "\n",
    "    # 返回每个拆分的数据加载器\n",
    "    def train_dataloader(self):\n",
    "        mnist_train = DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "        return mnist_train\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        mnist_val = DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "        return mnist_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        mnist_test = DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "        return mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-brake",
   "metadata": {},
   "source": [
    "LightningDataModule 旨在实现跨项目共享和重用数据拆分和转换。 它封装了处理数据所需的所有步骤：下载、标记化、处理等。\n",
    "\n",
    "现在你可以简单地将你的 LightningDataModule 传递给训练器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = LitModel()\n",
    "\n",
    "# init data\n",
    "dm = MNISTDataModule()\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# test\n",
    "trainer.test(datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-flashing",
   "metadata": {},
   "source": [
    "DataModules 对于基于数据构建模型特别有用。 阅读有关数据模块的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-adobe",
   "metadata": {},
   "source": [
    "# 调试\n",
    "\n",
    "Lightning 有很多调试工具。 以下是其中几个的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅使用 10 个训练批次和 3 个 val 批次\n",
    "trainer = Trainer(limit_train_batches=10, limit_val_batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动过度拟合模型的理智批次进行健全性测试\n",
    "trainer = Trainer(overfit_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对所有代码进行单元测试 - 对代码的每一行执行一次以查看是否存在错误，而不是等待数小时在验证时崩溃\n",
    "trainer = Trainer(fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅训练 20% 的 epoch\n",
    "trainer = Trainer(limit_train_batches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每 25% 的训练epoch运行一次验证\n",
    "trainer = Trainer(val_check_interval=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析您的代码以查找速度/内存瓶颈\n",
    "Trainer(profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-heath",
   "metadata": {},
   "source": [
    "# 其他很酷的功能\n",
    "\n",
    "定义和训练第一个 Lightning 模型后，您可能想尝试其他很酷的功能，例如\n",
    "* 自动提前停止\n",
    "* 自动截断反向传播时间\n",
    "* 自动调整批量大小\n",
    "* 自动找到一个好的学习率\n",
    "* 直接从 S3 加载检查点\n",
    "* 扩展到大规模计算集群\n",
    "* 每个训练/验证/测试循环使用多个数据加载器\n",
    "* 使用多个优化器进行强化学习甚至 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-person",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
