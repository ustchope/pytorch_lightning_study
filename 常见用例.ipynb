{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "systematic-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 505 ms (started: 2021-08-30 12:53:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #1 Aug 30, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finite-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.41 s (started: 2021-08-30 12:58:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-floating",
   "metadata": {},
   "source": [
    "# 子模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-melbourne",
   "metadata": {},
   "source": [
    "研究项目倾向于测试针对同一数据集的不同方法。 这在带有继承的 Lightning 中很容易做到。\n",
    "\n",
    "例如，假设我们现在想要训练一个自动编码器用作 MNIST 图像的特征提取器。 我们正在从 LitMNIST 模块扩展我们的自动编码器，该模块已经定义了所有数据加载。 Autoencoder 模型中唯一改变的是初始化、转发、训练、验证和测试步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AutoEncoder(LitMNIST):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.metric = MSE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        representation = self.encoder(x)\n",
    "        x_hat = self.decoder(representation)\n",
    "\n",
    "        loss = self.metric(x, x_hat)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, prefix):\n",
    "        x, _ = batch\n",
    "        representation = self.encoder(x)\n",
    "        x_hat = self.decoder(representation)\n",
    "\n",
    "        loss = self.metric(x, x_hat)\n",
    "        self.log(f\"{prefix}_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-flavor",
   "metadata": {},
   "source": [
    "我们可以使用同一个训练器来训练它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "trainer = Trainer()\n",
    "trainer.fit(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-jerusalem",
   "metadata": {},
   "source": [
    "请记住，forward 方法应该定义 LightningModule 的实际用途。 在这种情况下，我们想使用 AutoEncoder 来提取图像表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images = torch.Tensor(32, 1, 28, 28)\n",
    "representations = autoencoder(some_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-hacker",
   "metadata": {},
   "source": [
    "# 调试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-rough",
   "metadata": {},
   "source": [
    "以下是使调试更容易的标志。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-syndicate",
   "metadata": {},
   "source": [
    "## fast_dev_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-purple",
   "metadata": {},
   "source": [
    "该标志通过运行 n 如果设置为 n (int) 否则为 1 如果设置为 True 训练和验证批次来运行“单元测试”。 关键是检测训练/验证循环中的任何错误，而不必等待完整的 epoch 崩溃。\n",
    "\n",
    "（参见：Trainer 的 fast_dev_run 参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行 1 个训练、验证、测试批次和程序结束\n",
    "trainer = Trainer(fast_dev_run=True)\n",
    "\n",
    "# 运行 7 个训练、验证、测试批次和程序结束\n",
    "trainer = Trainer(fast_dev_run=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-realtor",
   "metadata": {},
   "source": [
    "> 此参数将禁用调谐器、检查点回调、提前停止回调、记录器和记录器回调（如 LearningRateLogger）并且仅运行 1 个时期。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-depth",
   "metadata": {},
   "source": [
    "## 检查梯度范数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-rocket",
   "metadata": {},
   "source": [
    "日志（到记录器），每个权重矩阵的范数。\n",
    "\n",
    "（参见：Trainer 的 track_grad_norm 参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 2-norm\n",
    "trainer = Trainer(track_grad_norm=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-definition",
   "metadata": {},
   "source": [
    "## 记录 GPU 使用情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-potter",
   "metadata": {},
   "source": [
    "记录（到记录器）主机上每个 GPU 的 GPU 使用情况。\n",
    "\n",
    "（参见：Trainer 的 log_gpu_memory 参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(log_gpu_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-portland",
   "metadata": {},
   "source": [
    "## 使模型过拟合数据子集\n",
    "\n",
    "一个好的调试技术是取一小部分数据（比如每个类 2 个样本），并尝试让您的模型过度拟合。 如果不能，则表明它不适用于大型数据集。\n",
    "\n",
    "（参见：Trainer 的 overfit_batches 参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅使用 1% 的训练数据（并在 val 和 test 中使用相同的训练数据加载器（关闭 shuffle））\n",
    "trainer = Trainer(overfit_batches=0.01)\n",
    "\n",
    "# 类似，但无论数据集大小如何，都有固定的 10 个批次\n",
    "trainer = Trainer(overfit_batches=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-gazette",
   "metadata": {},
   "source": [
    "有了这个标志，训练集、验证集和测试集都将是同一个训练集。 我们还将替换训练集中的采样器，为您关闭 shuffle。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-greece",
   "metadata": {},
   "source": [
    "## 打印 LightningModule 的摘要\n",
    "\n",
    "每当 `.fit()` 函数被调用时，Trainer 将打印 LightningModule 的权重摘要。 默认情况下，它只打印顶级模块。 如果要显示网络中的所有子模块，请使用“完整”选项："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(weights_summary=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-november",
   "metadata": {},
   "source": [
    "您还可以通过在 LightningModule 中设置 `example_input_array` 属性来显示所有图层的中间输入和输出大小。 它将打印这样的表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "  | Name  | Type        | Params | In sizes  | Out sizes\n",
    "--------------------------------------------------------------\n",
    "0 | net   | Sequential  | 132 K  | [10, 256] | [10, 512]\n",
    "1 | net.0 | Linear      | 131 K  | [10, 256] | [10, 512]\n",
    "2 | net.1 | BatchNorm1d | 1.0 K    | [10, 512] | [10, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-following",
   "metadata": {},
   "source": [
    "当您在 Trainer 上调用 .fit() 时。 这可以帮助您找到图层组合中的错误。\n",
    "也可以看看：\n",
    "* weights_summary参数\n",
    "* ModelSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-setting",
   "metadata": {},
   "source": [
    "## 缩短Epoch\n",
    "\n",
    "有时，仅使用一定百分比的训练、验证或测试数据（或一组批次）会很有帮助。 例如，您可以使用 20% 的训练集和 1% 的验证集。\n",
    "\n",
    "在 Imagenet 等更大的数据集上，这可以帮助您比等待一个完整的 epoch 更快地调试或测试一些事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅使用 10% 的训练数据和 1% 的 val 数据\n",
    "trainer = Trainer(limit_train_batches=0.1, limit_val_batches=0.01)\n",
    "\n",
    "# 使用 10 批 train 和 5 批 val\n",
    "trainer = Trainer(limit_train_batches=10, limit_val_batches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-convert",
   "metadata": {},
   "source": [
    "## 设置验证健全性步骤的数量\n",
    "\n",
    "Lightning 在训练开始时运行了几个验证步骤。 这可以避免在验证循环中崩溃，进入冗长的训练循环。\n",
    "\n",
    "（参见：训练师的 num_sanity_val_steps 参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT\n",
    "trainer = Trainer(num_sanity_val_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-robertson",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-metadata",
   "metadata": {},
   "source": [
    "## 提前停止一个Epoch\n",
    "\n",
    "您可以通过覆盖 `on_train_batch_start()` 在满足某些条件时返回 -1 来提前停止一个纪元。\n",
    "\n",
    "如果您重复执行此操作，对于您最初请求的每个 epoch，那么这将停止您的整个运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-southwest",
   "metadata": {},
   "source": [
    "## 使用 EarlyStopping 回调基于指标提前停止\n",
    "\n",
    "EarlyStopping 回调可用于监控验证指标并在未观察到改进时停止训练。\n",
    "\n",
    "要启用它：\n",
    "* 导入 EarlyStopping 回调。\n",
    "* 使用 log() 方法记录要监控的指标。\n",
    "* 初始化回调，并将监视器设置为您选择的记录指标。\n",
    "* 将 EarlyStopping 回调传递给 Trainer 回调标志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "def validation_step(self):\n",
    "    self.log(\"val_loss\", loss)\n",
    "\n",
    "\n",
    "trainer = Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-macedonia",
   "metadata": {},
   "source": [
    "您可以通过更改其参数来自定义回调行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "trainer = Trainer(callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-youth",
   "metadata": {},
   "source": [
    "在极端点停止训练的其他参数：\n",
    "* stop_threshold：一旦监控的数量达到这个阈值，立即停止训练。 当我们知道超出某个最佳值不会进一步使我们受益时，这很有用。\n",
    "* divergence_threshold：一旦监控的数量变得比这个阈值更差，就停止训练。 当达到如此糟糕的值时，我们认为模型无法再恢复，最好提前停止并在不同的初始条件下运行。\n",
    "* check_finite：开启后，如果监控指标变为 NaN 或无穷大，我们将停止训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-selection",
   "metadata": {},
   "source": [
    "如果您需要在训练的不同部分提前停止，请子类 EarlyStopping 并更改它的调用位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEarlyStopping(EarlyStopping):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # 覆盖它以在 val 循环结束时禁用提前停止\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        # i相反，在训练循环结束时进行\n",
    "        self._run_early_stopping_check(trainer, pl_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-motivation",
   "metadata": {},
   "source": [
    "> EarlyStopping 回调在每个验证时期结束时运行，在默认配置下，在每个训练时期之后发生。 但是，可以通过在 Trainer 中设置各种参数来修改验证频率，例如 check_val_every_n_epoch 和 val_check_interval。 必须注意，耐心参数计算没有改进的验证时期的数量，而不是训练时期的数量。 因此，在参数 check_val_every_n_epoch=10 和pattern=3 的情况下，训练器在停止之前将执行至少 40 个训练 epoch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
